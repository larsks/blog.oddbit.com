<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ansible_20_series on blog.oddbit.com</title><link>https://blog.oddbit.com/tag/ansible_20_series/</link><description>Recent content in ansible_20_series on blog.oddbit.com</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Lars Kellogg-Stedman</copyright><lastBuildDate>Mon, 26 Oct 2015 00:00:00 +0000</lastBuildDate><atom:link href="https://blog.oddbit.com/tag/ansible_20_series/rss.xml" rel="self" type="application/rss+xml"/><item><title>Ansible 2.0: New OpenStack modules</title><link>https://blog.oddbit.com/post/2015-10-26-ansible-20-new-openstack-modul/</link><pubDate>Mon, 26 Oct 2015 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2015-10-26-ansible-20-new-openstack-modul/</guid><description>This is the second in a loose sequence of articles looking at new features in Ansible 2.0. In the previous article I looked at the Docker connection driver. In this article, I would like to provide an overview of the new-and-much-improved suite of modules for interacting with an OpenStack environment, and provide a few examples of their use.
In versions of Ansible prior to 2.0, there was a small collection of OpenStack modules.</description><content>&lt;p>This is the second in a loose sequence of articles looking at new
features in Ansible 2.0. In the previous article I looked at the
&lt;a href="https://blog.oddbit.com/post/2015-10-13-ansible-20-the-docker-connecti/">Docker connection driver&lt;/a>. In this article, I would like to
provide an overview of the new-and-much-improved suite of modules for
interacting with an &lt;a href="http://www.openstack.org/">OpenStack&lt;/a> environment, and provide a few
examples of their use.&lt;/p>
&lt;p>In versions of Ansible prior to 2.0, there was a small collection of
OpenStack modules. There was the minimum necessary to boot a Nova
instance:&lt;/p>
&lt;ul>
&lt;li>&lt;code>glance_image.py&lt;/code>&lt;/li>
&lt;li>&lt;code>keystone_user.py&lt;/code>&lt;/li>
&lt;li>&lt;code>nova_compute.py&lt;/code>&lt;/li>
&lt;li>&lt;code>nova_keypair.py&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>And a collection of modules for interacting with &lt;a href="https://wiki.openstack.org/wiki/Neutron">Neutron&lt;/a> (previously
Quantum):&lt;/p>
&lt;ul>
&lt;li>&lt;code>quantum_floating_ip_associate.py&lt;/code>&lt;/li>
&lt;li>&lt;code>quantum_floating_ip.py&lt;/code>&lt;/li>
&lt;li>&lt;code>quantum_network.py&lt;/code>&lt;/li>
&lt;li>&lt;code>quantum_router_gateway.py&lt;/code>&lt;/li>
&lt;li>&lt;code>quantum_router_interface.py&lt;/code>&lt;/li>
&lt;li>&lt;code>quantum_router.py&lt;/code>&lt;/li>
&lt;li>&lt;code>quantum_subnet.py&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>While functional, these modules did not provide very comprehensive
coverage of even basic OpenStack services, and they suffered from
having a great deal of duplicated code (which made ensuring
consistent behavior across all the modules more difficult). The
behavior of these modules was not always what you would expect (e.g.,
the &lt;code>nova_compute&lt;/code> module would return information in different forms
depending on whether it had to create an instance or not).&lt;/p>
&lt;h2 id="throwing-shade">Throwing Shade&lt;/h2>
&lt;p>The situation is much improved in Ansible 2.0, which introduces a new
suite of OpenStack modules in which the common code has been factored
out into the &lt;a href="https://pypi.python.org/pypi/shade">Shade&lt;/a> project, a Python package that provides a
simpler interface to OpenStack than is available using the native
clients. Collecting this code in one place will help ensure both that
these Ansible modules share consistent behavior and that they are
easier to maintain.&lt;/p>
&lt;p>There are modules for managing Keystone:&lt;/p>
&lt;ul>
&lt;li>&lt;code>os_auth.py&lt;/code>&lt;/li>
&lt;li>&lt;code>os_user_group.py&lt;/code>&lt;/li>
&lt;li>&lt;code>os_user.py&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>Glance:&lt;/p>
&lt;ul>
&lt;li>&lt;code>os_image_facts.py&lt;/code>&lt;/li>
&lt;li>&lt;code>os_image.py&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>Cinder:&lt;/p>
&lt;ul>
&lt;li>&lt;code>os_server_volume.py&lt;/code>&lt;/li>
&lt;li>&lt;code>os_volume.py&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>Nova:&lt;/p>
&lt;ul>
&lt;li>&lt;code>os_keypair.py&lt;/code>&lt;/li>
&lt;li>&lt;code>os_nova_flavor.py&lt;/code>&lt;/li>
&lt;li>&lt;code>os_server_actions.py&lt;/code>&lt;/li>
&lt;li>&lt;code>os_server_facts.py&lt;/code>&lt;/li>
&lt;li>&lt;code>os_server.py&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>Ironic:&lt;/p>
&lt;ul>
&lt;li>&lt;code>os_ironic_node.py&lt;/code>&lt;/li>
&lt;li>&lt;code>os_ironic.py&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>Neutron and Nova Networking:&lt;/p>
&lt;ul>
&lt;li>&lt;code>os_floating_ip.py&lt;/code>&lt;/li>
&lt;li>&lt;code>os_network.py&lt;/code>&lt;/li>
&lt;li>&lt;code>os_networks_facts.py&lt;/code>&lt;/li>
&lt;li>&lt;code>os_port.py&lt;/code>&lt;/li>
&lt;li>&lt;code>os_router.py&lt;/code>&lt;/li>
&lt;li>&lt;code>os_security_group.py&lt;/code>&lt;/li>
&lt;li>&lt;code>os_security_group_rule.py&lt;/code>&lt;/li>
&lt;li>&lt;code>os_subnet.py&lt;/code>&lt;/li>
&lt;li>&lt;code>os_subnets_facts.py&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>and Swift:&lt;/p>
&lt;ul>
&lt;li>&lt;code>os_object.py&lt;/code>&lt;/li>
&lt;/ul>
&lt;h2 id="authentication">Authentication&lt;/h2>
&lt;p>Shade uses the &lt;a href="https://pypi.python.org/pypi/os-client-config/">os-client-config&lt;/a> library to configure
authentication credentials for your OpenStack environment.&lt;/p>
&lt;p>In the absence of any authentication information provided in your
Ansible playbook, these modules will attempt to use the standard suite
of &lt;code>OS_*&lt;/code> variables (&lt;code>OS_USERNAME&lt;/code>, &lt;code>OS_PASSWORD&lt;/code>, etc). This is fine
for testing, but you usually want to provide some sort of
authentication configuration in your Ansible environment.&lt;/p>
&lt;p>You can provide credentials directly in your plays by providing an
&lt;code>auth&lt;/code> argument to any of the modules. For example:&lt;/p>
&lt;pre>&lt;code>- os_image:
auth:
auth_url: http://openstack.local:5000/v2.0
username: admin
password: secret
project_name: admin
[...]
&lt;/code>&lt;/pre>
&lt;p>But that can get complicated, especially if you are maintaining
multiple sets of credentials. The &lt;code>shade&lt;/code> library allows you to
manage credentials in a file named (by default) &lt;code>clouds.yml&lt;/code>, which
&lt;code>shade&lt;/code> searches for in:&lt;/p>
&lt;ul>
&lt;li>The current directory&lt;/li>
&lt;li>&lt;code>$HOME/.config/openstack/&lt;/code>&lt;/li>
&lt;li>&lt;code>/etc/xdg/openstack/&lt;/code>&lt;/li>
&lt;li>&lt;code>/etc/openstack&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>This file may contain credentials for one or more cloud environments,
for example:&lt;/p>
&lt;pre>&lt;code>clouds:
testing:
auth:
auth_url: http://openstack.local:5000/v2.0
username: admin
password: secret
project_name: admin
&lt;/code>&lt;/pre>
&lt;p>If you have the above in &lt;code>clouds.yml&lt;/code> along with your playbook, the
above &lt;code>os_image&lt;/code> example can be rewritten as:&lt;/p>
&lt;pre>&lt;code>- os_image:
cloud: testing
[...]
&lt;/code>&lt;/pre>
&lt;h2 id="return-values">Return values&lt;/h2>
&lt;p>The new modules all return useful information about the objects they
have created. For example, if you create a network using
&lt;a href="http://docs.ansible.com/ansible/os_network_module.html">os_network&lt;/a> and register that result:&lt;/p>
&lt;pre>&lt;code>- os_network:
cloud: testing
name: mynetwork
register: mynetwork
&lt;/code>&lt;/pre>
&lt;p>You&amp;rsquo;ll get back a dictionary containing a top-level &lt;code>id&lt;/code> attribute,
which is the UUID of the created network, along with a &lt;code>network&lt;/code>
attribute containing a dictionary of information about the created
object. The &lt;a href="http://docs.ansible.com/ansible/debug_module.html">debug&lt;/a> module is an excellent tool for exploring these
return values. If we put the following in our playbook immediately
after the above task:&lt;/p>
&lt;pre>&lt;code>- debug:
var: mynetwork
&lt;/code>&lt;/pre>
&lt;p>We would get output that looks something like:&lt;/p>
&lt;pre>&lt;code>ok: [localhost] =&amp;gt; {
&amp;quot;changed&amp;quot;: false,
&amp;quot;mynetwork&amp;quot;: {
&amp;quot;changed&amp;quot;: true,
&amp;quot;id&amp;quot;: &amp;quot;02b77e32-794a-4102-ab1b-1b90e6d4d92f&amp;quot;,
&amp;quot;invocation&amp;quot;: {
&amp;quot;module_args&amp;quot;: {
&amp;quot;cloud&amp;quot;: &amp;quot;testing&amp;quot;,
&amp;quot;name&amp;quot;: &amp;quot;mynetwork&amp;quot;
},
&amp;quot;module_name&amp;quot;: &amp;quot;os_network&amp;quot;
},
&amp;quot;network&amp;quot;: {
&amp;quot;admin_state_up&amp;quot;: true,
&amp;quot;id&amp;quot;: &amp;quot;02b77e32-794a-4102-ab1b-1b90e6d4d92f&amp;quot;,
&amp;quot;mtu&amp;quot;: 0,
&amp;quot;name&amp;quot;: &amp;quot;mynetwork&amp;quot;,
&amp;quot;provider:network_type&amp;quot;: &amp;quot;vxlan&amp;quot;,
&amp;quot;provider:physical_network&amp;quot;: null,
&amp;quot;provider:segmentation_id&amp;quot;: 79,
&amp;quot;router:external&amp;quot;: false,
&amp;quot;shared&amp;quot;: false,
&amp;quot;status&amp;quot;: &amp;quot;ACTIVE&amp;quot;,
&amp;quot;subnets&amp;quot;: [],
&amp;quot;tenant_id&amp;quot;: &amp;quot;349a8b95c5ad4a3383149f65f8c44cff&amp;quot;
}
}
}
&lt;/code>&lt;/pre>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>I have written a set of basic &lt;a href="https://github.com/ansible/ansible/pull/12875">integration tests&lt;/a> for these modules.
I hope the pull request is merged, but even if not it provides an
example of how to make use of many of these new modules.&lt;/p>
&lt;p>I&amp;rsquo;d like to present a few brief examples here to give you a sense of
what working with the new modules is like.&lt;/p>
&lt;h3 id="uploading-an-image-to-glance">Uploading an image to Glance&lt;/h3>
&lt;p>The &lt;a href="http://docs.ansible.com/ansible/os_image_module.html">os_image&lt;/a> module is used to upload an image to Glance. Assuming
that you have file named &lt;code>cirros.qcow2&lt;/code> available locally, this will
create an image named &lt;code>cirros&lt;/code> in Glance:&lt;/p>
&lt;pre>&lt;code>- os_image:
cloud: testing
name: cirros
state: present
disk_format: qcow2
container_format: bare
filename: cirros.qcow2
&lt;/code>&lt;/pre>
&lt;h3 id="booting-a-nova-server">Booting a Nova server&lt;/h3>
&lt;p>The &lt;a href="http://docs.ansible.com/ansible/os_server_module.html">os_server&lt;/a> module, which is used for booting virtual servers
(&amp;ldquo;instances&amp;rdquo;) in Nova, replaces the &lt;a href="http://docs.ansible.com/ansible/nova_compute_module.html">nova_compute&lt;/a> module available
in Ansible versions before 2.0:&lt;/p>
&lt;pre>&lt;code>- name: create a nova server
os_server:
cloud: testing
name: myserver
state: present
nics:
- net-name: private
image: cirros
flavor: m1.small
key_name: my_ssh_key
&lt;/code>&lt;/pre>
&lt;p>The &lt;code>nics&lt;/code> parameter can accept net names, net ids, port names, and
port ids. So you could also do this (assuming you were attaching your
server to two different tenant networks):&lt;/p>
&lt;pre>&lt;code>nics:
- net-id: c875770c-a20b-45b5-a9da-5aca97153053
- net-name: private
&lt;/code>&lt;/pre>
&lt;p>The above examples are using a YAML list of dictionaries to provide
the information. You can also pass in a comma-delimited key=value
string, like this:&lt;/p>
&lt;pre>&lt;code>nics: net-name=private,net-name=database
&lt;/code>&lt;/pre>
&lt;p>This syntax is particular useful if you are running ad-hoc commands on
the command line:&lt;/p>
&lt;pre>&lt;code>ansible localhost -m os_server -a '
cloud=testing name=myserver nics=net-name=private
image=cirros flavor=m1.small key_name=my_ssh_key'
&lt;/code>&lt;/pre>
&lt;h3 id="adding-a-nova-server-to-your-ansible-inventory">Adding a Nova server to your Ansible inventory&lt;/h3>
&lt;p>I&amp;rsquo;d like to conclude this post with a longer example, that
demonstrates how you can use the &lt;a href="http://docs.ansible.com/ansible/add_host_module.html">add_host&lt;/a> module to add a freshly
created server to your inventory, and then target that new server in
your playbook. I&amp;rsquo;ve split up this playbook with commentary; in
practice, the pre-formatted text in this section would all be in a
single playbook (like &lt;a href="https://blog.oddbit.com/assets/2015/10/26/playbook.yml">this&lt;/a>).&lt;/p>
&lt;pre>&lt;code>- hosts: localhost
tasks:
&lt;/code>&lt;/pre>
&lt;p>This first task boots the server. The values for &lt;code>image&lt;/code>, &lt;code>nics&lt;/code>, and
`key_name will need to be adjusted for your environment.&lt;/p>
&lt;pre>&lt;code> - os_server:
cloud: testing
name: myserver
image: centos-7-atomic
nics:
- net-name: private
flavor: m1.small
key_name: lars
auto_ip: true
register: myserver
&lt;/code>&lt;/pre>
&lt;p>This &lt;code>debug&lt;/code> entry simply shows us what values were returned in the
&lt;code>myserver&lt;/code> variable.&lt;/p>
&lt;pre>&lt;code> - debug:
var: myserver
&lt;/code>&lt;/pre>
&lt;p>Now we add the new host to our Ansible inventory. For this to work,
you need to have assigned a floating ip to the server (either using
&lt;code>auto_ip&lt;/code>, as in this example, or by assigning one explicitly), and
you need to be running this playbook somewhere that has a route to the
floating ip address.&lt;/p>
&lt;pre>&lt;code> - add_host:
name: myserver
groups: openstack
ansible_host: &amp;quot;{{myserver.server.public_v4}}&amp;quot;
ansible_user: centos
ansible_become: true
&lt;/code>&lt;/pre>
&lt;p>Note that in the above play you can&amp;rsquo;t use information from the
inventory because that new host won&amp;rsquo;t exist in the inventory until
&lt;em>after&lt;/em> this play completes.&lt;/p>
&lt;p>We&amp;rsquo;ll need to wait for the server to finish booting and provisioning
before we are able to target it with ansible. A typical cloud image
is configured to run &lt;a href="https://cloudinit.readthedocs.org/en/latest/">cloud-init&lt;/a> when it boots, which will take
care of a number of initial configuration tasks, including
provisioning the ssh key we configured using &lt;code>os_server&lt;/code>. Until this
process is complete, we won&amp;rsquo;t have remote access to the server.&lt;/p>
&lt;p>We can&amp;rsquo;t use the &lt;code>wait_for&lt;/code> module because that will only
check for an open port. Instead, we use a &lt;a href="http://docs.ansible.com/ansible/playbooks_loops.html#do-until-loops">do-until loop&lt;/a> to
wait until we are able to successfully run a command on the server via
ssh.&lt;/p>
&lt;pre>&lt;code> - command: &amp;gt;
ssh -o BatchMode=yes
centos@{{myserver.server.public_v4}} true
register: result
until: result|success
retries: 300
delay: 5
&lt;/code>&lt;/pre>
&lt;p>Now that we have added the new server to our inventory
we can target it in subsequent plays (such as this one):&lt;/p>
&lt;pre>&lt;code>- hosts: myserver
tasks:
- service:
name: docker
state: running
enabled: true
&lt;/code>&lt;/pre></content></item><item><title>Ansible 2.0: The Docker connection driver</title><link>https://blog.oddbit.com/post/2015-10-13-ansible-20-the-docker-connecti/</link><pubDate>Tue, 13 Oct 2015 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2015-10-13-ansible-20-the-docker-connecti/</guid><description>As the release of Ansible 2.0 draws closer, I&amp;rsquo;d like to take a look at some of the new features that are coming down the pipe. In this post, we&amp;rsquo;ll look at the docker connection driver.
A &amp;ldquo;connection driver&amp;rdquo; is the mechanism by which Ansible connects to your target hosts. These days it uses ssh by default (which relies on the OpenSSH command line client for connectivity), and it also offers the Paramiko library as an alternative ssh implementation (this was in fact the default driver in earlier versions of Ansible).</description><content>&lt;p>As the release of &lt;a href="http://ansible.com/">Ansible&lt;/a> 2.0 draws closer, I&amp;rsquo;d like to take a
look at some of the new features that are coming down the pipe. In
this post, we&amp;rsquo;ll look at the &lt;code>docker&lt;/code> connection driver.&lt;/p>
&lt;p>A &amp;ldquo;connection driver&amp;rdquo; is the mechanism by which Ansible connects to
your target hosts. These days it uses &lt;code>ssh&lt;/code> by default (which relies
on the OpenSSH command line client for connectivity), and it also
offers the &lt;a href="http://www.paramiko.org/">Paramiko&lt;/a> library as an alternative ssh implementation
(this was in fact the default driver in earlier versions of Ansible).
Alternative drivers offered by recent versions of ansible included the
&lt;code>winrm&lt;/code> driver, for accessing Windows hosts, the &lt;code>fireball&lt;/code> driver, a
(deprecated) driver that used &lt;a href="http://zeromq.org/">0mq&lt;/a> for communication, and &lt;code>jail&lt;/code>, a
driver for connecting to FreeBSD jails.&lt;/p>
&lt;p>Ansible 2.0 will offer a &lt;code>docker&lt;/code> connection driver, which can be used
to connect to Docker containers via the &lt;code>docker exec&lt;/code> command.
Assuming you have a running container named &lt;code>target&lt;/code>, you can run an
ad-hoc command like this:&lt;/p>
&lt;pre>&lt;code>$ ansible all -i target, -c docker -m command -a 'uptime'
target | SUCCESS | rc=0 &amp;gt;&amp;gt;
03:54:21 up 7 days, 15:00, 0 users, load average: 0.81, 0.60, 0.46
&lt;/code>&lt;/pre>
&lt;p>You can specify the connection driver as part of a play in your
playbook:&lt;/p>
&lt;pre>&lt;code>- hosts: target
connection: docker
tasks:
- package:
name: git
state: latest
&lt;/code>&lt;/pre>
&lt;p>Or as a variable in your inventory. Here&amp;rsquo;s an example that has both a
docker container and an ssh-accessible host:&lt;/p>
&lt;pre>&lt;code>target ansible_connection=docker
server ansible_host=192.168.1.20 ansible_user=root
&lt;/code>&lt;/pre>
&lt;p>Given the following playbook:&lt;/p>
&lt;pre>&lt;code>- hosts: all
tasks:
- ping:
&lt;/code>&lt;/pre>
&lt;p>If we run it like this, assuming the above inventory is in the file
&lt;code>inventory&lt;/code>:&lt;/p>
&lt;pre>&lt;code>$ ansible-playbook -i inventory playbook.yml
&lt;/code>&lt;/pre>
&lt;p>The output will look something like:&lt;/p>
&lt;pre>&lt;code>TASK [ping] ********************************************************************
&amp;lt;192.168.1.20&amp;gt; ESTABLISH SSH CONNECTION FOR USER: root
&amp;lt;192.168.1.20&amp;gt; SSH: EXEC ssh -C -q -o ControlMaster=auto -o ControlPersist=60s ... 192.168.1.20 ...
&amp;lt;192.168.1.20&amp;gt; PUT /tmp/tmpbtrmo5 TO /root/.ansible/tmp/ansible-tmp-1444795190.49-64658551273604/ping
&amp;lt;192.168.1.20&amp;gt; SSH: EXEC sftp -b - -C -o ControlMaster=auto -o ControlPersist=60s ... 192.168.1.20 ...
ESTABLISH DOCKER CONNECTION FOR USER: lars
&amp;lt;target&amp;gt; EXEC ['/usr/bin/docker', 'exec', '-i', u'target', '/bin/sh', '-c', ...
&amp;lt;target&amp;gt; PUT /tmp/tmpNmcPTf TO /root/.ansible/tmp/ansible-tmp-1444795190.53-251446545325875/ping
&amp;lt;192.168.1.20&amp;gt; ESTABLISH SSH CONNECTION FOR USER: root
&amp;lt;192.168.1.20&amp;gt; SSH: EXEC ssh -C -q -o ControlMaster=auto -o ControlPersist=60s ... 192.168.1.20 ...
ok: [server -&amp;gt; localhost] =&amp;gt; {&amp;quot;changed&amp;quot;: false, &amp;quot;ping&amp;quot;: &amp;quot;pong&amp;quot;}
&amp;lt;target&amp;gt; EXEC ['/usr/bin/docker', 'exec', '-i', u'target', '/bin/sh', '-c', ...
ok: [target -&amp;gt; localhost] =&amp;gt; {&amp;quot;changed&amp;quot;: false, &amp;quot;ping&amp;quot;: &amp;quot;pong&amp;quot;}
PLAY RECAP *********************************************************************
server : ok=2 changed=0 unreachable=0 failed=0
target : ok=2 changed=0 unreachable=0 failed=0
&lt;/code>&lt;/pre>
&lt;p>Now you have a unified mechanism for managing configuration changes in
traditional hosts as well as in Docker containers.&lt;/p></content></item></channel></rss>