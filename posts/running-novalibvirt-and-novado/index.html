<!doctype html><html lang=en><head><title>Running nova-libvirt and nova-docker on the same host :: blog.oddbit.com</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="I regularly use OpenStack on my laptop with libvirt as my hypervisor. I was interested in experimenting with recent versions of the nova-docker driver, but I didn&amp;rsquo;t have a spare system available on which to run the driver, and I use my regular nova-compute service often enough that I didn&amp;rsquo;t want to simply disable it temporarily in favor of nova-docker.
NB As pointed out by gustavo in the comments, running two neutron-openvswitch-agents on the same host &amp;ndash; as suggested in this article &amp;ndash; is going to lead to nothing but sadness and doom."><meta name=keywords content><meta name=robots content="noodp"><link rel=canonical href=https://blog.oddbit.com/posts/running-novalibvirt-and-novado/><link rel=stylesheet href=https://blog.oddbit.com/styles.css><link rel=stylesheet href=https://blog.oddbit.com/style.css><link rel="shortcut icon" href=https://blog.oddbit.com/img/theme-colors/orange.png><link rel=apple-touch-icon href=https://blog.oddbit.com/img/theme-colors/orange.png><meta name=twitter:card content="summary"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="og:title" content="Running nova-libvirt and nova-docker on the same host"><meta property="og:description" content="I regularly use OpenStack on my laptop with libvirt as my hypervisor. I was interested in experimenting with recent versions of the nova-docker driver, but I didn&amp;rsquo;t have a spare system available on which to run the driver, and I use my regular nova-compute service often enough that I didn&amp;rsquo;t want to simply disable it temporarily in favor of nova-docker.
NB As pointed out by gustavo in the comments, running two neutron-openvswitch-agents on the same host &amp;ndash; as suggested in this article &amp;ndash; is going to lead to nothing but sadness and doom."><meta property="og:url" content="https://blog.oddbit.com/posts/running-novalibvirt-and-novado/"><meta property="og:site_name" content="blog.oddbit.com"><meta property="og:image" content="https://blog.oddbit.com/img/favicon/orange.png"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="627"><meta property="article:section" content="tech"><meta property="article:published_time" content="2015-01-17 00:00:00 +0000 UTC"></head><body class=orange><div class="container center headings--one-size"><header class=header><div class=header__inner><div class=header__logo><a href=/><div class=logo>the odd bit blog</div></a></div><ul class="menu menu--mobile"><li class=menu__trigger>Menu&nbsp;▾</li><li><ul class=menu__dropdown><li><a href=/>/</a></li><li><a href=https://oddbit.com>/about</a></li><li><a href=/posts>/posts</a></li><li><a href=/archive>/archive</a></li><li><a href=/rss.xml>/feed</a></li><li><a href=https://github.com/larsks>→Github</a></li><li><a href=https://hachyderm.io/@larsks>→Mastodon</a></li><li><a href=https://twitter.com/larsks>→Twitter</a></li></ul></li></ul></div><nav class=navigation-menu><ul class="navigation-menu__inner menu--desktop"><li><a href=/>/</a></li><li><a href=https://oddbit.com>/about</a></li><li><a href=/posts>/posts</a></li><li><a href=/archive>/archive</a></li><li><a href=/rss.xml>/feed</a></li><li><ul class=menu><li class=menu__trigger>&nbsp;▾</li><li><ul class=menu__dropdown><li><a href=https://github.com/larsks>→Github</a></li><li><a href=https://hachyderm.io/@larsks>→Mastodon</a></li><li><a href=https://twitter.com/larsks>→Twitter</a></li></ul></li></ul></li></ul></nav></header><div class=content><article class=post><h1 class=post-title><a href=https://blog.oddbit.com/posts/running-novalibvirt-and-novado/>Running nova-libvirt and nova-docker on the same host</a></h1><div class=post-meta><time class=post-date>2015-01-17 ::</time></div><span class=post-tags>#<a href=https://blog.oddbit.com/tags/openstack/>openstack</a>&nbsp;
#<a href=https://blog.oddbit.com/tags/docker/>docker</a>&nbsp;</span><div class=post-content><div><p>I regularly use <a href=http://www.openstack.org/>OpenStack</a> on my laptop with <a href=http://www.libvirt.org/>libvirt</a> as my
hypervisor. I was interested in experimenting with recent versions of
the <a href=https://github.com/stackforge/nova-docker>nova-docker</a> driver, but I didn&rsquo;t have a spare system available
on which to run the driver, and I use my regular <code>nova-compute</code> service
often enough that I didn&rsquo;t want to simply disable it temporarily in
favor of <code>nova-docker</code>.</p><hr><p><strong>NB</strong> As pointed out by <em>gustavo</em> in the comments, running two
<code>neutron-openvswitch-agents</code> on the same host &ndash; as suggested in this
article &ndash; is going to lead to nothing but sadness and doom. So
kids, don&rsquo;t try this at home. I&rsquo;m leaving the article here because I
think it still has some interesting bits.</p><hr><p>I guess the simplest solution would be to spin up a vm on which to run
<code>nova-docker</code>, but why use a simple solution when there are things to
be learned? I wanted to know if it were possible (and if so, how) to
run both hypervisors on the same physical host.</p><p>The naive solution would be to start up another instance of
<code>nova-compute</code> configured to use the Docker driver. Unfortunately,
Nova only permits a single service instance per &ldquo;host&rdquo;, so starting up
the second instance of <code>nova-compute</code> would effectively &ldquo;mask&rdquo; the
original one.</p><p>Fortunately, Nova&rsquo;s definition of what constitutes a &ldquo;host&rdquo; is
somewhat flexible. Nova supports a <code>host</code> configuration key in
<code>nova.conf</code> that will cause Nova to identify the host on which it is
running using your explicitly configured value, rather than your
system hostname. We can take advantage of this to get a second
<code>nova-compute</code> instance running on the same system.</p><h2 id=install-nova-docker>Install nova-docker<a href=#install-nova-docker class=hanchor arialabel=Anchor>&#8983;</a></h2><p>We&rsquo;ll start by installing the <code>nova-docker</code> driver from
<a href=https://github.com/stackforge/nova-docker>https://github.com/stackforge/nova-docker</a>. If you&rsquo;re running the
Juno release of OpenStack (which I am), you&rsquo;re going to want to use
the <code>stable/juno</code> branch of the <code>nova-docker</code> repository. So:</p><pre><code>$ git clone https://github.com/stackforge/nova-docker
$ cd nova-docker
$ git checkout stable/juno
$ sudo python setup.py install
</code></pre><p>You&rsquo;ll want to read the project&rsquo;s <a href=https://github.com/stackforge/nova-docker/blob/master/README.rst>README</a> for complete installation
instructions.</p><h2 id=configure-nova-docker>Configure nova-docker<a href=#configure-nova-docker class=hanchor arialabel=Anchor>&#8983;</a></h2><p>Now, rather than configuring <code>/etc/nova/nova.conf</code>, we&rsquo;re going to
create a new configuration file, <code>/etc/nova/nova-docker.conf</code>, with
only the configuration keys that differ from our primary Nova
configuration:</p><pre><code>[DEFAULT]
host=nova-docker
compute_driver=novadocker.virt.docker.DockerDriver
log_file=/var/log/nova/nova-docker.log
state_path=/var/lib/nova-docker
</code></pre><p>You can see that we&rsquo;ve set the value of <code>host</code> to <code>nova-docker</code>, to
differentiate this <code>nova-compute</code> service from the <code>libvirt</code>-backed
one that is already running. We&rsquo;ve provided the service with a
dedicated log file and state directory to prevent conflicts with the
already-running <code>nova-compute</code> service.</p><p>To use this configuration file, we&rsquo;ll launch a new instance of the
<code>nova-compute</code> service pointing at both the original configuration
file, <code>/etc/nova/nova.conf</code>, as well as this <code>nova-docker</code>
configuration file. The command line would look something like:</p><pre><code>nova-compute --config-file /etc/nova/nova.conf \
  --config-file /etc/nova/nova-docker.conf
</code></pre><p>The ordering of configuration files on the command line is
significant: later configuration files will override values from
earlier files.</p><p>I&rsquo;m running <a href=http://www.fedora.org/>Fedora</a> 21 on my laptop, which uses <a href=http://www.freedesktop.org/wiki/Software/systemd/>systemd</a>, so I
created a modified version of the <code>openstack-nova-compute.service</code>
unit on my system, and saved it as
<code>/etc/systemd/system/openstack-nova-docker.service</code>:</p><pre><code>[Unit]
Description=OpenStack Nova Compute Server (Docker)
After=syslog.target network.target

[Service]
Environment=LIBGUESTFS_ATTACH_METHOD=appliance
Type=notify
Restart=always
User=nova
ExecStart=/usr/bin/nova-compute --config-file /etc/nova/nova.conf --config-file /etc/nova/nova-docker.conf

[Install]
WantedBy=multi-user.target
</code></pre><p>And then activated the service;</p><pre><code># systemctl enable openstack-nova-docker
# systemctl start openstack-nova-docker
</code></pre><p>Now, if I run <code>nova service-list</code> with administrator credentials, I
can see both <code>nova-compute</code> instances:</p><pre><code>+----+------------------+------------------+----------+---------+-------...
| Id | Binary           | Host             | Zone     | Status  | State ...
+----+------------------+------------------+----------+---------+-------...
| 1  | nova-consoleauth | host.example.com | internal | enabled | up    ...
| 2  | nova-scheduler   | host.example.com | internal | enabled | up    ...
| 3  | nova-conductor   | host.example.com | internal | enabled | up    ...
| 5  | nova-cert        | host.example.com | internal | enabled | up    ...
| 6  | nova-compute     | host.example.com | nova     | enabled | up    ...
| 7  | nova-compute     | nova-docker      | nova     | enabled | up    ...
+----+------------------+------------------+----------+---------+-------...
</code></pre><h2 id=booting-a-docker-container-take-1>Booting a Docker container (take 1)<a href=#booting-a-docker-container-take-1 class=hanchor arialabel=Anchor>&#8983;</a></h2><p>Let&rsquo;s try starting a Docker container using the new <code>nova-compute</code>
service. We&rsquo;ll first need to load a Docker image into Glance (you
followed the <code>nova-docker</code> <a href=https://github.com/stackforge/nova-docker#1-enable-the-driver-in-glances-configuration>instructions for configuring
Glance</a>, right?). We&rsquo;ll use my <a href=https://registry.hub.docker.com/u/larsks/thttpd/>larsks/thttpd</a> image,
because it&rsquo;s very small and doesn&rsquo;t require any configuration:</p><pre><code>$ docker pull larsks/thttpd
$ docker save larsks/thttpd |
  glance image-create --is-public True --container-format docker \
    --disk-format raw --name larsks/thttpd
</code></pre><p>(Note that you will probably require administrative credentials to load
this image into Glance.)</p><p>Now that we have an appropriate image available we can try booting a container:</p><pre><code>$ nova boot --image larsks/thttpd --flavor m1.small test1
</code></pre><p>If we wait a moment and then run <code>nova list</code>, we see:</p><pre><code>| 9a783952-a888-4fcd-8f5d-cd9291ed1969 | test1   | ERROR  | spawning   ...
</code></pre><p><a href=http://www.sadtrombone.com/>What happened?</a> Looking at the appropriate log file
(<code>/var/log/nova/nova-docker.log</code>), we find:</p><pre><code>Cannot setup network: Unexpected vif_type=binding_failed
Traceback (most recent call last):
  File &quot;/usr/lib/python2.7/site-packages/novadocker/virt/docker/driver.py&quot;, line 367, in _start_container
    self.plug_vifs(instance, network_info)
  File &quot;/usr/lib/python2.7/site-packages/novadocker/virt/docker/driver.py&quot;, line 187, in plug_vifs
    self.vif_driver.plug(instance, vif)
  File &quot;/usr/lib/python2.7/site-packages/novadocker/virt/docker/vifs.py&quot;, line 63, in plug
    _(&quot;Unexpected vif_type=%s&quot;) % vif_type)
NovaException: Unexpected vif_type=binding_failed
</code></pre><p>The message <code>vif_type=binding_failed</code> is Nova&rsquo;s way of saying &ldquo;I have
no idea what happened, go ask Neutron&rdquo;. Looking in Neutron&rsquo;s
<code>/var/log/neutron/server.log</code>, we find:</p><pre><code>Failed to bind port 82c07caa-b2c2-45e9-955d-e8b35112437c on host
nova-docker
</code></pre><p>And this tells us our problem: we have told our <code>nova-docker</code> service
that it is running on a host called &ldquo;nova-docker&rdquo;, and Neutron doesn&rsquo;t
know anything about that host.</p><hr><p><strong>NB</strong></p><p>If you were to try to delete this failed instance, you would find that
it is un-deletable. In the end, I was only able to delete it by
directly editing the <code>nova</code> database using <a href=/assets/2015/01/17/delete-deleting-instances.sql>this sql script</a>.</p><hr><h2 id=adding-a-neutron-agent>Adding a Neutron agent<a href=#adding-a-neutron-agent class=hanchor arialabel=Anchor>&#8983;</a></h2><p>We&rsquo;re going to need to set up an instance of
<code>neutron-openvswitch-agent</code> to service network requests on our
&ldquo;nova-docker&rdquo; host. Like Nova, Neutron also supports a <code>host</code>
configuration key, so we&rsquo;re going to pursue a solution similar to what
we used with Nova by creating a new configuration file,
<code>/etc/neutron/ovs-docker.conf</code>, with the following content:</p><pre><code>[DEFAULT]
host = nova-docker
</code></pre><p>And then we&rsquo;ll set up the corresponding service by dropping the
following into <code>/etc/systemd/system/docker-openvswitch-agent.service</code>:</p><pre><code>[Unit]
Description=OpenStack Neutron Open vSwitch Agent (Docker)
After=syslog.target network.target

[Service]
Type=simple
User=neutron
ExecStart=/usr/bin/neutron-openvswitch-agent --config-file /usr/share/neutron/neutron-dist.conf --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/openvswitch/ovs_neutron_plugin.ini --config-file /etc/neutron/ovs-docker.conf --log-file /var/log/neutron/docker-openvswitch-agent.log
PrivateTmp=true
KillMode=process

[Install]
WantedBy=multi-user.target
</code></pre><hr><p><strong>NB</strong></p><p>While working on this configuration I ran into an undesirable
interaction between Docker and <a href=http://www.freedesktop.org/wiki/Software/systemd/>systemd</a>&rsquo;s <code>PrivateTmp</code> directive.</p><p>This directive causes the service to run with
a private <a href=http://lwn.net/Articles/531114/>mount namespace</a> such that <code>/tmp</code> for the service is not
the same as <code>/tmp</code> for other services. This is a great idea from a
security perspective, but can cause problems in the following
scenario:</p><ol><li>Start a Docker container with <code>nova boot ...</code></li><li>Restart any service that uses the <code>PrivateTmp</code> directive</li><li>Attempt to delete the Docker container with <code>nova delete ...</code></li></ol><p>Docker will fail to destroy the container because the private
namespace created by the <code>PrivateTmp</code> directive preserves a reference
to the Docker <code>devicemapper</code> mount in
<code>/var/lib/docker/devicemapper/mnt/...</code> that was active at the time the
service was restarted. To recover from this situation, you will need
to restart whichever service is still holding a reference to the
Docker mounts.</p><p>I have <a href=http://lists.freedesktop.org/archives/systemd-devel/2015-January/027162.html>posted to the systemd-devel</a> mailing
list to see if there are any solutions to this behavior. As I note in
that email, this behavior appears to be identical to that described in
Fedora bug <a href="https://bugzilla.redhat.com/show_bug.cgi?id=851970">851970</a>, which was closed two years ago.</p><p><strong>Update</strong> I wrote a <a href=https://blog.oddbit.com/posts/docker-vs-privatetmp/>separate post</a> about this issue, which
includes some discussion about what&rsquo;s going on and a solution.</p><hr><p>If we activate this service&mldr;</p><pre><code># systemctl enable docker-openvswitch-agent
# systemctl start docker-openvswitch-agent
</code></pre><p>&mldr;and then run <code>neutron agent-list</code> with administrative credentials,
we&rsquo;ll see the new agent:</p><pre><code>$ neutron agent-list
+--------------------------------------+--------------------+------------------+-------+...
| id                                   | agent_type         | host             | alive |...
+--------------------------------------+--------------------+------------------+-------+...
| 2e40062a-1c30-46a3-8719-3ce93a56b4ce | Open vSwitch agent | nova-docker      | :-)   |...
| 63edb2a4-f980-4f88-b9c0-9610a1b20f13 | L3 agent           | host.example.com | :-)   |...
| 8482c5c3-208c-4145-9f7d-606be3da11ed | Loadbalancer agent | host.example.com | :-)   |...
| 9922ed54-00fa-41d4-96e8-ac8af8c291fd | Open vSwitch agent | host.example.com | :-)   |...
| b8becb9c-7290-42be-9faf-fd3baeea3dcf | Metadata agent     | host.example.com | :-)   |...
| c46be41b-e93a-40ab-a37e-4d67b770a3df | DHCP agent         | host.example.com | :-)   |...
+--------------------------------------+--------------------+------------------+-------+...
</code></pre><h2 id=booting-a-docker-container-take-2>Booting a Docker container (take 2)<a href=#booting-a-docker-container-take-2 class=hanchor arialabel=Anchor>&#8983;</a></h2><p>Now that we have both the <code>nova-docker</code> service running and a
corresponding <code>neutron-openvswitch-agent</code> available, let&rsquo;s try
starting our container one more time:</p><pre><code>$ nova boot --image larsks/thttpd --flavor m1.small test1
$ nova list
+--------------------------------------+---------+--------+...
| ID                                   | Name    | Status |...
+--------------------------------------+---------+--------+...
| 642b7d61-9189-40ea-86f5-2424c3c86028 | test1   | ACTIVE |...
+--------------------------------------+---------+--------+...
</code></pre><p>If we assign a floating IP address:</p><pre><code>$ nova floating-ip-create ext-nat
+-----------------+-----------+----------+---------+
| Ip              | Server Id | Fixed Ip | Pool    |
+-----------------+-----------+----------+---------+
| 192.168.200.211 | -         | -        | ext-nat |
+-----------------+-----------+----------+---------+
$ nova floating-ip-associate test1 192.168.200.211
</code></pre><p>We can then browse to <code>http://192.168.200.211</code> and see the sample
page:</p><pre><code>$ curl http://192.168.200.211/
.
.
.
  ____                            _         _       _   _                 
 / ___|___  _ __   __ _ _ __ __ _| |_ _   _| | __ _| |_(_) ___  _ __  ___ 
| |   / _ \| '_ \ / _` | '__/ _` | __| | | | |/ _` | __| |/ _ \| '_ \/ __|
| |__| (_) | | | | (_| | | | (_| | |_| |_| | | (_| | |_| | (_) | | | \__ \
 \____\___/|_| |_|\__, |_|  \__,_|\__|\__,_|_|\__,_|\__|_|\___/|_| |_|___/
                  |___/                                                   
.
.
.
</code></pre><h2 id=booting-a-libvirt-instance>Booting a libvirt instance<a href=#booting-a-libvirt-instance class=hanchor arialabel=Anchor>&#8983;</a></h2><p>To show that we really are running two hypervisors on the same host,
we can launch a traditional <code>libvirt</code> instance alongside our Docker
container:</p><pre><code>$ nova boot --image cirros --flavor m1.small --key-name lars test2
</code></pre><p>Wait a bit, then:</p><pre><code>$ nova list
+--------------------------------------+-------+--------+...
| ID                                   | Name  | Status |...
+--------------------------------------+-------+--------+...
| 642b7d61-9189-40ea-86f5-2424c3c86028 | test1 | ACTIVE |...
| 7fec33c9-d50f-477e-957c-a05ee9bd0b0b | test2 | ACTIVE |...
+--------------------------------------+-------+--------+...</code></pre></div></div><script src=https://utteranc.es/client.js repo=larsks/blog.oddbit.com issue-term=pathname label=comment theme=github-light crossorigin=anonymous async></script></article></div><footer class=footer><div class=footer__inner><div class="copyright copyright--user"><span>Lars Kellogg-Stedman</span>
<span>:: <a href=https://github.com/panr/hugo-theme-terminal target=_blank>Theme</a> made by <a href=https://github.com/panr target=_blank>panr</a></span></div></div></footer><script type=text/javascript src=/bundle.min.js></script></div></body></html>