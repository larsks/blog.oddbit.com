<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Systemd on blog.oddbit.com</title><link>https://blog.oddbit.com/tags/systemd/</link><description>Recent content in Systemd on blog.oddbit.com</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Lars Kellogg-Stedman</copyright><lastBuildDate>Mon, 08 Feb 2016 00:00:00 +0000</lastBuildDate><atom:link href="https://blog.oddbit.com/tags/systemd/rss.xml" rel="self" type="application/rss+xml"/><item><title>A systemd-nspawn connection driver for Ansible</title><link>https://blog.oddbit.com/post/2016-02-08-a-systemd-nspawn-connection-dr/</link><pubDate>Mon, 08 Feb 2016 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2016-02-08-a-systemd-nspawn-connection-dr/</guid><description>I wrote earlier about systemd-nspawn, and how it can take much of the fiddly work out of setting up functional chroot environments. I&amp;rsquo;m a regular Ansible user, and I wanted to be able to apply some of those techniques to my playbooks.
Ansible already has a chroot module, of course, but for some situations &amp;ndash; such as targeting an emulated chroot environment &amp;ndash; that just means a lot of extra work.</description><content>&lt;p>I wrote &lt;a href="https://blog.oddbit.com/post/2016-02-07-systemd-nspawn-for-fun-and-wel/">earlier&lt;/a> about &lt;a href="https://www.freedesktop.org/software/systemd/man/systemd-nspawn.html">systemd-nspawn&lt;/a>, and how it can take much
of the fiddly work out of setting up functional &lt;code>chroot&lt;/code> environments.
I&amp;rsquo;m a regular &lt;a href="http://ansible.com/">Ansible&lt;/a> user, and I wanted to be able to apply some
of those techniques to my playbooks.&lt;/p>
&lt;p>Ansible already has a &lt;code>chroot&lt;/code> module, of course, but for some
situations &amp;ndash; such as targeting an emulated &lt;code>chroot&lt;/code> environment &amp;ndash;
that just means a lot of extra work. Using &lt;code>systemd-nspawn&lt;/code> makes
this trivial.&lt;/p>
&lt;p>I&amp;rsquo;ve submitted
&lt;a href="https://github.com/ansible/ansible/pull/14334" class="pull-request">#14334&lt;/a>
to the Ansible project,
which introduces a new connection driver named &lt;code>nspawn&lt;/code>. It acts very
much like the &lt;code>chroot&lt;/code> driver, but it adds a few new configuration
options:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>ansible_nspawn_args&lt;/code> &amp;ndash; analagous to &lt;code>ansible_ssh_args&lt;/code>, setting
this will override the arguments that are passed to &lt;code>systemd-nspawn&lt;/code>
by default.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>ansible_nspawn_extra_args&lt;/code> &amp;ndash; analgous to &lt;code>ansible_ssh_extra_args&lt;/code>,
setting this will &lt;em>append&lt;/em> the values to the default
&lt;code>systemd-nspawn&lt;/code> command line.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="advantages-over-chroot">Advantages over chroot&lt;/h2>
&lt;p>Let&amp;rsquo;s say we had a Fedora filesystem mounted on &lt;code>/fedora&lt;/code> and we want
to run the following playbook:&lt;/p>
&lt;pre>&lt;code>- hosts: /fedora
tasks:
- raw: dnf -y install python libselinux-python python2-dnf
- dnf:
name: git
state: installed
&lt;/code>&lt;/pre>
&lt;p>Using the &lt;code>chroot&lt;/code> driver, we get:&lt;/p>
&lt;pre>&lt;code>$ sudo ansible-playbook -i /fedora, -c chroot playbook.yml
PLAY ***************************************************************************
TASK [raw] *********************************************************************
fatal: [/fedora]: FAILED! =&amp;gt; {&amp;quot;changed&amp;quot;: false, &amp;quot;failed&amp;quot;: true, &amp;quot;rc&amp;quot;: -6, &amp;quot;stderr&amp;quot;: &amp;quot;Fatal Python error: Failed to open /dev/urandom\n&amp;quot;, &amp;quot;stdout&amp;quot;: &amp;quot;&amp;quot;, &amp;quot;stdout_lines&amp;quot;: []}
&lt;/code>&lt;/pre>
&lt;p>Adding the necessary tasks to our playbook to set up the chroot
environment properly will add a lot of additional complexity and will
make the playbook substantially less generic. Now compare that to the
result of running the same playbook using the &lt;code>nspawn&lt;/code> driver:&lt;/p>
&lt;pre>&lt;code>$ sudo ansible-playbook -i /fedora, -c nspawn playbook.yml
PLAY ***************************************************************************
TASK [raw] *********************************************************************
ok: [/fedora]
TASK [dnf] *********************************************************************
changed: [/fedora]
PLAY RECAP *********************************************************************
/fedora : ok=2 changed=1 unreachable=0 failed=0
&lt;/code>&lt;/pre>
&lt;h2 id="ansible-in-emulation">Ansible in emulation&lt;/h2>
&lt;p>By taking advantage of &lt;code>ansible_nspawn_extra_args&lt;/code> you can create
more complex containers. For example, in my &lt;a href="https://blog.oddbit.com/post/2016-02-07-systemd-nspawn-for-fun-and-wel/">last post&lt;/a> on
&lt;code>systemd-nspawn&lt;/code> I showed how to start a container for a different
architecture through the use of QEMU user-mode emulation. We can
apply the same idea to Ansible with an inventory entry like this:&lt;/p>
&lt;pre>&lt;code>target
ansible_host=/fedora
ansible_connection=nspawn
ansible_nspawn_extra_args=&amp;quot;--bind /usr/bin/qemu-arm&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>The above will allow you to run a playbook against a filesystem
containing ARM architecture binaries, even though you&amp;rsquo;re running on an
x86_64 host.&lt;/p></content></item><item><title>Systemd-nspawn for fun and...well, mostly for fun</title><link>https://blog.oddbit.com/post/2016-02-07-systemd-nspawn-for-fun-and-wel/</link><pubDate>Sun, 07 Feb 2016 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2016-02-07-systemd-nspawn-for-fun-and-wel/</guid><description>systemd-nspawn has been called &amp;ldquo;chroot on steroids&amp;rdquo;, but if you think of it as Docker with a slightly different target you wouldn&amp;rsquo;t be far wrong, either. It can be used to spawn containers on your host, and has a variety of options for configuring the containerized environment through the use of private networking, bind mounts, capability controls, and a variety of other facilities that give you flexible container management.
There are many different ways in which it can be used.</description><content>&lt;p>&lt;code>systemd-nspawn&lt;/code> has been called &lt;a href="https://wiki.archlinux.org/index.php/Systemd-nspawn">&amp;ldquo;chroot on steroids&amp;rdquo;&lt;/a>,
but if you think of it as &lt;a href="http://docker.com">Docker&lt;/a> with a slightly different target
you wouldn&amp;rsquo;t be far wrong, either. It can be used to spawn containers
on your host, and has a variety of options for configuring the
containerized environment through the use of private networking, bind
mounts, capability controls, and a variety of other facilities that
give you flexible container management.&lt;/p>
&lt;p>There are many different ways in which it can be used. I&amp;rsquo;m going to
focus on one that&amp;rsquo;s a bit of a corner use case that I find
particularly interesting. In this article we&amp;rsquo;re going to explore how
we can use &lt;a href="https://www.freedesktop.org/software/systemd/man/systemd-nspawn.html">systemd-nspawn&lt;/a> to spawn lightweight containers for
architectures other than that of our host system.&lt;/p>
&lt;h2 id="why-systemd-nspawn">Why systemd-nspawn?&lt;/h2>
&lt;p>While everything described in this article could be accomplished
through the use of &lt;code>chroot&lt;/code> and a chunk of additional configuration,
using &lt;code>systemd-nspawn&lt;/code> makes it much easier. For example,
&lt;code>systemd-nspawn&lt;/code> takes care of making virtual filesystems like
&lt;code>/proc&lt;/code>, &lt;code>/sys&lt;/code>, and a minimal &lt;code>/dev&lt;/code> available inside the container
(without which some programs simply won&amp;rsquo;t work). And of course
&lt;code>systemd-nspawn&lt;/code> takes care of cleaning up these mounts when the
container exits. For a simple container, this:&lt;/p>
&lt;pre>&lt;code># systemd-nspawn -D /mnt /some/command
&lt;/code>&lt;/pre>
&lt;p>Is roughly equivalent to:&lt;/p>
&lt;pre>&lt;code># mount -o bind /proc /mnt/proc
# mount -o bind /sys /mnt/sys
# mount -t tmpfs tmpfs /mnt/run
# mount -t tmpfs tmpfs /mnt/dev
# ...populate /mnt/dev here...
# chroot /mnt /some/command
# umount /mnt/dev
# umount /mnt/run
# umount /mnt/sys
# umount /mnt/proc
&lt;/code>&lt;/pre>
&lt;p>&lt;code>systemd-nspawn&lt;/code> does all of this for us, and does much of it via
private mount namespaces so that the temporary filesystems aren&amp;rsquo;t
visible from the host.&lt;/p>
&lt;h2 id="in-which-we-perform-magic">In which we perform magic&lt;/h2>
&lt;p>Linux allows you to run binaries intended for other architectures
via the &lt;a href="https://www.kernel.org/doc/Documentation/binfmt_misc.txt">binfmt-misc&lt;/a> subsystem, which allows you to use bits at the
beginning of a file to match against an appropriate interpreter. This
can be used, for example, to make Java binaries directly executable.
We&amp;rsquo;re going to use this technique to accomplish the following:&lt;/p>
&lt;ul>
&lt;li>Teach our system how to run Raspberry Pi ARM binaries, and&lt;/li>
&lt;li>Allow us to spawn a &lt;code>systemd-nspawn&lt;/code> container into a Raspberry Pi
filesystem.&lt;/li>
&lt;/ul>
&lt;p>When a &lt;code>systemd&lt;/code>-based system boots, the &lt;a href="https://www.freedesktop.org/software/systemd/man/binfmt.d.html">systemd-binfmt&lt;/a> service
(if it&amp;rsquo;s enabled) will automatically register configurations found in
&lt;code>/etc/binfmt.d&lt;/code> or &lt;code>/usr/lib/binfmt.d&lt;/code>. You can set these up by hand,
of course, but we&amp;rsquo;re going to take the easy route and install the
&lt;code>qemu-user-static&lt;/code> package, which includes both the necessary &lt;code>binfmt.d&lt;/code>
configuration files as well as the associated emulators:&lt;/p>
&lt;pre>&lt;code># dnf -y install qemu-user-static
&lt;/code>&lt;/pre>
&lt;p>The &lt;code>qemu-user-static&lt;/code> package on my system has installed, among other files,
&lt;code>/usr/lib/binfmt.d/qemu-arm.conf&lt;/code>, which looks like this:&lt;/p>
&lt;pre>&lt;code>:qemu-arm:M::\x7fELF\x01\x01\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x00\x28\x00:\xff\xff\xff\xff\xff\xff\xff\x00\xff\xff\xff\xff\xff\xff\xff\xff\xfe\xff\xff\xff:/usr/bin/qemu-arm-static:
&lt;/code>&lt;/pre>
&lt;p>This gets registered with &lt;code>/proc/sys/fs/binfmt_misc/register&lt;/code> and
informs the kernel that there is a new binfmt called &lt;code>qemu-arm&lt;/code>, and
that files that contain the specified byte pattern in the header
should be handled with &lt;code>/usr/bin/qemu-arm-static&lt;/code>.&lt;/p>
&lt;p>With all this set up, we can mount a Raspberry Pi filesystem (I&amp;rsquo;m
starting with &lt;a href="https://minibianpi.wordpress.com/">minibian&lt;/a>)&amp;hellip;&lt;/p>
&lt;pre>&lt;code># tar xf 2015-11-12-jessie-minibian.tar.gz
# losetup -fP --show 2015-11-12-jessie-minibian.img
/dev/loop1
# mount /dev/loop1p2 /mnt
# mount /dev/loop1p1 /mnt/boot
&lt;/code>&lt;/pre>
&lt;p>&amp;hellip;and then start up a process in it:&lt;/p>
&lt;pre>&lt;code># systemd-nspawn -D /mnt
Spawning container mnt on /mnt.
Press ^] three times within 1s to kill container.
root@mnt:~#
&lt;/code>&lt;/pre>
&lt;p>And there we are! We&amp;rsquo;re now running a shell inside a container
running an ARM userspace. We can modify the image by installing or
udpating packages or making any other necessary configuration changes:&lt;/p>
&lt;pre>&lt;code>root@mnt:/# apt-get install raspberrypi-bootloader
Reading package lists... Done
Building dependency tree
Reading state information... Done
The following extra packages will be installed:
libraspberrypi-bin libraspberrypi0
The following packages will be upgraded:
libraspberrypi-bin libraspberrypi0 raspberrypi-bootloader
3 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.
Need to get 32.5 MB of archives.
After this operation, 827 kB of additional disk space will be used.
Do you want to continue? [Y/n]
&lt;/code>&lt;/pre>
&lt;p>When we&amp;rsquo;re done, we exit our container:&lt;/p>
&lt;pre>&lt;code>root#mnt:/# exit
&lt;/code>&lt;/pre>
&lt;p>Unmount the directory:o&lt;/p>
&lt;pre>&lt;code># umount /mnt
&lt;/code>&lt;/pre>
&lt;p>And finally clean up the loopback device:&lt;/p>
&lt;pre>&lt;code># losetup -d /dev/loop1
&lt;/code>&lt;/pre>
&lt;p>Now we have an updated image file that we can write to an SD card and
use to boot our Raspberry Pi.&lt;/p>
&lt;p>&lt;strong>NB&lt;/strong> You&amp;rsquo;ll note that in this document I&amp;rsquo;m mounting &lt;code>loop1p2&lt;/code> on &lt;code>/&lt;/code>
and &lt;code>loop1p1&lt;/code> on &lt;code>/boot&lt;/code>. You obviously don&amp;rsquo;t need &lt;code>/boot&lt;/code> in your
container in order for things to run, but you will regret not mounting
it if you happen to install an updated kernel package, which needs to
populate &lt;code>/boot&lt;/code> with the new kernel image.&lt;/p>
&lt;h2 id="bonus-growing-the-image">Bonus: growing the image&lt;/h2>
&lt;p>The stock &lt;a href="https://minibianpi.wordpress.com/">minibian&lt;/a> image doesn&amp;rsquo;t have much free space on it; this
is intentional, and in general you&amp;rsquo;re expected to grow the root
partition and resize the filesystem after booting on your Pi.
However, if we&amp;rsquo;re going to use the above process to pre-configure our
image, there&amp;rsquo;s a good chance we&amp;rsquo;ll need more space immediately. We
start by growing the size of the image file itself; you can that with
&lt;code>qemu-img&lt;/code>, like this:&lt;/p>
&lt;pre>&lt;code># qemu-img resize 2015-11-12-jessie-minibian.img 2G
&lt;/code>&lt;/pre>
&lt;p>Or by using &lt;code>truncate&lt;/code>:&lt;/p>
&lt;pre>&lt;code># truncate -s 2G 2015-11-12-jessie-minibian.img
&lt;/code>&lt;/pre>
&lt;p>Or by using &lt;code>dd&lt;/code>:&lt;/p>
&lt;pre>&lt;code># dd of=2015-11-12-jessie-minibian.img if=/dev/zero \
count=0 bs=1G seek=2
&lt;/code>&lt;/pre>
&lt;p>Once the file has been extended, we need to grow the corresponding
partition. Assuming that you have a recent version of &lt;code>util-linux&lt;/code>
(where &amp;ldquo;recent&amp;rdquo; means &amp;ldquo;at least &lt;a href="http://karelzak.blogspot.com/2015/05/resize-by-sfdisk.html">v2.26.2&lt;/a>) installed, this is easy:&lt;/p>
&lt;pre>&lt;code># echo &amp;quot;, +&amp;quot; | sfdisk -N 2 2015-11-12-jessie-minibian.img
&lt;/code>&lt;/pre>
&lt;p>And lastly, we need to grow the filesystem. This requires
attaching the image to a loop device:&lt;/p>
&lt;pre>&lt;code># losetup -fP --show 2015-11-12-jessie-minibian.img
/dev/loop1
&lt;/code>&lt;/pre>
&lt;p>And then:&lt;/p>
&lt;pre>&lt;code># e2fsck -f /dev/loop1p2
# resize2fs /dev/loop1p2
&lt;/code>&lt;/pre>
&lt;p>Now when we mount the filesystem:&lt;/p>
&lt;pre>&lt;code># mount /dev/loop1p2 /mnt
# mount /dev/loop1p1 /mnt/boot
&lt;/code>&lt;/pre>
&lt;p>We see that there is more space available:&lt;/p>
&lt;pre>&lt;code># df -h /mnt
Filesystem Size Used Avail Use% Mounted on
/dev/loop1p2 1.9G 432M 1.4G 24% /mnt
&lt;/code>&lt;/pre>
&lt;h2 id="bonus-static-qemu-arm-binaries">Bonus: Static qemu-arm binaries&lt;/h2>
&lt;p>Earlier we saw that it was necessary to mount &lt;code>/lib64&lt;/code> into my
Raspberry Pi container because the &lt;code>qemu-arm&lt;/code> binary was dynamically
linked. You can acquire statically built versions of the QEMU
binaries from the Debian project, e.g., &lt;a href="https://packages.debian.org/sid/amd64/qemu-user-static/download">here&lt;/a>:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://packages.debian.org/sid/amd64/qemu-user-static/download">https://packages.debian.org/sid/amd64/qemu-user-static/download&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Then unpack the &lt;code>.deb&lt;/code> file and extract the &lt;code>qemu-arm-static&lt;/code> binary:&lt;/p>
&lt;pre>&lt;code>$ ar xv qemu-user-static_2.5+dfsg-5_amd64.deb
x - debian-binary
x - control.tar.gz
x - data.tar.xz
$ tar xf data.tar.xz ./usr/bin/qemu-arm-static
&lt;/code>&lt;/pre>
&lt;p>And copy it into place:&lt;/p>
&lt;pre>&lt;code># cp qemu-arm-static /usr/bin/qemu-arm
&lt;/code>&lt;/pre>
&lt;p>And now our earlier command will work without further modification:&lt;/p>
&lt;pre>&lt;code># systemd-nspawn -q --bind /usr/bin/qemu-arm -D /mnt /bin/bash
root@mnt:/#
&lt;/code>&lt;/pre></content></item><item><title>Docker vs. PrivateTmp</title><link>https://blog.oddbit.com/post/2015-01-18-docker-vs-privatetmp/</link><pubDate>Sun, 18 Jan 2015 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2015-01-18-docker-vs-privatetmp/</guid><description>While working with Docker the other day, I ran into an undesirable interaction between Docker and systemd services that utilize the PrivateTmp directive.
The PrivateTmp directive, if true, &amp;ldquo;sets up a new file system namespace for the executed processes and mounts private /tmp and /var/tmp directories inside it that is not shared by processes outside of the namespace&amp;rdquo;. This is a great idea from a security perspective, but can cause some unanticipated consequences.</description><content>&lt;p>While working with Docker &lt;a href="https://blog.oddbit.com/post/2015-01-17-running-novalibvirt-and-novado/">the other day&lt;/a>, I ran into an
undesirable interaction between Docker and &lt;a href="http://www.freedesktop.org/wiki/Software/systemd/">systemd&lt;/a> services that
utilize the &lt;code>PrivateTmp&lt;/code> directive.&lt;/p>
&lt;p>The &lt;a href="http://www.freedesktop.org/software/systemd/man/systemd.exec.html#PrivateTmp=">PrivateTmp&lt;/a> directive, if &lt;code>true&lt;/code>, &amp;ldquo;sets up a new file system
namespace for the executed processes and mounts private &lt;code>/tmp&lt;/code> and
&lt;code>/var/tmp&lt;/code> directories inside it that is not shared by processes outside
of the namespace&amp;rdquo;. This is a great idea from a &lt;a href="https://danwalsh.livejournal.com/51459.html">security
perspective&lt;/a>, but can cause some unanticipated consequences.&lt;/p>
&lt;h2 id="the-problem-in-a-nutshell">The problem in a nutshell&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>Start a Docker container:&lt;/p>
&lt;pre>&lt;code> # cid=$(docker run -d larsks/thttpd)
# echo $cid
e68df3f45d6151259ce84a0e467a3117840084e99ef3bbc654b33f08d2d6dd62
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>See the &lt;code>devicemapper&lt;/code> mountpoint created by Docker for the
container:&lt;/p>
&lt;pre>&lt;code> # grep devicemapper/mnt /proc/mounts
/dev/mapper/docker-253:6-98310-e68df3f45d6151259ce84a0e467a3117840084e99ef3bbc654b33f08d2d6dd62 /var/lib/docker/devicemapper/mnt/e68df3f45d6151259ce84a0e467a3117840084e99ef3bbc654b33f08d2d6dd62 ext4 rw,context=&amp;quot;system_u:object_r:svirt_sandbox_file_t:s0:c261,c1018&amp;quot;,relatime,discard,stripe=16,data=ordered 0 0
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>Now restart a service &amp;ndash; any service! &amp;ndash; that has
&lt;code>PrivateTmp=true&lt;/code>:&lt;/p>
&lt;pre>&lt;code> # systemctl restart systemd-machined
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>Get the PID for that service:&lt;/p>
&lt;pre>&lt;code> # systemctl status systemd-machined | grep PID
Main PID: 18698 (systemd-machine
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>And see that the mount created by the Docker &amp;ldquo;devicemapper&amp;rdquo; storage
driver is visible inside the mount namespace for this process:&lt;/p>
&lt;pre>&lt;code> # grep devicemapper/mnt /proc/18698/mounts
/dev/mapper/docker-253:6-98310-e68df3f45d6151259ce84a0e467a3117840084e99ef3bbc654b33f08d2d6dd62 /var/lib/docker/devicemapper/mnt/e68df3f45d6151259ce84a0e467a3117840084e99ef3bbc654b33f08d2d6dd62 ext4 rw,context=&amp;quot;system_u:object_r:svirt_sandbox_file_t:s0:c261,c1018&amp;quot;,relatime,discard,stripe=16,data=ordered 0 0
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>Attempt to destroy the container:&lt;/p>
&lt;pre>&lt;code> # docker rm -f $cid
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>Watch Docker fail to destroy the container because it is unable to
remove the mountpoint directory:&lt;/p>
&lt;pre>&lt;code> Jan 17 22:43:03 pk115wp-lkellogg docker-1.4.1-dev[18239]:
time=&amp;quot;2015-01-17T22:43:03-05:00&amp;quot; level=&amp;quot;error&amp;quot; msg=&amp;quot;Handler for DELETE
/containers/{name:.*} returned error: Cannot destroy container e68df3f45d61:
Driver devicemapper failed to remove root filesystem
e68df3f45d6151259ce84a0e467a3117840084e99ef3bbc654b33f08d2d6dd62: Device is
Busy&amp;quot;
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>Because while that mount is gone from the global namespace:&lt;/p>
&lt;pre>&lt;code> # grep devicemapper/mnt /proc/mounts
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>It still exists inside the mount namespace for the service we restarted:&lt;/p>
&lt;pre>&lt;code># grep devicemapper/mnt /proc/18698/mounts
/dev/mapper/docker-253:6-98310-e68df3f45d6151259ce84a0e467a3117840084e99ef3bbc654b33f08d2d6dd62 /var/lib/docker/devicemapper/mnt/e68df3f45d6151259ce84a0e467a3117840084e99ef3bbc654b33f08d2d6dd62 ext4 rw,context=&amp;quot;system_u:object_r:svirt_sandbox_file_t:s0:c261,c1018&amp;quot;,relatime,discard,stripe=16,data=ordered 0 0
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>To resolve this problem, restart the service holding the mount open:&lt;/p>
&lt;pre>&lt;code># systemctl restart systemd-machined
&lt;/code>&lt;/pre>
&lt;/li>
&lt;/ol>
&lt;p>Now the mountpoint can be deleted.&lt;/p>
&lt;h2 id="its-not-just-docker">It&amp;rsquo;s not just Docker&lt;/h2>
&lt;p>While I ran into this problem while working with Docker, there is
nothing particularly Docker-specific about the problem. You can
replicate this behavior by hand without involving either &lt;code>systemd&lt;/code> or
Docker:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Create a parent mountpoint, and make it private:&lt;/p>
&lt;pre>&lt;code> # mkdir /tmp/parent /tmp/parent-backing
# mount --bind --make-private /tmp/parent-backing /tmp/parent
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>Create a private mount on a directory &lt;em>inside&lt;/em> &lt;code>/tmp/parent&lt;/code>:&lt;/p>
&lt;pre>&lt;code> # mkdir /tmp/testmount /tmp/parent/mnt
# mount --bind --make-private /tmp/testmount /tmp/parent/mnt
# grep /tmp/parent/mnt /proc/self/mounts
tmpfs /tmp/parent/mnt tmpfs rw,seclabel 0 0
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>In another window, create a new mount namespace using &lt;code>unshare&lt;/code>:&lt;/p>
&lt;pre>&lt;code> # unshare -m env PS1='unshare# ' bash
unshare#
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>Unmount &lt;code>/tmp/parent/mnt&lt;/code> in the global namespace:&lt;/p>
&lt;pre>&lt;code> # umount /tmp/parent/mnt
# grep /tmp/parent/mnt /proc/self/mounts
#
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>Try to delete the mountpoint directory:&lt;/p>
&lt;pre>&lt;code> # rmdir /tmp/parent/mnt
rmdir: failed to remove ‘/tmp/parent/mnt’: Device or resource busy
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>See that the mount still exists in your &lt;code>unshare&lt;/code> namespace:&lt;/p>
&lt;pre>&lt;code> unshare# grep /tmp/parent/mnt /proc/self/mounts
tmpfs /tmp/parent/mnt tmpfs rw,seclabel 0 0
&lt;/code>&lt;/pre>
&lt;/li>
&lt;/ol>
&lt;h2 id="so-whats-going-on-here">So what&amp;rsquo;s going on here?&lt;/h2>
&lt;p>To understand what&amp;rsquo;s going on in these examples, you probably want to
start by at least glancing through the &lt;a href="https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt">sharedsubtree.txt&lt;/a> kernel
documentation.&lt;/p>
&lt;p>The Docker &lt;code>devicemapper&lt;/code> driver creates a &lt;em>private&lt;/em> mount on
&lt;code>/var/lib/docker/devicemapper&lt;/code>. A &lt;em>private&lt;/em> mount is one that does
not propagate mount operations between parent and child mount
namespaces.&lt;/p>
&lt;p>Container filesystems are mounted underneath
&lt;code>/var/lib/docker/devicemapper/mnt&lt;/code>, e.g:&lt;/p>
&lt;pre>&lt;code> /dev/mapper/docker-253:6-98310-e68df3f45d6151259ce84a0e467a3117840084e99ef3bbc654b33f08d2d6dd62 /var/lib/docker/devicemapper/mnt/e68df3f45d6151259ce84a0e467a3117840084e99ef3bbc654b33f08d2d6dd62 ext4 rw,context=&amp;quot;system_u:object_r:svirt_sandbox_file_t:s0:c261,c1018&amp;quot;,relatime,discard,stripe=16,data=ordered 0 0
&lt;/code>&lt;/pre>
&lt;p>When you create a new mount namespace as a child of the global mount
namespace, either via the &lt;code>unshare&lt;/code> command or by starting a systemd
service with &lt;code>PrivateTmp=true&lt;/code>, it inherits these private mounts.
When Docker unmounts the the container filesystem in the global
namespace, the fact that the &lt;code>/var/lib/docker/devicemapper&lt;/code> mountpoint
is marked &lt;em>private&lt;/em> means that the unmount operation does not
propagate to other namespaces.&lt;/p>
&lt;h2 id="the-solution">The solution&lt;/h2>
&lt;p>The simplest solution to this problem is to set the &lt;code>MountFlags=slave&lt;/code>
option in the &lt;code>docker.service&lt;/code> file:&lt;/p>
&lt;pre>&lt;code>MountFlags=slave
&lt;/code>&lt;/pre>
&lt;p>This will cause SystemD to run Docker in a cloned mount namespace and
sets the &lt;code>MS_SLAVE&lt;/code> flag on all mountpoints; it is effectively
equivalent to:&lt;/p>
&lt;pre>&lt;code># unshare -m
# mount --make-rslave /
&lt;/code>&lt;/pre>
&lt;p>With this change, mounts performed by Docker will not be visible in
the global mount namespace, and they will thus not propagate into the
mount namespaces of other services.&lt;/p>
&lt;h2 id="not-necessarily-the-solution">Not necessarily the solution&lt;/h2>
&lt;p>There was an &lt;a href="http://pkgs.fedoraproject.org/cgit/docker-io.git/commit/?id=6c9e373ee06cb1aee07d3cae426c46002663010d">attempt to fix this problem&lt;/a> committed to the Fedora
&lt;code>docker-io&lt;/code> package that set &lt;code>MountFlags=private&lt;/code>. This will prevent
the symptoms I originally encountered, in which Docker is unable to
remove a mountpoint because it is still held open by another mount
namespace&amp;hellip;&lt;/p>
&lt;p>&amp;hellip;but it will result in behavior that might be confusing to a system
administrator. Specifically, mounts made in the global mount
namespace after Docker starts will not be visible to Docker
containers. This means that if you were to make a remote filesystem
available on your Docker host:&lt;/p>
&lt;pre>&lt;code># mount my-fileserver:/vol/webcontent /srv/content
&lt;/code>&lt;/pre>
&lt;p>And then attempt to bind that into a Docker container as a volume:&lt;/p>
&lt;pre>&lt;code># docker run -v /srv/content:/content larsks/thttpd -d /content
&lt;/code>&lt;/pre>
&lt;p>Your content would not be visible. The mount of
&lt;code>my-fileserver:/vol/webcontent&lt;/code> would not propagate from the global
namespace into the Docker mount namespace because of the &lt;em>private&lt;/em>
flag.&lt;/p>
&lt;h2 id="thanks">Thanks&lt;/h2>
&lt;p>I had some help figuring this out. Thanks to &lt;a href="https://en.wikipedia.org/wiki/Lennart_Poettering">Lennart Poettering&lt;/a>,
Andrey Borzenkov, and &lt;a href="http://blog.verbum.org/">Colin Walters&lt;/a>.&lt;/p></content></item><item><title>Starting systemd services without blocking</title><link>https://blog.oddbit.com/post/2014-12-02-starting-systemd-services-with/</link><pubDate>Tue, 02 Dec 2014 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2014-12-02-starting-systemd-services-with/</guid><description>Recently, I&amp;rsquo;ve been playing around with Fedora Atomic and Kubernetes. I ran into a frustrating problem in which I would attempt to start a service from within a script launched by cloud-init, only to have have systemctl block indefinitely because the service I was attempting to start was dependent on cloud-init finishing first.
It turns out that systemctl has a flag meant exactly for this situation:
--no-block Do not synchronously wait for the requested operation to finish.</description><content>&lt;p>Recently, I&amp;rsquo;ve been playing around with &lt;a href="https://blog.oddbit.com/post/2014-11-24-fedora-atomic-openstack-and-ku/">Fedora Atomic and
Kubernetes&lt;/a>. I ran into a frustrating problem in which I
would attempt to start a service from within a script launched by
&lt;a href="http://cloudinit.readthedocs.org/">cloud-init&lt;/a>, only to have have &lt;code>systemctl&lt;/code> block indefinitely
because the service I was attempting to start was dependent on
&lt;code>cloud-init&lt;/code> finishing first.&lt;/p>
&lt;p>It turns out that &lt;code>systemctl&lt;/code> has a flag meant exactly for this
situation:&lt;/p>
&lt;pre>&lt;code> --no-block
Do not synchronously wait for the requested operation to finish. If
this is not specified, the job will be verified, enqueued and
systemctl will wait until it is completed. By passing this
argument, it is only verified and enqueued.
&lt;/code>&lt;/pre>
&lt;p>Replacing &lt;code>systemctl start &amp;lt;service&amp;gt;&lt;/code> with &lt;code>systemctl start --no-block &amp;lt;service&amp;gt;&lt;/code> has solved that particular problem.&lt;/p></content></item><item><title>Private /tmp directories in Fedora</title><link>https://blog.oddbit.com/post/2012-11-05-fedora-private-tmp/</link><pubDate>Mon, 05 Nov 2012 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2012-11-05-fedora-private-tmp/</guid><description>I ran into an odd problem the other day: I was testing out some configuration changes for a web application by dropping files into /tmp and pointing the application configuration at the appropriate directory. Everything worked out great when testing it by hand&amp;hellip;but when starting up the httpd service, the application behaved as if it was unable to find any of the files in /tmp.
My first assumption was that had simply missed something obvious like file permissions or that I had a typo in my configuration, but after repeated checks and lots of testing it was obvious that something else was going on.</description><content>&lt;p>I ran into an odd problem the other day: I was testing out some
configuration changes for a web application by dropping files into
&lt;code>/tmp&lt;/code> and pointing the application configuration at the appropriate
directory. Everything worked out great when testing it by hand&amp;hellip;but
when starting up the &lt;code>httpd&lt;/code> service, the application behaved as if it
was unable to find any of the files in &lt;code>/tmp&lt;/code>.&lt;/p>
&lt;p>My first assumption was that had simply missed something obvious like
file permissions or that I had a typo in my configuration, but after
repeated checks and lots of testing it was obvious that something else
was going on.&lt;/p>
&lt;p>Grasping at straws I took a close look at the &lt;code>systemd&lt;/code> service file
for &lt;code>httpd&lt;/code>, which looks like this:&lt;/p>
&lt;pre>&lt;code>[Unit]
Description=The Apache HTTP Server (prefork MPM)
After=syslog.target network.target remote-fs.target nss-lookup.target
[Service]
Type=forking
PIDFile=/var/run/httpd/httpd.pid
EnvironmentFile=/etc/sysconfig/httpd
ExecStart=/usr/sbin/httpd $OPTIONS -k start
ExecReload=/usr/sbin/httpd $OPTIONS -t
ExecReload=/bin/kill -HUP $MAINPID
ExecStop=/usr/sbin/httpd $OPTIONS -k stop
PrivateTmp=true
[Install]
WantedBy=multi-user.target
&lt;/code>&lt;/pre>
&lt;p>Browsing throught file the following line caught my eye:&lt;/p>
&lt;pre>&lt;code>PrivateTmp=true
&lt;/code>&lt;/pre>
&lt;p>If you know about per-process namespaces in Linux, you&amp;rsquo;re probably
saying &amp;ldquo;Ah-ha!&amp;rdquo;. If you &lt;em>don&amp;rsquo;t&lt;/em> know about per-process namespaces in
Linux&amp;hellip;you should, because this is the foundation for all sorts of
things including Linux Containers (&lt;a href="http://lxc.sourceforge.net/">LXC&lt;/a>). Here&amp;rsquo;s some good
introductory reading:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="http://lxr.free-electrons.com/source/Documentation/unshare.txt">http://lxr.free-electrons.com/source/Documentation/unshare.txt&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://www.debian-administration.org/article/628/Per-Process_Namespaces">http://www.debian-administration.org/article/628/Per-Process_Namespaces&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://glandium.org/blog/?p=217">http://glandium.org/blog/?p=217&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>In short, with this configuration in place, the service gets it&amp;rsquo;s very
own version of &lt;code>/tmp&lt;/code> not shared with any other process. While the
files I placed in &lt;code>/tmp&lt;/code> were visible in &lt;em>my&lt;/em> process, they didn&amp;rsquo;t
exist from the point of view of Apache.&lt;/p>
&lt;p>The fix in my case was to place the files somewhere other than &lt;code>/tmp&lt;/code>.
One could also disable the &lt;code>PrivateTmp&lt;/code> setting, but it&amp;rsquo;s generally
turned on for reasons of security.&lt;/p>
&lt;p>The &lt;code>PrivateTmp&lt;/code> option is documented in &lt;a href="https://docs.fedoraproject.org/en-US/Fedora/17/html/Release_Notes/sect-Release_Notes-Changes_for_Sysadmin.html">Changes in Fedora for System
Administrators&lt;/a>, and Dan Walsh discusses it briefly on
&lt;a href="http://danwalsh.livejournal.com/51459.html">his blog&lt;/a>.&lt;/p></content></item></channel></rss>