<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Fedora on blog.oddbit.com</title><link>https://blog.oddbit.com/tags/fedora/</link><description>Recent content in Fedora on blog.oddbit.com</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Lars Kellogg-Stedman</copyright><lastBuildDate>Tue, 17 Nov 2015 00:00:00 +0000</lastBuildDate><atom:link href="https://blog.oddbit.com/tags/fedora/rss.xml" rel="self" type="application/rss+xml"/><item><title>Installing pyspatialite on Fedora</title><link>https://blog.oddbit.com/post/2015-11-17-installing-pyspatialite-on-fed/</link><pubDate>Tue, 17 Nov 2015 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2015-11-17-installing-pyspatialite-on-fed/</guid><description>&lt;p>If you should find yourself wanting to install &lt;a href="https://github.com/lokkju/pyspatialite">pyspatialite&lt;/a> on
Fedora &amp;ndash; perhaps because you want to use the &lt;a href="https://plugins.qgis.org/plugins/processing/">Processing plugin&lt;/a>
for &lt;a href="http://www.qgis.org/">QGIS&lt;/a> &amp;ndash; you will first need to install the following
dependencies:&lt;/p>
&lt;ul>
&lt;li>&lt;code>gcc&lt;/code>&lt;/li>
&lt;li>&lt;code>python-devel&lt;/code>&lt;/li>
&lt;li>&lt;code>sqlite-devel&lt;/code>&lt;/li>
&lt;li>&lt;code>geos-devel&lt;/code>&lt;/li>
&lt;li>&lt;code>proj-devel&lt;/code>&lt;/li>
&lt;li>&lt;code>python-pip&lt;/code>&lt;/li>
&lt;li>&lt;code>redhat-rpm-config&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>After which you can install &lt;code>pyspatialite&lt;/code> using &lt;code>pip&lt;/code> by running:&lt;/p>
&lt;pre>&lt;code>CFLAGS=-I/usr/include pip install pyspatialite
&lt;/code>&lt;/pre>
&lt;p>At this point, you should be able to use the &amp;ldquo;Processing&amp;rdquo; plugin.&lt;/p></description><content>&lt;p>If you should find yourself wanting to install &lt;a href="https://github.com/lokkju/pyspatialite">pyspatialite&lt;/a> on
Fedora &amp;ndash; perhaps because you want to use the &lt;a href="https://plugins.qgis.org/plugins/processing/">Processing plugin&lt;/a>
for &lt;a href="http://www.qgis.org/">QGIS&lt;/a> &amp;ndash; you will first need to install the following
dependencies:&lt;/p>
&lt;ul>
&lt;li>&lt;code>gcc&lt;/code>&lt;/li>
&lt;li>&lt;code>python-devel&lt;/code>&lt;/li>
&lt;li>&lt;code>sqlite-devel&lt;/code>&lt;/li>
&lt;li>&lt;code>geos-devel&lt;/code>&lt;/li>
&lt;li>&lt;code>proj-devel&lt;/code>&lt;/li>
&lt;li>&lt;code>python-pip&lt;/code>&lt;/li>
&lt;li>&lt;code>redhat-rpm-config&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>After which you can install &lt;code>pyspatialite&lt;/code> using &lt;code>pip&lt;/code> by running:&lt;/p>
&lt;pre>&lt;code>CFLAGS=-I/usr/include pip install pyspatialite
&lt;/code>&lt;/pre>
&lt;p>At this point, you should be able to use the &amp;ldquo;Processing&amp;rdquo; plugin.&lt;/p></content></item><item><title>Bootstrapping Ansible on Fedora 23</title><link>https://blog.oddbit.com/post/2015-10-15-bootstrapping-ansible-on-fedor/</link><pubDate>Thu, 15 Oct 2015 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2015-10-15-bootstrapping-ansible-on-fedor/</guid><description>&lt;p>If you&amp;rsquo;ve tried running &lt;a href="http://ansible.com/">Ansible&lt;/a> against a &lt;a href="http://fedoraproject.org/">Fedora&lt;/a> 23 system,
you may have run into the following problem:&lt;/p>
&lt;pre>&lt;code>fatal: [myserver]: FAILED! =&amp;gt; {&amp;quot;changed&amp;quot;: false, &amp;quot;failed&amp;quot;: true,
&amp;quot;msg&amp;quot;: &amp;quot;/bin/sh: /usr/bin/python: No such file or directory\r\n&amp;quot;,
&amp;quot;parsed&amp;quot;: false}
&lt;/code>&lt;/pre>
&lt;p>Fedora has recently made the switch to only including Python 3 on the
base system (at least for the &lt;a href="https://getfedora.org/en/cloud/prerelease/">cloud&lt;/a> variant), while Ansible still
requires Python 2. With Fedora 23, Python 3 is available as
&lt;code>/usr/bin/python3&lt;/code>, and &lt;code>/usr/bin/python&lt;/code> is only available if you
have installed the Python 2 interpreter.&lt;/p></description><content>&lt;p>If you&amp;rsquo;ve tried running &lt;a href="http://ansible.com/">Ansible&lt;/a> against a &lt;a href="http://fedoraproject.org/">Fedora&lt;/a> 23 system,
you may have run into the following problem:&lt;/p>
&lt;pre>&lt;code>fatal: [myserver]: FAILED! =&amp;gt; {&amp;quot;changed&amp;quot;: false, &amp;quot;failed&amp;quot;: true,
&amp;quot;msg&amp;quot;: &amp;quot;/bin/sh: /usr/bin/python: No such file or directory\r\n&amp;quot;,
&amp;quot;parsed&amp;quot;: false}
&lt;/code>&lt;/pre>
&lt;p>Fedora has recently made the switch to only including Python 3 on the
base system (at least for the &lt;a href="https://getfedora.org/en/cloud/prerelease/">cloud&lt;/a> variant), while Ansible still
requires Python 2. With Fedora 23, Python 3 is available as
&lt;code>/usr/bin/python3&lt;/code>, and &lt;code>/usr/bin/python&lt;/code> is only available if you
have installed the Python 2 interpreter.&lt;/p>
&lt;p>This is not an insurmountable problem; Ansible&amp;rsquo;s &lt;a href="http://docs.ansible.com/ansible/raw_module.html">raw&lt;/a> module can be
used to run arbitrary commands on a remote host without requiring an
installed Python interpreter. This gives us everything we need to
bootstrap the remote environment.&lt;/p>
&lt;p>The simplest playbook might look something like:&lt;/p>
&lt;pre>&lt;code>- hosts: all
tasks:
- name: install packages for ansible support
raw: dnf -y -e0 -d0 install python python-dnf
&lt;/code>&lt;/pre>
&lt;p>(The &lt;code>python-dnf&lt;/code> package is required if you want to install packages
using the &lt;code>dnf&lt;/code> module.)&lt;/p>
&lt;p>So you drop this into a playbook and run it and&amp;hellip;it still fails, with
the same error. This is because Ansible will, by default, attempt to
gather facts from the remote host by running the &lt;code>setup&lt;/code> module, which
requires Python. So we modify our playbook to look like this:&lt;/p>
&lt;pre>&lt;code>- hosts: all
gather_facts: false
tasks:
- name: install packages for ansible support
raw: dnf -y -e0 -d0 install python python-dnf
&lt;/code>&lt;/pre>
&lt;p>Setting &lt;code>gather_facts: false&lt;/code> inhibits this initial fact collection;
with this change, the playbook should run successfully:&lt;/p>
&lt;pre>&lt;code>$ ansible-playbook playbook.yml
PLAY ***************************************************************************
TASK [install packages for ansible support] ************************************
ok: [myserver -&amp;gt; localhost]
PLAY RECAP *********************************************************************
myserver : ok=1 changed=0 unreachable=0 failed=0
&lt;/code>&lt;/pre>
&lt;p>Having installed the basics, you can now use many of the standard
Ansible modules:&lt;/p>
&lt;pre>&lt;code>- hosts: all
gather_facts: true
tasks:
- lineinefile:
dest: /etc/hosts
line: &amp;quot;{{ansible_eth0.ipv4.address}} {{inventory_hostname}}&amp;quot;
regexp: &amp;quot;{{inventory_hostname}}&amp;quot;
- package:
name: git
state: present
&lt;/code>&lt;/pre>
&lt;p>As the above example demonstrates, now that the necessary Python stack
is installed on the remote Fedora 23 host, Ansible is is able to
gather &lt;a href="http://docs.ansible.com/ansible/playbooks_variables.html#information-discovered-from-systems-facts">facts&lt;/a> about the host that can be used in tasks, templates,
etc.&lt;/p>
&lt;p>Note that with the &lt;code>raw&lt;/code> module I had to use the &lt;code>dnf&lt;/code> command
explicitly, while in the above playbook I can use the &lt;code>package&lt;/code> module
for package installation, which relies on available facts to determine
the correct package module.&lt;/p></content></item><item><title>Booting cloud images with libvirt</title><link>https://blog.oddbit.com/post/2015-03-10-booting-cloud-images-with-libv/</link><pubDate>Tue, 10 Mar 2015 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2015-03-10-booting-cloud-images-with-libv/</guid><description>&lt;p>Most major distributions now provide &amp;ldquo;cloud-enabled&amp;rdquo; images designed
for use in cloud environments like OpenStack and AWS. These images
are usually differentiated by (a) being relatively small, and (b) running
&lt;a href="http://cloudinit.readthedocs.org/">cloud-init&lt;/a> at boot to perform initial system configuration tasks
using metadata provided by the cloud environment.&lt;/p>
&lt;p>Because of their small size and support for automatic configuration
(including such useful tasks as provisioning ssh keys), these images
are attractive for use &lt;em>outside&lt;/em> of a cloud environment.
Unfortunately, when people first try to boot them they are met with
frustration as first the image takes forever to boot as it tries to
contact a non-existent metadata service, and then when it finally does
boot they are unable to log in because the images typically only
support key-based login.&lt;/p></description><content>&lt;p>Most major distributions now provide &amp;ldquo;cloud-enabled&amp;rdquo; images designed
for use in cloud environments like OpenStack and AWS. These images
are usually differentiated by (a) being relatively small, and (b) running
&lt;a href="http://cloudinit.readthedocs.org/">cloud-init&lt;/a> at boot to perform initial system configuration tasks
using metadata provided by the cloud environment.&lt;/p>
&lt;p>Because of their small size and support for automatic configuration
(including such useful tasks as provisioning ssh keys), these images
are attractive for use &lt;em>outside&lt;/em> of a cloud environment.
Unfortunately, when people first try to boot them they are met with
frustration as first the image takes forever to boot as it tries to
contact a non-existent metadata service, and then when it finally does
boot they are unable to log in because the images typically only
support key-based login.&lt;/p>
&lt;p>Fortunately, there are ways to work around these issues. In addition
to working with various network-accessible metadata services,
&lt;a href="http://cloudinit.readthedocs.org/">cloud-init&lt;/a> is also able to read configuration information from an
attached [virtual] CD-ROM device. This is known as a &amp;ldquo;configuration
drive&amp;rdquo;, and it is relatively easy to create.&lt;/p>
&lt;p>For this purpose, the simplest solution is use &lt;a href="http://cloudinit.readthedocs.org/">cloud-init&lt;/a>&amp;rsquo;s &amp;ldquo;no
cloud&amp;rdquo; data source. For this, we need to create an ISO filesystem
creating two files, &lt;code>meta-data&lt;/code> and (optionally) &lt;code>user-data&lt;/code>.&lt;/p>
&lt;h2 id="the-meta-data-file">The meta-data file&lt;/h2>
&lt;p>The &lt;code>meta-data&lt;/code> file is effectively a YAML version of the data
typically available in the EC2 metadata service, and will look
something like this:&lt;/p>
&lt;pre>&lt;code>instance-id: my-instance-id
local-hostname: my-host-name
&lt;/code>&lt;/pre>
&lt;p>The &lt;code>instance-id&lt;/code> key is required. You can also include SSH public
keys in this file, like this:&lt;/p>
&lt;pre>&lt;code>instance-id: my-instance-id
local-hostname: my-host-name
public-keys:
- ssh-rsa AAAAB3NzaC1...
&lt;/code>&lt;/pre>
&lt;p>You will see examples that place ssh keys in the &lt;code>user-data&lt;/code> file
instead, but I believe this is the wrong solution, since it forces you
to use a &amp;ldquo;cloud-config&amp;rdquo; format &lt;code>user-data&lt;/code> file. Putting ssh keys
into the &lt;code>meta-data&lt;/code> provides you more flexibility with your
&lt;code>user-data&lt;/code> content.&lt;/p>
&lt;h2 id="the-user-data-file">The user-data file&lt;/h2>
&lt;p>The &lt;code>user-data&lt;/code> can be any of the various formats &lt;a href="http://cloudinit.readthedocs.org/en/latest/topics/format.html">supported by
cloud-init&lt;/a>. For example, it could simply be a shell script:&lt;/p>
&lt;pre>&lt;code>#!/bin/sh
yum -y install some-critical-package
&lt;/code>&lt;/pre>
&lt;p>Or it could be a &lt;a href="http://cloudinit.readthedocs.org/en/latest/topics/examples.html#yaml-examples">cloud-config&lt;/a> YAML document:&lt;/p>
&lt;pre>&lt;code>#cloud-config
write-files:
- path: /etc/profile.d/gitaliases.sh
content: |
alias gc=&amp;quot;git commit&amp;quot;
alias gcv=&amp;quot;git commit --no-verify&amp;quot;
runcmd:
- setenforce 1
&lt;/code>&lt;/pre>
&lt;h2 id="putting-it-all-together">Putting it all together&lt;/h2>
&lt;p>Once you have created your &lt;code>meta-data&lt;/code> and &lt;code>user-data&lt;/code> files, you can
create the configuration drive like this:&lt;/p>
&lt;pre>&lt;code>genisoimage -o config.iso -V cidata -r -J meta-data user-data
&lt;/code>&lt;/pre>
&lt;p>To boot an instance using this configuration drive, you could do
something like this:&lt;/p>
&lt;pre>&lt;code>virt-install -n example -r 512 -w network=default \
--disk vol=default/fedora-21-cloud.qcow2 --import \
--disk path=config.iso,device=cdrom
&lt;/code>&lt;/pre>
&lt;p>(This assumes, obviously, that you have an image named
&lt;code>fedora-21-cloud.qcow2&lt;/code> available in libvirt&amp;rsquo;s &lt;code>default&lt;/code> storage
pool.)&lt;/p>
&lt;h2 id="a-little-automation">A little automation&lt;/h2>
&lt;p>I have written a &lt;a href="https://github.com/larsks/virt-utils/blob/master/create-config-drive">create-config-drive&lt;/a> script that will automate
this process. With this script available, the above process is
simply:&lt;/p>
&lt;pre>&lt;code>create-config-drive -k ~/.ssh/id_rsa.pub -u user-data config.iso
adding pubkey from /home/lars/.ssh/id_rsa.pub
adding user data from userdata
generating configuration image at config.iso
&lt;/code>&lt;/pre></content></item><item><title>Fedora Atomic, OpenStack, and Kubernetes (oh my)</title><link>https://blog.oddbit.com/post/2014-11-24-fedora-atomic-openstack-and-ku/</link><pubDate>Mon, 24 Nov 2014 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2014-11-24-fedora-atomic-openstack-and-ku/</guid><description>&lt;p>While experimenting with &lt;a href="http://www.projectatomic.io/">Fedora Atomic&lt;/a>, I was looking for an
elegant way to automatically deploy Atomic into an &lt;a href="http://openstack.org/">OpenStack&lt;/a>
environment and then automatically schedule some &lt;a href="http://docker.com/">Docker&lt;/a> containers
on the Atomic host. This post describes my solution.&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>Like many other cloud-targeted distributions, Fedora Atomic runs
&lt;a href="http://cloudinit.readthedocs.org/">cloud-init&lt;/a> when the system boots. We can take advantage of this
to configure the system at first boot by providing a &lt;code>user-data&lt;/code> blob
to Nova when we boot the instance. A &lt;code>user-data&lt;/code> blob can be as
simple as a shell script, and while we could arguably mash everything
into a single script it wouldn&amp;rsquo;t be particularly maintainable or
flexible in the face of different pod/service/etc descriptions.&lt;/p></description><content>&lt;p>While experimenting with &lt;a href="http://www.projectatomic.io/">Fedora Atomic&lt;/a>, I was looking for an
elegant way to automatically deploy Atomic into an &lt;a href="http://openstack.org/">OpenStack&lt;/a>
environment and then automatically schedule some &lt;a href="http://docker.com/">Docker&lt;/a> containers
on the Atomic host. This post describes my solution.&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>Like many other cloud-targeted distributions, Fedora Atomic runs
&lt;a href="http://cloudinit.readthedocs.org/">cloud-init&lt;/a> when the system boots. We can take advantage of this
to configure the system at first boot by providing a &lt;code>user-data&lt;/code> blob
to Nova when we boot the instance. A &lt;code>user-data&lt;/code> blob can be as
simple as a shell script, and while we could arguably mash everything
into a single script it wouldn&amp;rsquo;t be particularly maintainable or
flexible in the face of different pod/service/etc descriptions.&lt;/p>
&lt;p>In order to build a more flexible solution, we&amp;rsquo;re going to take
advantage of the following features:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Support for &lt;a href="http://cloudinit.readthedocs.org/en/latest/topics/format.html#mime-multi-part-archive">multipart MIME archives&lt;/a>.&lt;/p>
&lt;p>Cloud-init allows you to pass in multiple files via &lt;code>user-data&lt;/code> by
encoding them as a multipart MIME archive.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Support for a &lt;a href="http://cloudinit.readthedocs.org/en/latest/topics/format.html#part-handler">custom part handler&lt;/a>.&lt;/p>
&lt;p>Cloud-init recognizes a number of specific MIME types (such as
&lt;code>text/cloud-config&lt;/code> or &lt;code>text/x-shellscript&lt;/code>). We can provide a
custom part handler that will be used to handle MIME types not
intrinsincally supported by &lt;code>cloud-init&lt;/code>.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="a-custom-part-handler-for-kubernetes-configurations">A custom part handler for Kubernetes configurations&lt;/h2>
&lt;p>I have written a &lt;a href="https://github.com/larsks/atomic-kubernetes-tools/blob/master/kube-part-handler.py">custom part handler&lt;/a> that knows
about the following MIME types:&lt;/p>
&lt;ul>
&lt;li>&lt;code>text/x-kube-pod&lt;/code>&lt;/li>
&lt;li>&lt;code>text/x-kube-service&lt;/code>&lt;/li>
&lt;li>&lt;code>text/x-kube-replica&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>When the part handler is first initialized it will ensure the
Kubernetes is started. If it is provided with a document matching one
of the above MIME types, it will pass it to the appropriate &lt;code>kubecfg&lt;/code>
command to create the objects in Kubernetes.&lt;/p>
&lt;h2 id="creating-multipart-mime-archives">Creating multipart MIME archives&lt;/h2>
&lt;p>I have also created a &lt;a href="https://github.com/larsks/atomic-kubernetes-tools/blob/master/write-mime-multipart.py">modified version&lt;/a> of the standard
&lt;code>write-multipart-mime.py&lt;/code> Python script. This script will inspect the
first lines of files to determine their content type; in addition to
the standard &lt;code>cloud-init&lt;/code> types (like &lt;code>#cloud-config&lt;/code> for a
&lt;code>text/cloud-config&lt;/code> type file), this script recognizes:&lt;/p>
&lt;ul>
&lt;li>&lt;code>#kube-pod&lt;/code> for &lt;code>text/x-kube-pod&lt;/code>&lt;/li>
&lt;li>&lt;code>#kube-service&lt;/code> for &lt;code>text/x-kube-service&lt;/code>&lt;/li>
&lt;li>&lt;code>#kube-replica&lt;/code> for &lt;code>text/x-kube-replca&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>That is, a simple pod description might look something like:&lt;/p>
&lt;pre>&lt;code>#kube-pod
id: dbserver
desiredState:
manifest:
version: v1beta1
id: dbserver
containers:
- image: mysql
name: dbserver
env:
- name: MYSQL_ROOT_PASSWORD
value: secret
&lt;/code>&lt;/pre>
&lt;h2 id="putting-it-all-together">Putting it all together&lt;/h2>
&lt;p>Assuming that the pod description presented in the previous section is
stored in a file named &lt;code>dbserver.yaml&lt;/code>, we can bundle that file up
with our custom part handler like this:&lt;/p>
&lt;pre>&lt;code>$ write-mime-multipart.py \
kube-part-handler.py dbserver.yaml &amp;gt; userdata
&lt;/code>&lt;/pre>
&lt;p>We would then launch a Nova instance using the &lt;code>nova boot&lt;/code> command,
providing the generated &lt;code>userdata&lt;/code> file as an argument to the
&lt;code>user-data&lt;/code> command:&lt;/p>
&lt;pre>&lt;code>$ nova boot --image fedora-atomic --key-name mykey \
--flavor m1.small --user-data userdata my-atomic-server
&lt;/code>&lt;/pre>
&lt;p>You would obviously need to substitute values for &lt;code>--image&lt;/code> and
&lt;code>--key-name&lt;/code> that are appropriate for your environment.&lt;/p>
&lt;h2 id="details-details">Details, details&lt;/h2>
&lt;p>If you are experimenting with Fedora Atomic 21, you may find out that
the above example doesn&amp;rsquo;t work &amp;ndash; the official &lt;code>mysql&lt;/code> image generates
an selinux error. We can switch selinux to permissive mode by putting
the following into a file called &lt;code>disable-selinux.sh&lt;/code>:&lt;/p>
&lt;pre>&lt;code>#!/bin/sh
setenforce 0
sed -i '/^SELINUX=/ s/=.*/=permissive/' /etc/selinux/config
&lt;/code>&lt;/pre>
&lt;p>And then including that in our MIME archive:&lt;/p>
&lt;pre>&lt;code>$ write-mime-multipart.py \
kube-part-handler.py disable-selinux.sh dbserver.yaml &amp;gt; userdata
&lt;/code>&lt;/pre>
&lt;h2 id="a-brief-demonstration">A brief demonstration&lt;/h2>
&lt;p>If we launch an instance as described in the previous section and then
log in, we should find that the pod has already been scheduled:&lt;/p>
&lt;pre>&lt;code># kubecfg list pods
ID Image(s) Host Labels Status
---------- ---------- ---------- ---------- ----------
dbserver mysql / Waiting
&lt;/code>&lt;/pre>
&lt;p>At this point, &lt;code>docker&lt;/code> needs to pull the &lt;code>mysql&lt;/code> image locally, so
this step can take a bit depending on the state of your local internet
connection.&lt;/p>
&lt;p>Running &lt;code>docker ps&lt;/code> at this point will yield:&lt;/p>
&lt;pre>&lt;code># docker ps
CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES
3561e39f198c kubernetes/pause:latest &amp;quot;/pause&amp;quot; 46 seconds ago Up 43 seconds k8s--net.d96a64a9--dbserver.etcd--3d30eac0_-_745c_-_11e4_-_b32a_-_fa163e6e92ce--d872be51
&lt;/code>&lt;/pre>
&lt;p>The &lt;code>pause&lt;/code> image here is a Kubernetes detail that is used to
configure the networking for a pod (in the Kubernetes world, a pod is
a group of linked containers that share a common network namespace).&lt;/p>
&lt;p>After a few minutes, you should eventually see:&lt;/p>
&lt;pre>&lt;code># docker ps
CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES
644c8fc5a79c mysql:latest &amp;quot;/entrypoint.sh mysq 3 minutes ago Up 3 minutes k8s--dbserver.fd48803d--dbserver.etcd--3d30eac0_-_745c_-_11e4_-_b32a_-_fa163e6e92ce--58794467
3561e39f198c kubernetes/pause:latest &amp;quot;/pause&amp;quot; 5 minutes ago Up 5 minutes k8s--net.d96a64a9--dbserver.etcd--3d30eac0_-_745c_-_11e4_-_b32a_-_fa163e6e92ce--d872be51
&lt;/code>&lt;/pre>
&lt;p>And &lt;code>kubecfg&lt;/code> should show the pod as running:&lt;/p>
&lt;pre>&lt;code># kubecfg list pods
ID Image(s) Host Labels Status
---------- ---------- ---------- ---------- ----------
dbserver mysql 127.0.0.1/ Running
&lt;/code>&lt;/pre>
&lt;h2 id="problems-problems">Problems, problems&lt;/h2>
&lt;p>This works and is I think a relatively elegant solution. However,
there are some drawbacks. In particular, the custom part handler
runs fairly early in the &lt;code>cloud-init&lt;/code> process, which means that it
cannot depend on changes implemented by &lt;code>user-data&lt;/code> scripts (because
these run much later).&lt;/p>
&lt;p>A better solution might be to have the custom part handler simply
write the Kubernetes configs into a directory somewhere, and then
install a service that launches after Kubernetes and (a) watches that
directory for files, then (b) passes the configuration to Kubernetes
and deletes (or relocates) the file.&lt;/p></content></item><item><title>Fedora and OVS Bridge Interfaces</title><link>https://blog.oddbit.com/post/2014-05-20-fedora-and-ovs-bridge-interfac/</link><pubDate>Tue, 20 May 2014 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2014-05-20-fedora-and-ovs-bridge-interfac/</guid><description>&lt;p>I run OpenStack on my laptop, and I&amp;rsquo;ve been chasing down a pernicious
problem with OVS bridge interfaces under both F19 and F20. My
OpenStack environment relies on an OVS bridge device named &lt;code>br-ex&lt;/code> for
external connectivity and for making services available to OpenStack
instances, but after rebooting, &lt;code>br-ex&lt;/code> was consistently unconfigured,
which caused a variety of problems.&lt;/p>
&lt;p>This is the network configuration file for &lt;code>br-ex&lt;/code> on my system:&lt;/p>
&lt;pre>&lt;code>DEVICE=br-ex
DEVICETYPE=ovs
TYPE=OVSBridge
BOOTPROT=static
IPADDR=192.168.200.1
NETMASK=255.255.255.0
ONBOOT=yes
NM_CONTROLLED=no
ZONE=openstack
&lt;/code>&lt;/pre>
&lt;p>Running &lt;code>ifup br-ex&lt;/code> would also fail to configure the interface, but
running &lt;code>ifdown br-ex; ifup br-ex&lt;/code> would configure things
appropriately.&lt;/p></description><content>&lt;p>I run OpenStack on my laptop, and I&amp;rsquo;ve been chasing down a pernicious
problem with OVS bridge interfaces under both F19 and F20. My
OpenStack environment relies on an OVS bridge device named &lt;code>br-ex&lt;/code> for
external connectivity and for making services available to OpenStack
instances, but after rebooting, &lt;code>br-ex&lt;/code> was consistently unconfigured,
which caused a variety of problems.&lt;/p>
&lt;p>This is the network configuration file for &lt;code>br-ex&lt;/code> on my system:&lt;/p>
&lt;pre>&lt;code>DEVICE=br-ex
DEVICETYPE=ovs
TYPE=OVSBridge
BOOTPROT=static
IPADDR=192.168.200.1
NETMASK=255.255.255.0
ONBOOT=yes
NM_CONTROLLED=no
ZONE=openstack
&lt;/code>&lt;/pre>
&lt;p>Running &lt;code>ifup br-ex&lt;/code> would also fail to configure the interface, but
running &lt;code>ifdown br-ex; ifup br-ex&lt;/code> would configure things
appropriately.&lt;/p>
&lt;p>I finally got fed up with this behavior and spent some time chasing
down the problem, and this is what I found:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Calling &lt;code>ifup br-ex&lt;/code> passes control to
&lt;code>/etc/sysconfig/network-scripts/ifup-ovs&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>ifup-ovs&lt;/code> calls the &lt;code>check_device_down&lt;/code> function from
&lt;code>network-functions&lt;/code>, which looks like:&lt;/p>
&lt;pre>&lt;code> check_device_down ()
{
[ ! -d /sys/class/net/$1 ] &amp;amp;&amp;amp; return 0
if LC_ALL=C ip -o link show dev $1 2&amp;gt;/dev/null | grep -q &amp;quot;,UP&amp;quot; ; then
return 1
else
return 0
fi
}
&lt;/code>&lt;/pre>
&lt;/li>
&lt;/ul>
&lt;p>This returns failure (=1) if the interface flags contain &lt;code>,UP&lt;/code>.
Unfortunately, since information about this device is stored
persistently in &lt;code>ovsdb&lt;/code>, the device is already &lt;code>UP&lt;/code> when &lt;code>ifup&lt;/code> is
called, which causes &lt;code>ifup-ovs&lt;/code> to skip further device
configuration. The logic that calls &lt;code>check_device_down&lt;/code> looks like
this:&lt;/p>
&lt;pre>&lt;code>if check_device_down &amp;quot;${DEVICE}&amp;quot;; then
ovs-vsctl -t ${TIMEOUT} -- --may-exist add-br &amp;quot;$DEVICE&amp;quot; $OVS_OPTIONS \
${OVS_EXTRA+-- $OVS_EXTRA} \
${STP+-- set bridge &amp;quot;$DEVICE&amp;quot; stp_enable=&amp;quot;${STP}&amp;quot;}
else
OVSBRIDGECONFIGURED=&amp;quot;yes&amp;quot;
fi
&lt;/code>&lt;/pre>
&lt;p>This sets &lt;code>OVSBRIDGECONFIGURED&lt;/code> if it believes the device is &lt;code>UP&lt;/code>,
which causes &lt;code>ifup-ovs&lt;/code> to skip the call to &lt;code>ifup-eth&lt;/code> to configure
the interface:&lt;/p>
&lt;pre>&lt;code>if [ &amp;quot;${OVSBOOTPROTO}&amp;quot; != &amp;quot;dhcp&amp;quot; ] &amp;amp;&amp;amp; [ -z &amp;quot;${OVSINTF}&amp;quot; ] &amp;amp;&amp;amp; \
[ &amp;quot;${OVSBRIDGECONFIGURED}&amp;quot; != &amp;quot;yes&amp;quot; ]; then
${OTHERSCRIPT} ${CONFIG}
fi
&lt;/code>&lt;/pre>
&lt;p>I have found that the simplest solution to this problem is to disable
the logic that sets &lt;code>OVSBRIDGECONFIGURED&lt;/code>, by changing this:&lt;/p>
&lt;pre>&lt;code>else
OVSBRIDGECONFIGURED=&amp;quot;yes&amp;quot;
fi
&lt;/code>&lt;/pre>
&lt;p>To this:&lt;/p>
&lt;pre>&lt;code>else
: OVSBRIDGECONFIGURED=&amp;quot;yes&amp;quot;
fi
&lt;/code>&lt;/pre>
&lt;p>With this change in place, &lt;code>br-ex&lt;/code> is correctly configured after a
reboot.&lt;/p></content></item><item><title>Private /tmp directories in Fedora</title><link>https://blog.oddbit.com/post/2012-11-05-fedora-private-tmp/</link><pubDate>Mon, 05 Nov 2012 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2012-11-05-fedora-private-tmp/</guid><description>&lt;p>I ran into an odd problem the other day: I was testing out some
configuration changes for a web application by dropping files into
&lt;code>/tmp&lt;/code> and pointing the application configuration at the appropriate
directory. Everything worked out great when testing it by hand&amp;hellip;but
when starting up the &lt;code>httpd&lt;/code> service, the application behaved as if it
was unable to find any of the files in &lt;code>/tmp&lt;/code>.&lt;/p>
&lt;p>My first assumption was that had simply missed something obvious like
file permissions or that I had a typo in my configuration, but after
repeated checks and lots of testing it was obvious that something else
was going on.&lt;/p></description><content>&lt;p>I ran into an odd problem the other day: I was testing out some
configuration changes for a web application by dropping files into
&lt;code>/tmp&lt;/code> and pointing the application configuration at the appropriate
directory. Everything worked out great when testing it by hand&amp;hellip;but
when starting up the &lt;code>httpd&lt;/code> service, the application behaved as if it
was unable to find any of the files in &lt;code>/tmp&lt;/code>.&lt;/p>
&lt;p>My first assumption was that had simply missed something obvious like
file permissions or that I had a typo in my configuration, but after
repeated checks and lots of testing it was obvious that something else
was going on.&lt;/p>
&lt;p>Grasping at straws I took a close look at the &lt;code>systemd&lt;/code> service file
for &lt;code>httpd&lt;/code>, which looks like this:&lt;/p>
&lt;pre>&lt;code>[Unit]
Description=The Apache HTTP Server (prefork MPM)
After=syslog.target network.target remote-fs.target nss-lookup.target
[Service]
Type=forking
PIDFile=/var/run/httpd/httpd.pid
EnvironmentFile=/etc/sysconfig/httpd
ExecStart=/usr/sbin/httpd $OPTIONS -k start
ExecReload=/usr/sbin/httpd $OPTIONS -t
ExecReload=/bin/kill -HUP $MAINPID
ExecStop=/usr/sbin/httpd $OPTIONS -k stop
PrivateTmp=true
[Install]
WantedBy=multi-user.target
&lt;/code>&lt;/pre>
&lt;p>Browsing throught file the following line caught my eye:&lt;/p>
&lt;pre>&lt;code>PrivateTmp=true
&lt;/code>&lt;/pre>
&lt;p>If you know about per-process namespaces in Linux, you&amp;rsquo;re probably
saying &amp;ldquo;Ah-ha!&amp;rdquo;. If you &lt;em>don&amp;rsquo;t&lt;/em> know about per-process namespaces in
Linux&amp;hellip;you should, because this is the foundation for all sorts of
things including Linux Containers (&lt;a href="http://lxc.sourceforge.net/">LXC&lt;/a>). Here&amp;rsquo;s some good
introductory reading:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="http://lxr.free-electrons.com/source/Documentation/unshare.txt">http://lxr.free-electrons.com/source/Documentation/unshare.txt&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://www.debian-administration.org/article/628/Per-Process_Namespaces">http://www.debian-administration.org/article/628/Per-Process_Namespaces&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://glandium.org/blog/?p=217">http://glandium.org/blog/?p=217&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>In short, with this configuration in place, the service gets it&amp;rsquo;s very
own version of &lt;code>/tmp&lt;/code> not shared with any other process. While the
files I placed in &lt;code>/tmp&lt;/code> were visible in &lt;em>my&lt;/em> process, they didn&amp;rsquo;t
exist from the point of view of Apache.&lt;/p>
&lt;p>The fix in my case was to place the files somewhere other than &lt;code>/tmp&lt;/code>.
One could also disable the &lt;code>PrivateTmp&lt;/code> setting, but it&amp;rsquo;s generally
turned on for reasons of security.&lt;/p>
&lt;p>The &lt;code>PrivateTmp&lt;/code> option is documented in &lt;a href="https://docs.fedoraproject.org/en-US/Fedora/17/html/Release_Notes/sect-Release_Notes-Changes_for_Sysadmin.html">Changes in Fedora for System
Administrators&lt;/a>, and Dan Walsh discusses it briefly on
&lt;a href="http://danwalsh.livejournal.com/51459.html">his blog&lt;/a>.&lt;/p></content></item></channel></rss>