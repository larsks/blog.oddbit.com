<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Docker on blog.oddbit.com</title><link>https://blog.oddbit.com/tags/docker/</link><description>Recent content in Docker on blog.oddbit.com</description><generator>Hugo</generator><language>en</language><copyright>Lars Kellogg-Stedman</copyright><lastBuildDate>Thu, 16 Feb 2023 10:58:10 -0500</lastBuildDate><atom:link href="https://blog.oddbit.com/tags/docker/rss.xml" rel="self" type="application/rss+xml"/><item><title>Directing different ports to different containers with Traefik</title><link>https://blog.oddbit.com/post/2022-06-20-traefik-multiple-listeners/</link><pubDate>Mon, 20 Jun 2022 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2022-06-20-traefik-multiple-listeners/</guid><description>&lt;p&gt;This post is mostly for myself: I find the &lt;a href="https://traefik.io"&gt;Traefik&lt;/a&gt; documentation hard to navigate, so having figured this out in response to &lt;a href="https://stackoverflow.com/a/72694677/147356"&gt;a question on Stack Overflow&lt;/a&gt;, I&amp;rsquo;m putting it here to help it stick in my head.&lt;/p&gt;
&lt;p&gt;The question asks essentially how to perform port-based routing of requests to containers, so that a request for &lt;code&gt;http://example.com&lt;/code&gt; goes to one container while a request for &lt;code&gt;http://example.com:9090&lt;/code&gt; goes to a different container.&lt;/p&gt;
&lt;h2 id="creating-entrypoints"&gt;Creating entrypoints&lt;/h2&gt;
&lt;p&gt;A default Traefik configuration will already have a listener on port 80, but if we want to accept connections on port 9090 we need to create a new listener: what Traefik calls an &lt;a href="https://doc.traefik.io/traefik/routing/entrypoints/"&gt;entrypoint&lt;/a&gt;. We do this using the &lt;code&gt;--entrypoints.&amp;lt;name&amp;gt;.address&lt;/code&gt; option. For example, &lt;code&gt;--entrypoints.ep1.address=80&lt;/code&gt; creates an entrypoint named &lt;code&gt;ep1&lt;/code&gt; on port 80, while &lt;code&gt;--entrypoints.ep2.address=9090&lt;/code&gt; creates an entrypoint named &lt;code&gt;ep2&lt;/code&gt; on port 9090. Those names are important because we&amp;rsquo;ll use them for mapping containers to the appropriate listener later on.&lt;/p&gt;</description></item><item><title>Building multi-architecture images with GitHub Actions</title><link>https://blog.oddbit.com/post/2020-09-25-building-multi-architecture-im/</link><pubDate>Fri, 25 Sep 2020 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2020-09-25-building-multi-architecture-im/</guid><description>&lt;p&gt;At work we have a cluster of IBM Power 9 systems running OpenShift. The
problem with this environment is that nobody runs Power 9 on their desktop,
and Docker Hub only offers automatic build support for the x86
architecture. This means there&amp;rsquo;s no convenient options for building Power 9
Docker images&amp;hellip;or so I thought.&lt;/p&gt;
&lt;p&gt;It turns out that &lt;a href="https://github.com/docker"&gt;Docker&lt;/a&gt; provides &lt;a href="https://github.com/features/actions"&gt;GitHub actions&lt;/a&gt; that make the process
of producing multi-architecture images quite simple.&lt;/p&gt;</description></item><item><title>Running Keystone with Docker Compose</title><link>https://blog.oddbit.com/post/2019-06-07-running-keystone-with-docker-c/</link><pubDate>Fri, 07 Jun 2019 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2019-06-07-running-keystone-with-docker-c/</guid><description>&lt;p&gt;In this article, we will look at what is necessary to run OpenStack&amp;rsquo;s &lt;a href="https://docs.openstack.org/keystone/latest/"&gt;Keystone&lt;/a&gt; service (and the requisite database server) in containers using &lt;a href="https://docs.docker.com/compose/"&gt;Docker Compose&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="running-mariadb"&gt;Running MariaDB&lt;/h2&gt;
&lt;p&gt;The standard &lt;a href="https://hub.docker.com/_/mariadb/"&gt;mariadb docker image&lt;/a&gt; can be configured via a number of environment variables. It also benefits from persistent volume storage, since in most situations you don&amp;rsquo;t want to lose your data when you remove a container. A simple &lt;code&gt;docker&lt;/code&gt; command line for starting MariaDB might look something like:&lt;/p&gt;</description></item><item><title>Docker build learns about secrets and ssh agent forwarding</title><link>https://blog.oddbit.com/post/2019-02-24-docker-build-learns-about-secr/</link><pubDate>Sun, 24 Feb 2019 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2019-02-24-docker-build-learns-about-secr/</guid><description>&lt;p&gt;A common problem for folks working with Docker is accessing resources which require authentication during the image build step. A particularly common use case is getting access to private git repositories using ssh key-based authentication. Until recently there hasn&amp;rsquo;t been a great solution:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;you can embed secrets in your image, but now you can&amp;rsquo;t share the image with anybody.&lt;/li&gt;
&lt;li&gt;you can use build arguments, but this requires passing in an unenecrypted private key on the &lt;code&gt;docker build&lt;/code&gt; command line, which is suboptimal for a number of reasons&lt;/li&gt;
&lt;li&gt;you can perform all the steps requiring authentication at runtime, but this can needlessly complicate your container startup process.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With Docker 18.09, there are some experimental features available that makes this much easier. You can read the official announcement &lt;a href="https://docs.docker.com/develop/develop-images/build_enhancements/"&gt;here&lt;/a&gt;, but I wanted to highlight the support for ssh agent forwarding and private keys.&lt;/p&gt;</description></item><item><title>Using Docker macvlan networks</title><link>https://blog.oddbit.com/post/2018-03-12-using-docker-macvlan-networks/</link><pubDate>Mon, 12 Mar 2018 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2018-03-12-using-docker-macvlan-networks/</guid><description>&lt;p&gt;A question that crops up regularly on &lt;a href="https://docs.docker.com/opensource/ways/#docker-users"&gt;#docker&lt;/a&gt; is &amp;ldquo;How do I attach
a container directly to my local network?&amp;rdquo; One possible answer to that
question is the &lt;a href="https://docs.docker.com/network/macvlan/"&gt;macvlan&lt;/a&gt; network type, which lets you create
&amp;ldquo;clones&amp;rdquo; of a physical interface on your host and use that to attach
containers directly to your local network. For the most part it works
great, but it does come with some minor caveats and limitations. I
would like to explore those here.&lt;/p&gt;</description></item><item><title>Ansible 2.0: The Docker connection driver</title><link>https://blog.oddbit.com/post/2015-10-13-ansible-20-the-docker-connecti/</link><pubDate>Tue, 13 Oct 2015 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2015-10-13-ansible-20-the-docker-connecti/</guid><description>&lt;p&gt;As the release of &lt;a href="http://ansible.com/"&gt;Ansible&lt;/a&gt; 2.0 draws closer, I&amp;rsquo;d like to take a
look at some of the new features that are coming down the pipe. In
this post, we&amp;rsquo;ll look at the &lt;code&gt;docker&lt;/code&gt; connection driver.&lt;/p&gt;
&lt;p&gt;A &amp;ldquo;connection driver&amp;rdquo; is the mechanism by which Ansible connects to
your target hosts. These days it uses &lt;code&gt;ssh&lt;/code&gt; by default (which relies
on the OpenSSH command line client for connectivity), and it also
offers the &lt;a href="http://www.paramiko.org/"&gt;Paramiko&lt;/a&gt; library as an alternative ssh implementation
(this was in fact the default driver in earlier versions of Ansible).
Alternative drivers offered by recent versions of ansible included the
&lt;code&gt;winrm&lt;/code&gt; driver, for accessing Windows hosts, the &lt;code&gt;fireball&lt;/code&gt; driver, a
(deprecated) driver that used &lt;a href="http://zeromq.org/"&gt;0mq&lt;/a&gt; for communication, and &lt;code&gt;jail&lt;/code&gt;, a
driver for connecting to FreeBSD jails.&lt;/p&gt;</description></item><item><title>Running NTP in a Container</title><link>https://blog.oddbit.com/post/2015-10-09-running-ntp-in-a-container/</link><pubDate>Fri, 09 Oct 2015 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2015-10-09-running-ntp-in-a-container/</guid><description>&lt;p&gt;Someone asked on IRC about running ntpd in a container on &lt;a href="http://www.projectatomic.io/"&gt;Atomic&lt;/a&gt;,
so I&amp;rsquo;ve put together a small example. We&amp;rsquo;ll start with a very simple
&lt;code&gt;Dockerfile&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM alpine
RUN apk update
RUN apk add openntpd
ENTRYPOINT [&amp;quot;ntpd&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I&amp;rsquo;m using the &lt;code&gt;alpine&lt;/code&gt; image as my starting point because it&amp;rsquo;s very
small, which makes this whole process go a little faster. I&amp;rsquo;m
installing the &lt;a href="http://www.openntpd.org/"&gt;openntpd&lt;/a&gt; package, which provides the &lt;code&gt;ntpd&lt;/code&gt; binary.&lt;/p&gt;
&lt;p&gt;By setting an &lt;code&gt;ENTRYPOINT&lt;/code&gt; here, the &lt;code&gt;ntpd&lt;/code&gt; binary will be started by
default, and any arguments passed to &lt;code&gt;docker run&lt;/code&gt; after the image name
will be passed to &lt;code&gt;ntpd&lt;/code&gt;.&lt;/p&gt;</description></item><item><title>Heat-kubernetes Demo with Autoscaling</title><link>https://blog.oddbit.com/post/2015-06-19-heatkubernetes-demo-with-autos/</link><pubDate>Fri, 19 Jun 2015 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2015-06-19-heatkubernetes-demo-with-autos/</guid><description>&lt;p&gt;Next week is the &lt;a href="http://www.redhat.com/summit/"&gt;Red Hat Summit&lt;/a&gt; in Boston, and I&amp;rsquo;ll be taking part
in a &lt;a href="http://www.projectatomic.io/"&gt;Project Atomic&lt;/a&gt; presentation in which I will discuss various
(well, two) options for deploying Atomic into an OpenStack
environment, focusing on my &lt;a href="https://github.com/projectatomic/heat-kubernetes/"&gt;heat-kubernetes&lt;/a&gt; templates.&lt;/p&gt;
&lt;p&gt;As part of that presentation, I&amp;rsquo;ve put together a short demonstration video:&lt;/p&gt;
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;"&gt;
 &lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/tS5X0qi04ZU?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"&gt;&lt;/iframe&gt;
 &lt;/div&gt;

&lt;p&gt;This shows off the autoscaling behavior available with recent versions
of these templates (and also serves as a very brief introduction to
working with Kubernetes).&lt;/p&gt;</description></item><item><title>Suggestions for the Docker MAINTAINER directive</title><link>https://blog.oddbit.com/post/2015-04-27-suggestions-for-the-docker-mai/</link><pubDate>Mon, 27 Apr 2015 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2015-04-27-suggestions-for-the-docker-mai/</guid><description>&lt;p&gt;Because nobody asked for it, this is my opinion on the use of the
&lt;code&gt;MAINTAINER&lt;/code&gt; directive in your Dockerfiles.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://docs.docker.com/reference/builder/#maintainer"&gt;documentation&lt;/a&gt; says simply:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;The MAINTAINER instruction allows you to set the Author field of the generated images.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Many people end up putting the name and email address of an actual
person here. I think this is ultimately a bad idea, and does a
disservice both to members of a project that produce Docker images and
to people consuming those images.&lt;/p&gt;</description></item><item><title>Converting hexadecimal ip addresses to dotted quads with Bash</title><link>https://blog.oddbit.com/post/2015-03-08-converting-hexadecimal-ip-addr/</link><pubDate>Sun, 08 Mar 2015 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2015-03-08-converting-hexadecimal-ip-addr/</guid><description>&lt;p&gt;This is another post that is primarily for my own benefit for the next
time I forget how to do this.&lt;/p&gt;
&lt;p&gt;I wanted to read routing information directly from &lt;code&gt;/proc/net/route&lt;/code&gt;
using &lt;code&gt;bash&lt;/code&gt;, because you never know what may or may not be available
in the minimal environment of a Docker container (for example, the
&lt;code&gt;iproute&lt;/code&gt; package is not installed by default in the Fedora Docker
images). The contents of &lt;code&gt;/proc/net/route&lt;/code&gt; looks something like:&lt;/p&gt;</description></item><item><title>Unpacking Docker images with Undocker</title><link>https://blog.oddbit.com/post/2015-02-13-unpacking-docker-images/</link><pubDate>Fri, 13 Feb 2015 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2015-02-13-unpacking-docker-images/</guid><description>&lt;p&gt;In some ways, the most exciting thing about &lt;a href="http://docker.com/"&gt;Docker&lt;/a&gt; isn&amp;rsquo;t the ability
to start containers. That&amp;rsquo;s been around for a long time in various
forms, such as &lt;a href="https://linuxcontainers.org/"&gt;LXC&lt;/a&gt; or &lt;a href="http://openvz.org/Main_Page"&gt;OpenVZ&lt;/a&gt;. What Docker brought to the
party was a convenient method of building and distributing the
filesystems necessary for running containers. Suddenly, it was easy
to build a containerized service &lt;em&gt;and&lt;/em&gt; to share it with other people.&lt;/p&gt;
&lt;p&gt;I was taking a closer at the &lt;a href="http://www.freedesktop.org/software/systemd/man/systemd-nspawn.html"&gt;systemd-nspawn&lt;/a&gt; command, which it
seems has been developing it&amp;rsquo;s own set of container-related
superpowers recently, including a number of options for setting up the
network environment of a container. Like Docker, &lt;code&gt;systemd-nspawn&lt;/code&gt;
needs a filesystem on which to operate, but &lt;em&gt;unlike&lt;/em&gt; Docker, there is
no convenient distribution mechanism and no ecosystem of existing
images. In fact, the official documentation seems to assume that
you&amp;rsquo;ll be building your own from scratch. Ain&amp;rsquo;t nobody got time for
that&amp;hellip;&lt;/p&gt;</description></item><item><title>Installing nova-docker with devstack</title><link>https://blog.oddbit.com/post/2015-02-11-installing-novadocker-with-dev/</link><pubDate>Wed, 11 Feb 2015 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2015-02-11-installing-novadocker-with-dev/</guid><description>&lt;p&gt;This is a long-form response to &lt;a href="https://ask.openstack.org/en/question/60679/installing-docker-on-openstack-with-ubuntu/"&gt;this question&lt;/a&gt;, and describes
how to get the &lt;a href="http://github.com/stackforge/nova-docker/"&gt;nova-docker&lt;/a&gt; driver up running with &lt;a href="http://devstack.org/"&gt;devstack&lt;/a&gt;
under Ubuntu 14.04 (Trusty). I wrote a &lt;a href="https://blog.oddbit.com/post/2015-02-06-installing-nova-docker-on-fedo/"&gt;similar post&lt;/a&gt; for Fedora
21, although that one was using the &lt;a href="http://openstack.redhat.com/"&gt;RDO&lt;/a&gt; Juno packages, while this
one is using &lt;a href="http://devstack.org/"&gt;devstack&lt;/a&gt; and the upstream sources.&lt;/p&gt;
&lt;h2 id="getting-started"&gt;Getting started&lt;/h2&gt;
&lt;p&gt;We&amp;rsquo;ll be using the &lt;a href="https://cloud-images.ubuntu.com/trusty/current/"&gt;Ubuntu 14.04 cloud image&lt;/a&gt; (because my test
environment runs on &lt;a href="http://www.openstack.org/"&gt;OpenStack&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;First, let&amp;rsquo;s install a few prerequisites:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo apt-get update
$ sudo apt-get -y install git git-review python-pip python-dev
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And generally make sure things are up-to-date:&lt;/p&gt;</description></item><item><title>External networking for Kubernetes services</title><link>https://blog.oddbit.com/post/2015-02-10-external-networking-for-kubern/</link><pubDate>Tue, 10 Feb 2015 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2015-02-10-external-networking-for-kubern/</guid><description>&lt;p&gt;I have recently started running some &amp;ldquo;real&amp;rdquo; services (that is,
&amp;ldquo;services being consumed by someone other than myself&amp;rdquo;) on top of
Kubernetes (running on bare metal), which means I suddenly had to
confront the question of how to provide external access to Kubernetes
hosted services. Kubernetes provides two solutions to this problem,
neither of which is particularly attractive out of the box:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;There is a field &lt;code&gt;createExternalLoadBalancer&lt;/code&gt; that can be set in a
service description. This is meant to integrate with load
balancers provided by your local cloud environment, but at the
moment there is only support for this when running under &lt;a href="https://cloud.google.com/compute/"&gt;GCE&lt;/a&gt;.&lt;/p&gt;</description></item><item><title>Installing nova-docker on Fedora 21/RDO Juno</title><link>https://blog.oddbit.com/post/2015-02-06-installing-nova-docker-on-fedo/</link><pubDate>Fri, 06 Feb 2015 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2015-02-06-installing-nova-docker-on-fedo/</guid><description>&lt;p&gt;This post comes about indirectly by a request on IRC in &lt;code&gt;#rdo&lt;/code&gt; for help getting &lt;a href="https://github.com/stackforge/nova-docker"&gt;nova-docker&lt;/a&gt; installed on Fedora 21. I ran through the process from start to finish and decided to write everything down for posterity.&lt;/p&gt;
&lt;h2 id="getting-started"&gt;Getting started&lt;/h2&gt;
&lt;p&gt;I started with the &lt;a href="https://getfedora.org/en/cloud/download/"&gt;Fedora 21 Cloud Image&lt;/a&gt;, because I&amp;rsquo;m
installing onto OpenStack and the cloud images include
some features that are useful in this environment.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ll be using OpenStack packages from the &lt;a href="https://repos.fedorapeople.org/repos/openstack/openstack-juno/"&gt;RDO Juno&lt;/a&gt; repository.
Because there is often some skew between the RDO packages and the
current Fedora selinux policy, we&amp;rsquo;re going to start by putting SELinux
into permissive mode (sorry, Dan):&lt;/p&gt;</description></item><item><title>Creating minimal Docker images from dynamically linked ELF binaries</title><link>https://blog.oddbit.com/post/2015-02-05-creating-minimal-docker-images/</link><pubDate>Thu, 05 Feb 2015 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2015-02-05-creating-minimal-docker-images/</guid><description>&lt;p&gt;In this post, we&amp;rsquo;ll look at a method for building minimal Docker
images for dynamically linked ELF binaries, and then at &lt;a href="https://github.com/larsks/dockerize"&gt;a
tool&lt;/a&gt; for automating this process.&lt;/p&gt;
&lt;p&gt;It is tempting, when creating a simple Docker image, to start with one
of the images provided by the major distributions. For example, if
you need an image that provides &lt;code&gt;tcpdump&lt;/code&gt; for use on your &lt;a href="http://www.projectatomic.io/"&gt;Atomic&lt;/a&gt;
host, you might do something like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM fedora
RUN yum -y install tcpdump
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And while this will work, you end up consuming 250MB for &lt;code&gt;tcpdump&lt;/code&gt;.
In theory, the layering mechanism that Docker uses to build images
will reduce the practical impact of this (because other images based on
the &lt;code&gt;fedora&lt;/code&gt; image will share the common layers), but in practice the
size is noticeable, especially if you often find yourself pulling this
image into a fresh environment with no established cache.&lt;/p&gt;</description></item><item><title>Docker vs. PrivateTmp</title><link>https://blog.oddbit.com/post/2015-01-18-docker-vs-privatetmp/</link><pubDate>Sun, 18 Jan 2015 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2015-01-18-docker-vs-privatetmp/</guid><description>&lt;p&gt;While working with Docker &lt;a href="https://blog.oddbit.com/post/2015-01-17-running-novalibvirt-and-novado/"&gt;the other day&lt;/a&gt;, I ran into an
undesirable interaction between Docker and &lt;a href="http://www.freedesktop.org/wiki/Software/systemd/"&gt;systemd&lt;/a&gt; services that
utilize the &lt;code&gt;PrivateTmp&lt;/code&gt; directive.&lt;/p&gt;
&lt;p&gt;The &lt;a href="http://www.freedesktop.org/software/systemd/man/systemd.exec.html#PrivateTmp="&gt;PrivateTmp&lt;/a&gt; directive, if &lt;code&gt;true&lt;/code&gt;, &amp;ldquo;sets up a new file system
namespace for the executed processes and mounts private &lt;code&gt;/tmp&lt;/code&gt; and
&lt;code&gt;/var/tmp&lt;/code&gt; directories inside it that is not shared by processes outside
of the namespace&amp;rdquo;. This is a great idea from a &lt;a href="https://danwalsh.livejournal.com/51459.html"&gt;security
perspective&lt;/a&gt;, but can cause some unanticipated consequences.&lt;/p&gt;
&lt;h2 id="the-problem-in-a-nutshell"&gt;The problem in a nutshell&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Start a Docker container:&lt;/p&gt;</description></item><item><title>Running nova-libvirt and nova-docker on the same host</title><link>https://blog.oddbit.com/post/2015-01-17-running-novalibvirt-and-novado/</link><pubDate>Sat, 17 Jan 2015 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2015-01-17-running-novalibvirt-and-novado/</guid><description>&lt;p&gt;I regularly use &lt;a href="http://www.openstack.org/"&gt;OpenStack&lt;/a&gt; on my laptop with &lt;a href="http://www.libvirt.org/"&gt;libvirt&lt;/a&gt; as my
hypervisor. I was interested in experimenting with recent versions of
the &lt;a href="https://github.com/stackforge/nova-docker"&gt;nova-docker&lt;/a&gt; driver, but I didn&amp;rsquo;t have a spare system available
on which to run the driver, and I use my regular &lt;code&gt;nova-compute&lt;/code&gt; service
often enough that I didn&amp;rsquo;t want to simply disable it temporarily in
favor of &lt;code&gt;nova-docker&lt;/code&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;NB&lt;/strong&gt; As pointed out by &lt;em&gt;gustavo&lt;/em&gt; in the comments, running two
&lt;code&gt;neutron-openvswitch-agents&lt;/code&gt; on the same host &amp;ndash; as suggested in this
article &amp;ndash; is going to lead to nothing but sadness and doom. So
kids, don&amp;rsquo;t try this at home. I&amp;rsquo;m leaving the article here because I
think it still has some interesting bits.&lt;/p&gt;</description></item><item><title>Building a minimal web server for testing Kubernetes</title><link>https://blog.oddbit.com/post/2015-01-04-building-a-minimal-web-server-/</link><pubDate>Sun, 04 Jan 2015 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2015-01-04-building-a-minimal-web-server-/</guid><description>&lt;p&gt;I have recently been doing some work with &lt;a href="https://github.com/googlecloudplatform/kubernetes"&gt;Kubernetes&lt;/a&gt;, and wanted
to put together a minimal image with which I could test service and
pod deployment. Size in this case was critical: I wanted something
that would download quickly when initially deployed, because I am
often setting up and tearing down Kubernetes as part of my testing
(and some of my test environments have poor external bandwidth).&lt;/p&gt;
&lt;h2 id="building-thttpd"&gt;Building thttpd&lt;/h2&gt;
&lt;p&gt;My go-to minimal webserver is &lt;a href="http://acme.com/software/thttpd/"&gt;thttpd&lt;/a&gt;. For the normal case,
building the software is a simple matter of &lt;code&gt;./configure&lt;/code&gt; followed by
&lt;code&gt;make&lt;/code&gt;. This gets you a dynamically linked binary; using &lt;code&gt;ldd&lt;/code&gt; you
could build a Docker image containing only the necessary shared
libraries:&lt;/p&gt;</description></item><item><title>Building Docker images with Puppet</title><link>https://blog.oddbit.com/post/2014-10-22-building-docker-images-with-pu/</link><pubDate>Wed, 22 Oct 2014 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2014-10-22-building-docker-images-with-pu/</guid><description>&lt;p&gt;I like &lt;a href="http://docker.com/"&gt;Docker&lt;/a&gt;, but I&amp;rsquo;m not a huge fan of using shell scripts for
complex system configuration&amp;hellip;and Dockerfiles are basically giant
shell scripts.&lt;/p&gt;
&lt;p&gt;I was curious whether or not it would be possible to use Puppet during
the &lt;code&gt;docker build&lt;/code&gt; process. As a test case, I used the
&lt;a href="https://github.com/saz/puppet-ssh"&gt;ssh&lt;/a&gt; module included in the openstack-puppet-modules package.&lt;/p&gt;
&lt;p&gt;I started with a manifest like this (in &lt;code&gt;puppet/node.pp&lt;/code&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class { 'ssh': }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And a Dockerfile like this:&lt;/p&gt;</description></item><item><title>Docker networking with dedicated network containers</title><link>https://blog.oddbit.com/post/2014-10-06-docker-networking-with-dedicat/</link><pubDate>Mon, 06 Oct 2014 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2014-10-06-docker-networking-with-dedicat/</guid><description>&lt;p&gt;The current version of Docker has a very limited set of networking
options:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;bridge&lt;/code&gt; &amp;ndash; connect a container to the Docker bridge&lt;/li&gt;
&lt;li&gt;&lt;code&gt;host&lt;/code&gt; &amp;ndash; run the container in the global network namespace&lt;/li&gt;
&lt;li&gt;&lt;code&gt;container:xxx&lt;/code&gt; &amp;ndash; connect a container to the network namespace of
another container&lt;/li&gt;
&lt;li&gt;&lt;code&gt;none&lt;/code&gt; &amp;ndash; do not configure any networking&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you need something more than that, you can use a tool like
&lt;a href="https://github.com/jpetazzo/pipework"&gt;pipework&lt;/a&gt; to provision additional network interfaces inside the
container, but this leads to a synchronization problem: &lt;code&gt;pipework&lt;/code&gt; can
only be used after your container is running. This means that when
starting your container, you must have logic that will wait until the
necessary networking is available before starting your service.&lt;/p&gt;</description></item><item><title>Docker plugin bugs</title><link>https://blog.oddbit.com/post/2014-09-01-docker-plugin-bugs/</link><pubDate>Mon, 01 Sep 2014 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2014-09-01-docker-plugin-bugs/</guid><description>&lt;p&gt;This is a companion to my &lt;a href="https://blog.oddbit.com/post/2014-08-30-docker-plugin-for-openstack-he/"&gt;article on the Docker plugin for Heat&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;While writing that article, I encountered a number of bugs in the
Docker plugin and elsewhere. I&amp;rsquo;ve submitted patches for most of the
issues I encountered:&lt;/p&gt;
&lt;h2 id="bugs-in-the-heat-plugin"&gt;Bugs in the Heat plugin&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://bugs.launchpad.net/heat/&amp;#43;bug/1364017"&gt;https://bugs.launchpad.net/heat/+bug/1364017&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;docker plugin fails to delete a container resource in
&lt;code&gt;CREATE_FAILED&lt;/code&gt; state.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://bugs.launchpad.net/heat/&amp;#43;bug/1364041"&gt;https://bugs.launchpad.net/heat/+bug/1364041&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;docker plugin &lt;code&gt;volumes_from&lt;/code&gt; parameter should be a list.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://bugs.launchpad.net/heat/&amp;#43;bug/1364039"&gt;https://bugs.launchpad.net/heat/+bug/1364039&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;docker plugin &lt;code&gt;volumes_from&lt;/code&gt; parameter results in an error&lt;/p&gt;</description></item><item><title>Annotated documentation for DockerInc::Docker::Container</title><link>https://blog.oddbit.com/post/2014-08-30-docker-contain-doc/</link><pubDate>Sat, 30 Aug 2014 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2014-08-30-docker-contain-doc/</guid><description>&lt;p&gt;This is a companion to my &lt;a href="https://blog.oddbit.com/post/2014-08-30-docker-plugin-for-openstack-he/"&gt;article on the Docker plugin for Heat&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="dockerincdockercontainer"&gt;DockerInc::Docker::Container&lt;/h2&gt;
&lt;h3 id="properties"&gt;Properties&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;cmd&lt;/code&gt; : List&lt;/p&gt;
&lt;p&gt;Command to run after spawning the container.&lt;/p&gt;
&lt;p&gt;Optional property.&lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; cmd: [ 'thttpd', '-C', '/etc/thttpd.conf', '-D', '-c', '*.cgi']
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;dns&lt;/code&gt; : List&lt;/p&gt;
&lt;p&gt;Set custom DNS servers.&lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; dns:
 - 8.8.8.8
 - 8.8.4.4
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;docker_endopint&lt;/code&gt; : String&lt;/p&gt;
&lt;p&gt;Docker daemon endpoint. By default the local Docker daemon will
be used.&lt;/p&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; docker_endpoint: tcp://192.168.1.100:2375
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;env&lt;/code&gt; : String&lt;/p&gt;</description></item><item><title>Docker plugin for OpenStack Heat</title><link>https://blog.oddbit.com/post/2014-08-30-docker-plugin-for-openstack-he/</link><pubDate>Sat, 30 Aug 2014 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2014-08-30-docker-plugin-for-openstack-he/</guid><description>&lt;p&gt;I have been looking at both Docker and OpenStack recently. In my &lt;a href="https://blog.oddbit.com/post/2014-08-28-novadocker-and-environment-var/"&gt;last
post&lt;/a&gt; I talked a little about the &lt;a href="https://github.com/stackforge/nova-docker"&gt;Docker driver for Nova&lt;/a&gt;; in
this post I&amp;rsquo;ll be taking an in-depth look at the Docker plugin for
Heat, which has been available &lt;a href="https://blog.docker.com/2014/03/docker-will-be-in-openstack-icehouse/"&gt;since the Icehouse release&lt;/a&gt; but is
surprisingly under-documented.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://blog.docker.com/2014/03/docker-will-be-in-openstack-icehouse/"&gt;release announcement&lt;/a&gt; on the Docker blog includes an
example Heat template, but it is unfortunately grossly inaccurate and
has led many people astray. In particular:&lt;/p&gt;</description></item><item><title>nova-docker and environment variables</title><link>https://blog.oddbit.com/post/2014-08-28-novadocker-and-environment-var/</link><pubDate>Thu, 28 Aug 2014 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2014-08-28-novadocker-and-environment-var/</guid><description>&lt;p&gt;I&amp;rsquo;ve been playing with &lt;a href="https://docker.com/"&gt;Docker&lt;/a&gt; a bit recently, and decided to take
a look at the &lt;a href="https://github.com/stackforge/nova-docker"&gt;nova-docker&lt;/a&gt; driver for &lt;a href="http://openstack.org/"&gt;OpenStack&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;nova-docker&lt;/code&gt; driver lets Nova, the OpenStack Compute service,
spawn Docker containers instead of hypervisor-based servers. For
certain workloads, this leads to better resource utilization than you
would get with a hypervisor-based solution, while at the same time
givin you better support for multi-tenancy and flexible networking
than you get with Docker by itself.&lt;/p&gt;</description></item><item><title>Four ways to connect a docker container to a local network</title><link>https://blog.oddbit.com/post/2014-08-11-four-ways-to-connect-a-docker/</link><pubDate>Mon, 11 Aug 2014 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2014-08-11-four-ways-to-connect-a-docker/</guid><description>&lt;p&gt;&lt;strong&gt;Update (2018-03-22)&lt;/strong&gt; Since I wrote this document back in 2014,
Docker has developed the &lt;a href="https://docs.docker.com/network/macvlan/"&gt;macvlan network
driver&lt;/a&gt;. That gives you a
&lt;em&gt;supported&lt;/em&gt; mechanism for direct connectivity to a local layer 2
network. I&amp;rsquo;ve &lt;a href="https://blog.oddbit.com/2018/03/12/using-docker-macvlan-networks/"&gt;written an article about working with the macvlan
driver&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;This article discusses four ways to make a Docker container appear on
a local network. These are not suggested as practical solutions, but
are meant to illustrate some of the underlying network technology
available in Linux.&lt;/p&gt;</description></item><item><title>Tracking down a kernel bug with git bisect</title><link>https://blog.oddbit.com/post/2014-07-21-tracking-down-a-kernel-bug-wit/</link><pubDate>Mon, 21 Jul 2014 00:00:00 +0000</pubDate><guid>https://blog.oddbit.com/post/2014-07-21-tracking-down-a-kernel-bug-wit/</guid><description>&lt;p&gt;After a recent upgrade of my Fedora 20 system to kernel 3.15.mumble, I
started running into a problem (&lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1121345"&gt;BZ 1121345&lt;/a&gt;) with my &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;
containers. Operations such as &lt;code&gt;su&lt;/code&gt; or &lt;code&gt;runuser&lt;/code&gt; would fail with the
singularly unhelpful &lt;code&gt;System error&lt;/code&gt; message:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker run -ti fedora /bin/bash
bash-4.2# su -c 'uptime'
su: System error
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hooking up something (like, say, &lt;code&gt;socat unix-listen:/dev/log -&lt;/code&gt;) to
&lt;code&gt;/dev/log&lt;/code&gt; revealed that the system was logging:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Jul 19 14:31:18 su: PAM audit_log_acct_message() failed: Operation not permitted
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Downgrading the kernel to 3.14 immediately resolved the problem,
suggesting that this was at least partly a kernel issue. This seemed
like a great opportunity to play with the &lt;a href="http://git-scm.com/docs/git-bisect"&gt;git bisect&lt;/a&gt; command,
which uses a binary search to find which commit introduced a
particular problem.&lt;/p&gt;</description></item></channel></rss>