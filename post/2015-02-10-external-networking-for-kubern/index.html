<!doctype html><html lang=en><head><title>External networking for Kubernetes services :: blog.oddbit.com</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="I have recently started running some &ldquo;real&rdquo; services (that is, &ldquo;services being consumed by someone other than myself&rdquo;) on top of Kubernetes (running on bare metal), which means I suddenly had to confront the question of how to provide external access to Kubernetes hosted services. Kubernetes provides two solutions to this problem, neither of which is particularly attractive out of the box:
There is a field createExternalLoadBalancer that can be set in a service description. This is meant to integrate with load balancers provided by your local cloud environment, but at the moment there is only support for this when running under GCE.
"><meta name=keywords content><meta name=robots content="noodp"><link rel=canonical href=https://blog.oddbit.com/post/2015-02-10-external-networking-for-kubern/><script async src="https://www.googletagmanager.com/gtag/js?id=G-G1FYT93ENG"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-G1FYT93ENG")}</script><link rel=stylesheet href=https://blog.oddbit.com/css/buttons.min.86f6b4c106b6c6eb690ae5203d36b442c1f66f718ff4e8164fa86cf6c61ad641.css><link rel=stylesheet href=https://blog.oddbit.com/css/code.min.d529ea4b2fb8d34328d7d31afc5466d5f7bc2f0bc9abdd98b69385335d7baee4.css><link rel=stylesheet href=https://blog.oddbit.com/css/fonts.min.5bb7ed13e1d00d8ff39ea84af26737007eb5051b157b86fc24487c94f3dc8bbe.css><link rel=stylesheet href=https://blog.oddbit.com/css/footer.min.eb8dfc2c6a7eafa36cd3ba92d63e69e849e2200e0002a228d137f236b09ecd75.css><link rel=stylesheet href=https://blog.oddbit.com/css/gist.min.a751e8b0abe1ba8bc53ced52a38b19d8950fe78ca29454ea8c2595cf26aad5c0.css><link rel=stylesheet href=https://blog.oddbit.com/css/header.min.75c7eb0e2872d95ff48109c6647d0223a38db52e2561dd87966eb5fc7c6bdac6.css><link rel=stylesheet href=https://blog.oddbit.com/css/main.min.36833afd348409fc6c3d09d0897c5833d9d5bf1ff31f5e60ea3ee42ce2b1268c.css><link rel=stylesheet href=https://blog.oddbit.com/css/menu.min.3c17467ebeb3d38663dce68f71f519901124fa5cbb4519b2fb0667a21e9aca39.css><link rel=stylesheet href=https://blog.oddbit.com/css/pagination.min.bbb986dbce00a5ce5aca0504b7925fc1c581992a4bf57f163e5d69cc1db7d836.css><link rel=stylesheet href=https://blog.oddbit.com/css/post.min.e6dddd258e64c83e05cec0cd49c05216742d42fc8ecbfbe6b67083412b609bd3.css><link rel=stylesheet href=https://blog.oddbit.com/css/syntax.min.a0773cce9310cb6d8ed23e50f005448facf29a53001b57e038828daa466b25c0.css><link rel=stylesheet href=https://blog.oddbit.com/css/terminal.min.e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855.css><link rel=stylesheet href=https://blog.oddbit.com/css/terms.min.b81791663c3790e738e571cdbf802312390d30e4b1d8dc9d814a5b5454d0ac11.css><link rel=stylesheet href=https://blog.oddbit.com/style.css><link rel="shortcut icon" href=https://blog.oddbit.com/favicon.png><link rel=apple-touch-icon href=https://blog.oddbit.com/apple-touch-icon.png><meta name=twitter:card content="summary"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="og:title" content="External networking for Kubernetes services"><meta property="og:description" content="I have recently started running some &ldquo;real&rdquo; services (that is, &ldquo;services being consumed by someone other than myself&rdquo;) on top of Kubernetes (running on bare metal), which means I suddenly had to confront the question of how to provide external access to Kubernetes hosted services. Kubernetes provides two solutions to this problem, neither of which is particularly attractive out of the box:
There is a field createExternalLoadBalancer that can be set in a service description. This is meant to integrate with load balancers provided by your local cloud environment, but at the moment there is only support for this when running under GCE.
"><meta property="og:url" content="https://blog.oddbit.com/post/2015-02-10-external-networking-for-kubern/"><meta property="og:site_name" content="blog.oddbit.com"><meta property="og:image" content="https://blog.oddbit.com/og-image.png"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="627"><meta property="article:section" content="tech"><meta property="article:published_time" content="2015-02-10 00:00:00 +0000 UTC"></head><body><div class="container center"><header class=header><div class=header__inner><div class=header__logo><a href=/><div class=logo>the odd bit blog</div></a></div><ul class="menu menu--mobile"><li class=menu__trigger>Menu&nbsp;▾</li><li><ul class=menu__dropdown><li><a href=/>/</a></li><li><a href=https://oddbit.com>/about</a></li><li><a href=/posts>/posts</a></li><li><a href=/tags>/tags</a></li><li><a href=/archive>/archive</a></li><li><a href=/rss.xml>/feed</a></li><li><a href=https://github.com/larsks>→Github</a></li><li><a href=https://hachyderm.io/@larsks>→Mastodon</a></li><li><a href=https://twitter.com/larsks>→Twitter</a></li></ul></li></ul></div><nav class=navigation-menu><ul class="navigation-menu__inner menu--desktop"><li><a href=/>/</a></li><li><a href=https://oddbit.com>/about</a></li><li><a href=/posts>/posts</a></li><li><a href=/tags>/tags</a></li><li><a href=/archive>/archive</a></li><li><a href=/rss.xml>/feed</a></li><li><ul class=menu><li class=menu__trigger>&nbsp;▾</li><li><ul class=menu__dropdown><li><a href=https://github.com/larsks>→Github</a></li><li><a href=https://hachyderm.io/@larsks>→Mastodon</a></li><li><a href=https://twitter.com/larsks>→Twitter</a></li></ul></li></ul></li></ul></nav></header><div class=content><article class=post><h1 class=post-title><a href=https://blog.oddbit.com/post/2015-02-10-external-networking-for-kubern/>External networking for Kubernetes services</a></h1><div class=post-meta><time class=post-date>2015-02-10&nbsp;[Updated: 2023-02-16]</time></div><span class=post-tags>#<a href=https://blog.oddbit.com/tags/docker/>docker</a>&nbsp;
#<a href=https://blog.oddbit.com/tags/kubernetes/>kubernetes</a>&nbsp;</span><div class=post-content><div><p>I have recently started running some &ldquo;real&rdquo; services (that is,
&ldquo;services being consumed by someone other than myself&rdquo;) on top of
Kubernetes (running on bare metal), which means I suddenly had to
confront the question of how to provide external access to Kubernetes
hosted services. Kubernetes provides two solutions to this problem,
neither of which is particularly attractive out of the box:</p><ol><li><p>There is a field <code>createExternalLoadBalancer</code> that can be set in a
service description. This is meant to integrate with load
balancers provided by your local cloud environment, but at the
moment there is only support for this when running under <a href=https://cloud.google.com/compute/>GCE</a>.</p></li><li><p>A service description can have a list of public IP addresses
associated with it in the <code>publicIPS</code> field. This will cause
<code>kube-proxy</code> to create rules in the <code>KUBE-PROXY</code> chain of your
<code>nat</code> table to direct traffic inbound to those addresses to the
appropriate local <code>kube-proxy</code> port.</p></li></ol><p>The second option is a good starting point, since if you were to
simply list the public IP addresses of your Kubernetes minions in the
<code>publicIPs</code> field, everything would Just Work. That is, inbound
traffic to the appropriate port on your minions would get directed to
<code>kube-proxy</code> by the <code>nat</code> rules. That&rsquo;s great for simple cases, but
in practice it means that you cannot have more that <em>N</em> services
exposed on a given port where <em>N</em> is the number of minions in your
cluster. That limit is difficult if you &ndash; like I do &ndash; have an
all-in-one (e.g., on a single host) Kubernetes deployment on which you
wish to host multiple web services exposed on port 80 (and even in a
larger environment, you really don&rsquo;t want &ldquo;number of things on port
XX&rdquo; tightly coupled to &ldquo;number of minions&rdquo;).</p><h2 id=introducing-kiwi>Introducing Kiwi<a href=#introducing-kiwi class=hanchor arialabel=Anchor>#</a></h2><p>To overcome this problem, I wrote <a href=http://github.com/larsks/kiwi/>Kiwi</a>, a service that listens to
Kubernetes for events concerning new/modified/deleted services, and in
response to those events manages (a) the assignment of IP addresses to
network interfaces on your minions and (b) creating additional
firewall rules to permit traffic inbound to your services to pass a
default-deny firewall configuration.</p><p>Kiwi uses <a href=https://github.com/coreos/etcd>etcd</a> to coordinate ownership of IP addresses between
minions in your Kubernetes cluster.</p><h2 id=how-it-works>How it works<a href=#how-it-works class=hanchor arialabel=Anchor>#</a></h2><p>Kiwi listens to event streams from both Kubernetes and Etcd.</p><p>On the Kubernetes side, Kiwi listens to <code>/api/v1beta/watch/services</code>,
which produces events in response to new, modified, or deleted
services. The Kubernetes API uses a server-push model, in which a
client makes a single HTTP request and then receives a series of
events over the same connection. A event looks something like:</p><pre><code>{
  &quot;type&quot;: &quot;ADDED&quot;,
  &quot;object&quot;: {
    &quot;portalIP&quot;: &quot;10.254.93.176&quot;,
    &quot;containerPort&quot;: 80,
    &quot;publicIPs&quot;: [
      &quot;192.168.1.100&quot;
    ],
    &quot;selector&quot;: {
      &quot;name&quot;: &quot;test-web&quot;
    },
    &quot;protocol&quot;: &quot;TCP&quot;,
    &quot;port&quot;: 8080,
    &quot;kind&quot;: &quot;Service&quot;,
    &quot;id&quot;: &quot;test-web&quot;,
    &quot;uid&quot;: &quot;72bc1286-a440-11e4-b83e-20cf30467e62&quot;,
    &quot;creationTimestamp&quot;: &quot;2015-01-24T22:15:43-05:00&quot;,
    &quot;selfLink&quot;: &quot;/api/v1beta1/services/test-web&quot;,
    &quot;resourceVersion&quot;: 245,
    &quot;apiVersion&quot;: &quot;v1beta1&quot;,
    &quot;namespace&quot;: &quot;default&quot;
  }
}
</code></pre><p>I am using the Python <a href=http://docs.python-requests.org/en/latest/>requests</a> library, which it turns out <a href=https://github.com/kennethreitz/requests/issues/2433>has a
bug</a> in its handling of streaming server responses, but I was
able to work around that issue once I realized what was going on.</p><p>On the Etcd side, Kiwi uses keys under the <code>/kiwi/publicips</code> prefix to
coordinate address ownership among Kiwi instances. It listens to
events from Etcd regarding key create/delete/set/etc operations in
this prefix by calling
<code>/v2/keys/kiwi/publicips?watch=true&amp;recursive=true</code>. This is a
long-poll request, rather than a streaming request: that means that a
request will only ever receive a single event, but it may need to wait
for a while before it receives that response. This model worked well
with the <code>requests</code> library out of the box.</p><p>After receiving an event from Kubernetes, Kiwi iterates over the
public IP addresses in the <code>publicIPs</code> key, and for any address that
is not already being manged by the local instance it makes a claim on
that address by attempting to atomically create a key in etcd under
<code>/kiwi/publicips/</code> (such as <code>/kiwi/publicips/192.168.1.100</code>). If this
attempt succeeds, Kiwi on the local minion has claimed that address
and proceeds to assign it to the local interface. If the attempt to
set that key does not succeed, it means the address is already being
managed by Kiwi on another minion.</p><p>The address keys are set with a TTL of 20 seconds, after which they
will be expired. If an address expires, other Kiwi instances will
receive notification from Etcd and ownership of that address will
transfer to another Kiwi instance.</p><h2 id=getting-started-with-kiwi>Getting started with Kiwi<a href=#getting-started-with-kiwi class=hanchor arialabel=Anchor>#</a></h2><p>The easiest way to get started with Kiwi is to use the <a href=https://registry.hub.docker.com/u/larsks/kiwi/>larsks/kiwi</a>
Docker image that is automatically built from the <a href=http://github.com/larsks/kiwi/>Git
repository</a>. For example, if you want to host public ip
addresses on <code>eth0</code> in the range <code>192.168.1.32/28</code>, you would start it
like this:</p><pre><code>docker run --privileged --net=host larsks/kiwi \
  --interface eth0 \
  --range 192.168.1.32/28
</code></pre><p>You need both <code>--privileged</code> and <code>--net=host</code> in order for Kiwi to
assign addresses to your host interfaces and to manage the iptables
configuration.</p><h2 id=an-example>An Example<a href=#an-example class=hanchor arialabel=Anchor>#</a></h2><p>Start Kiwi as described above. Next, plae the following content in a
file called <code>service.yaml</code>:</p><pre><code>kind: Service
apiVersion: v1beta1
id: test-web
port: 8888
selector:
  name: test-web
containerPort: 80
publicIPs:
  - 192.168.1.100
</code></pre><p>Create the service using <code>kubectl</code>:</p><pre><code>kubectl create -f service.yaml
</code></pre><p>After a short pause, you should see the address show up on interface
<code>eth0</code>; the entry will look something like:</p><pre><code>inet 192.168.1.100/32 scope global dynamic eth0:kube
       valid_lft 17sec preferred_lft 17sec
</code></pre><p>The <code>eth0:kube</code> is a label applied to the address; this allows Kiwi to
clean up these addresses at startup (by getting a list of
Kiwi-configured addresses with <code>ip addr show label eth0:kube</code>).</p><p>The <code>valid_lft</code> and <code>preferred_lft</code> fields control the lifetime of the
interface. When these counters reach 0, the addresses are removed by
the kernel. This ensure that if Kiwi dies, the addresses can
successfully be re-assigned on another node.</p></div></div><script src=https://utteranc.es/client.js repo=larsks/blog.oddbit.com issue-term=pathname label=comment theme=github-light crossorigin=anonymous async></script></article></div><footer class=footer><div class=footer__inner><div class="copyright copyright--user"><span>Lars Kellogg-Stedman</span>
<span>:: <a href=https://github.com/panr/hugo-theme-terminal target=_blank>Theme</a> made by <a href=https://github.com/panr target=_blank>panr</a></span></div></div></footer><script type=text/javascript src=/bundle.min.js></script><script src=/js/mermaid.min.js></script><script>mermaid.initialize({startOnLoad:!0})</script></div></body></html>