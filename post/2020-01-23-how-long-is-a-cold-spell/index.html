<!doctype html><html lang=en><head><title>How long is a cold spell in Boston? :: blog.oddbit.com</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="We&amp;rsquo;ve had some wacky weather recently. In the space of a week, the temperature went from a high of about 75°F to a low around 15°F. This got me to thinking about what constitutes &amp;ldquo;normal&amp;rdquo; weather here in the Boston area, and in particular, how common it is to have a string of consecutive days in which the high temperature stays below freezing. While this was an interesting question in itself, it also seemed like a great opportunity to learn a little about Pandas, the Python data analysis framework."><meta name=keywords content><meta name=robots content="noodp"><link rel=canonical href=https://blog.oddbit.com/post/2020-01-23-how-long-is-a-cold-spell/><link rel=stylesheet href=https://blog.oddbit.com/styles.css><link rel=stylesheet href=https://blog.oddbit.com/style.css><link rel="shortcut icon" href=https://blog.oddbit.com/img/theme-colors/orange.png><link rel=apple-touch-icon href=https://blog.oddbit.com/img/theme-colors/orange.png><meta name=twitter:card content="summary"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="og:title" content="How long is a cold spell in Boston?"><meta property="og:description" content="We&amp;rsquo;ve had some wacky weather recently. In the space of a week, the temperature went from a high of about 75°F to a low around 15°F. This got me to thinking about what constitutes &amp;ldquo;normal&amp;rdquo; weather here in the Boston area, and in particular, how common it is to have a string of consecutive days in which the high temperature stays below freezing. While this was an interesting question in itself, it also seemed like a great opportunity to learn a little about Pandas, the Python data analysis framework."><meta property="og:url" content="https://blog.oddbit.com/post/2020-01-23-how-long-is-a-cold-spell/"><meta property="og:site_name" content="blog.oddbit.com"><meta property="og:image" content="https://blog.oddbit.com/img/favicon/orange.png"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="627"><meta property="article:section" content="tech"><meta property="article:published_time" content="2020-01-23 00:00:00 +0000 UTC"></head><body class=orange><div class="container center headings--one-size"><header class=header><div class=header__inner><div class=header__logo><a href=/><div class=logo>the odd bit blog</div></a></div><ul class="menu menu--mobile"><li class=menu__trigger>Menu&nbsp;▾</li><li><ul class=menu__dropdown><li><a href=/>/</a></li><li><a href=https://oddbit.com>/about</a></li><li><a href=/posts>/posts</a></li><li><a href=/tags>/tags</a></li><li><a href=/archive>/archive</a></li><li><a href=/rss.xml>/feed</a></li><li><a href=https://github.com/larsks>→Github</a></li><li><a href=https://hachyderm.io/@larsks>→Mastodon</a></li><li><a href=https://twitter.com/larsks>→Twitter</a></li></ul></li></ul></div><nav class=navigation-menu><ul class="navigation-menu__inner menu--desktop"><li><a href=/>/</a></li><li><a href=https://oddbit.com>/about</a></li><li><a href=/posts>/posts</a></li><li><a href=/tags>/tags</a></li><li><a href=/archive>/archive</a></li><li><a href=/rss.xml>/feed</a></li><li><ul class=menu><li class=menu__trigger>&nbsp;▾</li><li><ul class=menu__dropdown><li><a href=https://github.com/larsks>→Github</a></li><li><a href=https://hachyderm.io/@larsks>→Mastodon</a></li><li><a href=https://twitter.com/larsks>→Twitter</a></li></ul></li></ul></li></ul></nav></header><div class=content><article class=post><h1 class=post-title><a href=https://blog.oddbit.com/post/2020-01-23-how-long-is-a-cold-spell/>How long is a cold spell in Boston?</a></h1><div class=post-meta><time class=post-date>2020-01-23 ::
[Updated :: 2023-02-16]</time></div><span class=post-tags>#<a href=https://blog.oddbit.com/tags/datascience/>datascience</a>&nbsp;
#<a href=https://blog.oddbit.com/tags/pandas/>pandas</a>&nbsp;
#<a href=https://blog.oddbit.com/tags/python/>python</a>&nbsp;
#<a href=https://blog.oddbit.com/tags/climate/>climate</a>&nbsp;</span><div class=post-content><div><p>We&rsquo;ve had some wacky weather recently. In the space of a week, the temperature went from a high of about 75°F to a low around 15°F. This got me to thinking about what constitutes &ldquo;normal&rdquo; weather here in the Boston area, and in particular, how common it is to have a string of consecutive days in which the high temperature stays below freezing. While this was an interesting question in itself, it also seemed like a great opportunity to learn a little about <a href=https://pandas.pydata.org>Pandas</a>, the Python data analysis framework.</p><p>The first step was finding an appropriate dataset. <a href=https://www.noaa.gov/>NOAA</a> provides a <a href="https://www.ncdc.noaa.gov/cdo-web/search?datasetid=GHCND">daily summaries</a> dataset that includes daily high and low temperature; for Boston, this data extends back to about 1936.</p><p>The next step was figuring how to solve the problem. To be explicit, the question I&rsquo;m trying to answer is:</p><blockquote><p>For any given winter, what was the longest consecutive string of days in which the temperature stayed below freezing?</p></blockquote><p>There are several parts to this problem.</p><h2 id=reading-the-data>Reading the data<a href=#reading-the-data class=hanchor arialabel=Anchor>&#8983;</a></h2><p>We can read the data using Pandas&rsquo; <code>read_csv</code> method:</p><pre tabindex=0><code>df = pandas.read_csv(&#39;boston.csv&#39;)
</code></pre><p>This assumes of course that we have previously <code>import</code>ed the Pandas library:</p><pre tabindex=0><code>import pandas
</code></pre><p>Now we have a dataframe in <code>df</code>, but it&rsquo;s using a positional index (i.e., the first item is at index <code>0</code>, the second at <code>1</code>, etc), whereas we want it to use a date-based index. The data has a <code>DATE</code> column that we can turn into an appropriate index like this:</p><pre tabindex=0><code>df[&#39;DATE&#39;] = pandas.to_datetime(df[&#39;DATE&#39;])
df.set_index(df[&#39;DATE&#39;], inplace=True)
</code></pre><h2 id=which-winter>Which winter?<a href=#which-winter class=hanchor arialabel=Anchor>&#8983;</a></h2><p>I need to be able to group the data by &ldquo;winter&rdquo;. For example, dates from December 21, 2018 through March 20, 2019 would all be associated with &ldquo;winter 2018&rdquo;. It would be easy to group the data by <em>year</em> using Pandas&rsquo; <code>groupby</code> method:</p><pre tabindex=0><code>df.groupby(df[&#39;DATE&#39;].dt.year)...
</code></pre><p>But what&rsquo;s the equivalent for grouping by winter? My first attempt was a naive iterative solution:</p><pre tabindex=0><code>def get_winter_start(val):
    if (val.month == 10 and val.day &gt;= 20) or val.month &gt; 10:
        winter = val.year
    elif (val.month == 3 and val.day &lt;= 20) or val.month &lt; 3:
        winter = val.year-1
    else:
        winter = 0

    return winter

df[&#39;winter_start&#39;] = df[&#39;DATE&#39;].apply(get_winter_start)
</code></pre><p>This works, but it&rsquo;s not particular graceful and doesn&rsquo;t take advantage of any of the vector operations supported by Pandas. I eventually came up with a different solution. First, create a boolean series that indicates whether a given date is in winter or not:</p><pre tabindex=0><code>df[&#39;winter&#39;] = (
    ((df[&#39;DATE&#39;].dt.month == 12) &amp; (df[&#39;DATE&#39;].dt.day &gt;= 20)) |
    (df[&#39;DATE&#39;].dt.month &lt; 3) |
    ((df[&#39;DATE&#39;].dt.month == 3) &amp; (df[&#39;DATE&#39;].dt.day &lt;= 20))
)
</code></pre><p>Next, use this boolean series to create a new dataframe that contains <em>only</em> dates in winter. Given this new data, the winter year is the current year for the month of December, or (the current year - 1) for months in Janurary, February, and March:</p><pre tabindex=0><code>winter = df[df[&#39;winter&#39;]].copy()
winter[&#39;winter_start&#39;] = (
    winter[&#39;DATE&#39;].dt.year - (winter[&#39;DATE&#39;].dt.month &lt;= 3))
</code></pre><p>This seems to do the job. You&rsquo;ll note that in the above expression I&rsquo;m subtracting a boolean from an integer, which is in fact totally legal and I talk about that in more detail <a href=#bool>later on</a> in this article.</p><h2 id=finding-a-sequence-of-consecutive-days-an-iterative-solution>Finding a sequence of consecutive days: an iterative solution<a href=#finding-a-sequence-of-consecutive-days-an-iterative-solution class=hanchor arialabel=Anchor>&#8983;</a></h2><p>To find the longest sequence of days below freezing, I again started with an iterative solution:</p><pre tabindex=0><code>def max_dbf(val):
    acc = []
    cur = 0

    for i, row in val.iterrows():
        if row[&#39;TMAX&#39;] &lt;= 32:
            cur += 1
        else:
            if cur:
                acc.append(cur)
                cur = 0
    if cur:
        acc.append(cur)

    return max(acc)
</code></pre><p>Which I applied using Pandas&rsquo; <code>apply</code> method:</p><pre tabindex=0><code>res = winter.groupby(&#39;winter_start&#39;).apply(max_dbf)
</code></pre><p>This time it&rsquo;s not just ugly, but it&rsquo;s also noticeably slow. I started doing some research to figure out how to make it faster.</p><h2 id=finding-a-sequence-of-consecutive-days-a-pandas-solution>Finding a sequence of consecutive days: a Pandas solution<a href=#finding-a-sequence-of-consecutive-days-a-pandas-solution class=hanchor arialabel=Anchor>&#8983;</a></h2><p>In an answer to <a href=https://stackoverflow.com/questions/27626542/counting-consecutive-positive-value-in-python-array>this question</a> on Stack Overflow, user <a href=https://stackoverflow.com/users/487339/dsm>DSM</a> suggests that given a series, you can find the longest sequence of consecutive items matching a condition by first creating a boolean series <code>y</code> that is <code>True</code> (or <code>1</code>) for items that match the condition (and <code>False</code> or <code>0</code> otherwise), and then running:</p><pre tabindex=0><code>result = y * (y.groupby((y != y.shift()).cumsum()).cumcount() + 1)
</code></pre><p>Using that suggestion, I rewrote the <code>max_dbf</code> method to look like this:</p><pre tabindex=0><code>def max_dbf(val):
    y = val[&#39;TMAX&#39;] &lt;= 32
    res = y * (y.groupby((y != y.shift()).cumsum()).cumcount() + 1)
    return max(res)
</code></pre><p>&mldr;and you know what, it works! But what exactly is going on there? There&rsquo;s a reasonable explanation in <a href=https://stackoverflow.com/a/27626699/147356>the answer</a>, but I&rsquo;m new enough to Pandas that I wanted to work it out for myself.</p><h2 id=setting-the-stage>Setting the stage<a href=#setting-the-stage class=hanchor arialabel=Anchor>&#8983;</a></h2><p>In order to explore the operation of this expression, let&rsquo;s start with some sample data. This is the value of <code>TMAX</code> for the month of Janurary, 2018:</p><pre tabindex=0><code>data = [
  [&#39;2018-01-01&#39;, 13],
  [&#39;2018-01-02&#39;, 19],
  [&#39;2018-01-03&#39;, 29],
  [&#39;2018-01-04&#39;, 30],
  [&#39;2018-01-05&#39;, 24],
  [&#39;2018-01-06&#39;, 12],
  [&#39;2018-01-07&#39;, 17],
  [&#39;2018-01-08&#39;, 35],
  [&#39;2018-01-09&#39;, 43],
  [&#39;2018-01-10&#39;, 36],
  [&#39;2018-01-11&#39;, 51],
  [&#39;2018-01-12&#39;, 60],
  [&#39;2018-01-13&#39;, 61],
  [&#39;2018-01-14&#39;, 23],
  [&#39;2018-01-15&#39;, 21],
  [&#39;2018-01-16&#39;, 33],
  [&#39;2018-01-17&#39;, 34],
  [&#39;2018-01-18&#39;, 32],
  [&#39;2018-01-19&#39;, 34],
  [&#39;2018-01-20&#39;, 47],
  [&#39;2018-01-21&#39;, 49],
  [&#39;2018-01-22&#39;, 39],
  [&#39;2018-01-23&#39;, 55],
  [&#39;2018-01-24&#39;, 42],
  [&#39;2018-01-25&#39;, 30],
  [&#39;2018-01-26&#39;, 34],
  [&#39;2018-01-27&#39;, 53],
  [&#39;2018-01-28&#39;, 52],
  [&#39;2018-01-29&#39;, 43],
  [&#39;2018-01-30&#39;, 31],
  [&#39;2018-01-31&#39;, 30],
  ]

data_unzipped = list(zip(*data))
df = pandas.DataFrame({&#39;DATE&#39;: data_unzipped[0], &#39;TMAX&#39;: data_unzipped[1]})
</code></pre><p>Our initial dataframe looks like this:</p><table><thead><tr><th></th><th>DATE</th><th>TMAX</th></tr></thead><tbody><tr><td>0</td><td>2018-01-01</td><td>13</td></tr><tr><td>1</td><td>2018-01-02</td><td>19</td></tr><tr><td>2</td><td>2018-01-03</td><td>29</td></tr><tr><td>3</td><td>2018-01-04</td><td>30</td></tr><tr><td>4</td><td>2018-01-05</td><td>24</td></tr><tr><td>5</td><td>2018-01-06</td><td>12</td></tr><tr><td>6</td><td>2018-01-07</td><td>17</td></tr><tr><td>7</td><td>2018-01-08</td><td>35</td></tr><tr><td>8</td><td>2018-01-09</td><td>43</td></tr><tr><td>9</td><td>2018-01-10</td><td>36</td></tr><tr><td>10</td><td>2018-01-11</td><td>51</td></tr><tr><td>11</td><td>2018-01-12</td><td>60</td></tr><tr><td>12</td><td>2018-01-13</td><td>61</td></tr><tr><td>13</td><td>2018-01-14</td><td>23</td></tr><tr><td>14</td><td>2018-01-15</td><td>21</td></tr><tr><td>15</td><td>2018-01-16</td><td>33</td></tr><tr><td>16</td><td>2018-01-17</td><td>34</td></tr><tr><td>17</td><td>2018-01-18</td><td>32</td></tr><tr><td>18</td><td>2018-01-19</td><td>34</td></tr><tr><td>19</td><td>2018-01-20</td><td>47</td></tr><tr><td>20</td><td>2018-01-21</td><td>49</td></tr><tr><td>21</td><td>2018-01-22</td><td>39</td></tr><tr><td>22</td><td>2018-01-23</td><td>55</td></tr><tr><td>23</td><td>2018-01-24</td><td>42</td></tr><tr><td>24</td><td>2018-01-25</td><td>30</td></tr><tr><td>25</td><td>2018-01-26</td><td>34</td></tr><tr><td>26</td><td>2018-01-27</td><td>53</td></tr><tr><td>27</td><td>2018-01-28</td><td>52</td></tr><tr><td>28</td><td>2018-01-29</td><td>43</td></tr><tr><td>29</td><td>2018-01-30</td><td>31</td></tr><tr><td>30</td><td>2018-01-31</td><td>30</td></tr></tbody></table><h3 id=step-1>Step 1<a href=#step-1 class=hanchor arialabel=Anchor>&#8983;</a></h3><p>We first need to create a boolean series indicating whether or not the temperature is below freezing. We&rsquo;ll put this into the dataframe as series <code>freezing</code>:</p><pre tabindex=0><code>df[&#39;freezing&#39;] = df[&#39;TMAX&#39;] &lt;= 32
</code></pre><p>Our dataframe now looks like this:</p><table><thead><tr><th></th><th>DATE</th><th>TMAX</th><th>freezing</th></tr></thead><tbody><tr><td>0</td><td>2018-01-01</td><td>13</td><td>True</td></tr><tr><td>1</td><td>2018-01-02</td><td>19</td><td>True</td></tr><tr><td>2</td><td>2018-01-03</td><td>29</td><td>True</td></tr><tr><td>3</td><td>2018-01-04</td><td>30</td><td>True</td></tr><tr><td>4</td><td>2018-01-05</td><td>24</td><td>True</td></tr><tr><td>5</td><td>2018-01-06</td><td>12</td><td>True</td></tr><tr><td>6</td><td>2018-01-07</td><td>17</td><td>True</td></tr><tr><td>7</td><td>2018-01-08</td><td>35</td><td>False</td></tr><tr><td>8</td><td>2018-01-09</td><td>43</td><td>False</td></tr><tr><td>9</td><td>2018-01-10</td><td>36</td><td>False</td></tr><tr><td>10</td><td>2018-01-11</td><td>51</td><td>False</td></tr><tr><td>11</td><td>2018-01-12</td><td>60</td><td>False</td></tr><tr><td>12</td><td>2018-01-13</td><td>61</td><td>False</td></tr><tr><td>13</td><td>2018-01-14</td><td>23</td><td>True</td></tr><tr><td>14</td><td>2018-01-15</td><td>21</td><td>True</td></tr><tr><td>15</td><td>2018-01-16</td><td>33</td><td>False</td></tr><tr><td>16</td><td>2018-01-17</td><td>34</td><td>False</td></tr><tr><td>17</td><td>2018-01-18</td><td>32</td><td>True</td></tr><tr><td>18</td><td>2018-01-19</td><td>34</td><td>False</td></tr><tr><td>19</td><td>2018-01-20</td><td>47</td><td>False</td></tr><tr><td>20</td><td>2018-01-21</td><td>49</td><td>False</td></tr><tr><td>21</td><td>2018-01-22</td><td>39</td><td>False</td></tr><tr><td>22</td><td>2018-01-23</td><td>55</td><td>False</td></tr><tr><td>23</td><td>2018-01-24</td><td>42</td><td>False</td></tr><tr><td>24</td><td>2018-01-25</td><td>30</td><td>True</td></tr><tr><td>25</td><td>2018-01-26</td><td>34</td><td>False</td></tr><tr><td>26</td><td>2018-01-27</td><td>53</td><td>False</td></tr><tr><td>27</td><td>2018-01-28</td><td>52</td><td>False</td></tr><tr><td>28</td><td>2018-01-29</td><td>43</td><td>False</td></tr><tr><td>29</td><td>2018-01-30</td><td>31</td><td>True</td></tr><tr><td>30</td><td>2018-01-31</td><td>30</td><td>True</td></tr></tbody></table><h3 id=step-2>Step 2<a href=#step-2 class=hanchor arialabel=Anchor>&#8983;</a></h3><p>Now we start looking at the various components in our expression of interest. In this step, we are looking at the highlighted part below:</p><p>Instead of <code>y</code>, we&rsquo;re operating on the result of the previous step, <code>df['freezing']</code>. We&rsquo;ll place the result of this step into a new series named <code>step2</code> in the dataframe:</p><pre tabindex=0><code>df[&#39;step2&#39;] = df[&#39;freezing&#39;] != df[&#39;freezing&#39;].shift()
</code></pre><p>This gives us the following:</p><table><thead><tr><th></th><th>DATE</th><th>TMAX</th><th>freezing</th><th>step2</th></tr></thead><tbody><tr><td>0</td><td>2018-01-01</td><td>13</td><td>True</td><td>True</td></tr><tr><td>1</td><td>2018-01-02</td><td>19</td><td>True</td><td>False</td></tr><tr><td>2</td><td>2018-01-03</td><td>29</td><td>True</td><td>False</td></tr><tr><td>3</td><td>2018-01-04</td><td>30</td><td>True</td><td>False</td></tr><tr><td>4</td><td>2018-01-05</td><td>24</td><td>True</td><td>False</td></tr><tr><td>5</td><td>2018-01-06</td><td>12</td><td>True</td><td>False</td></tr><tr><td>6</td><td>2018-01-07</td><td>17</td><td>True</td><td>False</td></tr><tr><td>7</td><td>2018-01-08</td><td>35</td><td>False</td><td>True</td></tr><tr><td>8</td><td>2018-01-09</td><td>43</td><td>False</td><td>False</td></tr><tr><td>9</td><td>2018-01-10</td><td>36</td><td>False</td><td>False</td></tr><tr><td>10</td><td>2018-01-11</td><td>51</td><td>False</td><td>False</td></tr><tr><td>11</td><td>2018-01-12</td><td>60</td><td>False</td><td>False</td></tr><tr><td>12</td><td>2018-01-13</td><td>61</td><td>False</td><td>False</td></tr><tr><td>13</td><td>2018-01-14</td><td>23</td><td>True</td><td>True</td></tr><tr><td>14</td><td>2018-01-15</td><td>21</td><td>True</td><td>False</td></tr><tr><td>15</td><td>2018-01-16</td><td>33</td><td>False</td><td>True</td></tr><tr><td>16</td><td>2018-01-17</td><td>34</td><td>False</td><td>False</td></tr><tr><td>17</td><td>2018-01-18</td><td>32</td><td>True</td><td>True</td></tr><tr><td>18</td><td>2018-01-19</td><td>34</td><td>False</td><td>True</td></tr><tr><td>19</td><td>2018-01-20</td><td>47</td><td>False</td><td>False</td></tr><tr><td>20</td><td>2018-01-21</td><td>49</td><td>False</td><td>False</td></tr><tr><td>21</td><td>2018-01-22</td><td>39</td><td>False</td><td>False</td></tr><tr><td>22</td><td>2018-01-23</td><td>55</td><td>False</td><td>False</td></tr><tr><td>23</td><td>2018-01-24</td><td>42</td><td>False</td><td>False</td></tr><tr><td>24</td><td>2018-01-25</td><td>30</td><td>True</td><td>True</td></tr><tr><td>25</td><td>2018-01-26</td><td>34</td><td>False</td><td>True</td></tr><tr><td>26</td><td>2018-01-27</td><td>53</td><td>False</td><td>False</td></tr><tr><td>27</td><td>2018-01-28</td><td>52</td><td>False</td><td>False</td></tr><tr><td>28</td><td>2018-01-29</td><td>43</td><td>False</td><td>False</td></tr><tr><td>29</td><td>2018-01-30</td><td>31</td><td>True</td><td>True</td></tr><tr><td>30</td><td>2018-01-31</td><td>30</td><td>True</td><td>False</td></tr></tbody></table><p>Looking at the values of <code>step2</code> in this table, we can see an interesting property: <code>step2</code> is <code>True</code> only in cases where the value of <code>df['freezing']</code> changes.</p><h3 id=step-3>Step 3<a href=#step-3 class=hanchor arialabel=Anchor>&#8983;</a></h3><p>In this step, we apply the <a href=https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.cumsum.html>cumsum</a> method (&ldquo;cumulative sum&rdquo;) to the result of step 2. We store the result in a new series <code>step3</code> in the dataframe:</p><pre tabindex=0><code>df[&#39;step3&#39;] = df[&#39;step2&#39;].cumsum()
</code></pre><p>The result looks like this:</p><table><thead><tr><th></th><th>DATE</th><th>TMAX</th><th>freezing</th><th>step2</th><th>step3</th></tr></thead><tbody><tr><td>0</td><td>2018-01-01</td><td>13</td><td>True</td><td>True</td><td>1</td></tr><tr><td>1</td><td>2018-01-02</td><td>19</td><td>True</td><td>False</td><td>1</td></tr><tr><td>2</td><td>2018-01-03</td><td>29</td><td>True</td><td>False</td><td>1</td></tr><tr><td>3</td><td>2018-01-04</td><td>30</td><td>True</td><td>False</td><td>1</td></tr><tr><td>4</td><td>2018-01-05</td><td>24</td><td>True</td><td>False</td><td>1</td></tr><tr><td>5</td><td>2018-01-06</td><td>12</td><td>True</td><td>False</td><td>1</td></tr><tr><td>6</td><td>2018-01-07</td><td>17</td><td>True</td><td>False</td><td>1</td></tr><tr><td>7</td><td>2018-01-08</td><td>35</td><td>False</td><td>True</td><td>2</td></tr><tr><td>8</td><td>2018-01-09</td><td>43</td><td>False</td><td>False</td><td>2</td></tr><tr><td>9</td><td>2018-01-10</td><td>36</td><td>False</td><td>False</td><td>2</td></tr><tr><td>10</td><td>2018-01-11</td><td>51</td><td>False</td><td>False</td><td>2</td></tr><tr><td>11</td><td>2018-01-12</td><td>60</td><td>False</td><td>False</td><td>2</td></tr><tr><td>12</td><td>2018-01-13</td><td>61</td><td>False</td><td>False</td><td>2</td></tr><tr><td>13</td><td>2018-01-14</td><td>23</td><td>True</td><td>True</td><td>3</td></tr><tr><td>14</td><td>2018-01-15</td><td>21</td><td>True</td><td>False</td><td>3</td></tr><tr><td>15</td><td>2018-01-16</td><td>33</td><td>False</td><td>True</td><td>4</td></tr><tr><td>16</td><td>2018-01-17</td><td>34</td><td>False</td><td>False</td><td>4</td></tr><tr><td>17</td><td>2018-01-18</td><td>32</td><td>True</td><td>True</td><td>5</td></tr><tr><td>18</td><td>2018-01-19</td><td>34</td><td>False</td><td>True</td><td>6</td></tr><tr><td>19</td><td>2018-01-20</td><td>47</td><td>False</td><td>False</td><td>6</td></tr><tr><td>20</td><td>2018-01-21</td><td>49</td><td>False</td><td>False</td><td>6</td></tr><tr><td>21</td><td>2018-01-22</td><td>39</td><td>False</td><td>False</td><td>6</td></tr><tr><td>22</td><td>2018-01-23</td><td>55</td><td>False</td><td>False</td><td>6</td></tr><tr><td>23</td><td>2018-01-24</td><td>42</td><td>False</td><td>False</td><td>6</td></tr><tr><td>24</td><td>2018-01-25</td><td>30</td><td>True</td><td>True</td><td>7</td></tr><tr><td>25</td><td>2018-01-26</td><td>34</td><td>False</td><td>True</td><td>8</td></tr><tr><td>26</td><td>2018-01-27</td><td>53</td><td>False</td><td>False</td><td>8</td></tr><tr><td>27</td><td>2018-01-28</td><td>52</td><td>False</td><td>False</td><td>8</td></tr><tr><td>28</td><td>2018-01-29</td><td>43</td><td>False</td><td>False</td><td>8</td></tr><tr><td>29</td><td>2018-01-30</td><td>31</td><td>True</td><td>True</td><td>9</td></tr><tr><td>30</td><td>2018-01-31</td><td>30</td><td>True</td><td>False</td><td>9</td></tr></tbody></table><p></p><p>We&rsquo;re applying the <code>cumsum</code> method to a boolean series. By doing so, we&rsquo;re taking advantage of the fact that in Python <a href=https://docs.python.org/release/3.0.1/reference/datamodel.html#the-standard-type-hierarchy>we can treat boolean values as integers</a>: a <code>True</code> value evaluates to <code>1</code>, and a <code>False</code> value to <code>0</code>. What we get with this operation is effectively a &ldquo;sequence id&rdquo;: because <code>step2</code> is only <code>True</code> when the value of <code>freezing</code> changes, the value calculated in this step only increments when we start a new sequence of values for which <code>freezing</code> has the same value.</p><h3 id=step-4>Step 4<a href=#step-4 class=hanchor arialabel=Anchor>&#8983;</a></h3><p>In the previous step, we calculated what I called a &ldquo;sequence id&rdquo;. We can take advantage of this to group the data into consecutive stretches for which the temperature was either below freezing or not by using the value as an argument to Pandas&rsquo; <code>groupby</code> method, and then applying the <a href=https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.GroupBy.cumcount.html>cumcount</a> method:</p><pre tabindex=0><code>df[&#39;step4&#39;] = df[&#39;freezing&#39;].groupby(df[&#39;step3&#39;]).cumcount() + 1
</code></pre><p>The <code>cumcount</code> method simply numbers the items in each group, starting at 0. This gives us:</p><table><thead><tr><th></th><th>DATE</th><th>TMAX</th><th>freezing</th><th>step2</th><th>step3</th><th>step4</th></tr></thead><tbody><tr><td>0</td><td>2018-01-01</td><td>13</td><td>True</td><td>True</td><td>1</td><td>1</td></tr><tr><td>1</td><td>2018-01-02</td><td>19</td><td>True</td><td>False</td><td>1</td><td>2</td></tr><tr><td>2</td><td>2018-01-03</td><td>29</td><td>True</td><td>False</td><td>1</td><td>3</td></tr><tr><td>3</td><td>2018-01-04</td><td>30</td><td>True</td><td>False</td><td>1</td><td>4</td></tr><tr><td>4</td><td>2018-01-05</td><td>24</td><td>True</td><td>False</td><td>1</td><td>5</td></tr><tr><td>5</td><td>2018-01-06</td><td>12</td><td>True</td><td>False</td><td>1</td><td>6</td></tr><tr><td>6</td><td>2018-01-07</td><td>17</td><td>True</td><td>False</td><td>1</td><td>7</td></tr><tr><td>7</td><td>2018-01-08</td><td>35</td><td>False</td><td>True</td><td>2</td><td>1</td></tr><tr><td>8</td><td>2018-01-09</td><td>43</td><td>False</td><td>False</td><td>2</td><td>2</td></tr><tr><td>9</td><td>2018-01-10</td><td>36</td><td>False</td><td>False</td><td>2</td><td>3</td></tr><tr><td>10</td><td>2018-01-11</td><td>51</td><td>False</td><td>False</td><td>2</td><td>4</td></tr><tr><td>11</td><td>2018-01-12</td><td>60</td><td>False</td><td>False</td><td>2</td><td>5</td></tr><tr><td>12</td><td>2018-01-13</td><td>61</td><td>False</td><td>False</td><td>2</td><td>6</td></tr><tr><td>13</td><td>2018-01-14</td><td>23</td><td>True</td><td>True</td><td>3</td><td>1</td></tr><tr><td>14</td><td>2018-01-15</td><td>21</td><td>True</td><td>False</td><td>3</td><td>2</td></tr><tr><td>15</td><td>2018-01-16</td><td>33</td><td>False</td><td>True</td><td>4</td><td>1</td></tr><tr><td>16</td><td>2018-01-17</td><td>34</td><td>False</td><td>False</td><td>4</td><td>2</td></tr><tr><td>17</td><td>2018-01-18</td><td>32</td><td>True</td><td>True</td><td>5</td><td>1</td></tr><tr><td>18</td><td>2018-01-19</td><td>34</td><td>False</td><td>True</td><td>6</td><td>1</td></tr><tr><td>19</td><td>2018-01-20</td><td>47</td><td>False</td><td>False</td><td>6</td><td>2</td></tr><tr><td>20</td><td>2018-01-21</td><td>49</td><td>False</td><td>False</td><td>6</td><td>3</td></tr><tr><td>21</td><td>2018-01-22</td><td>39</td><td>False</td><td>False</td><td>6</td><td>4</td></tr><tr><td>22</td><td>2018-01-23</td><td>55</td><td>False</td><td>False</td><td>6</td><td>5</td></tr><tr><td>23</td><td>2018-01-24</td><td>42</td><td>False</td><td>False</td><td>6</td><td>6</td></tr><tr><td>24</td><td>2018-01-25</td><td>30</td><td>True</td><td>True</td><td>7</td><td>1</td></tr><tr><td>25</td><td>2018-01-26</td><td>34</td><td>False</td><td>True</td><td>8</td><td>1</td></tr><tr><td>26</td><td>2018-01-27</td><td>53</td><td>False</td><td>False</td><td>8</td><td>2</td></tr><tr><td>27</td><td>2018-01-28</td><td>52</td><td>False</td><td>False</td><td>8</td><td>3</td></tr><tr><td>28</td><td>2018-01-29</td><td>43</td><td>False</td><td>False</td><td>8</td><td>4</td></tr><tr><td>29</td><td>2018-01-30</td><td>31</td><td>True</td><td>True</td><td>9</td><td>1</td></tr><tr><td>30</td><td>2018-01-31</td><td>30</td><td>True</td><td>False</td><td>9</td><td>2</td></tr></tbody></table><h3 id=step-5>Step 5<a href=#step-5 class=hanchor arialabel=Anchor>&#8983;</a></h3><p>Looking at the results of the previous step, we can see the simply asking for <code>df['step5'].max()</code> would give us the longest sequence of days for which the value of <code>freezing</code> remained constant. How do we limit that to only consider sequences in which <code>freezing</code> is <code>True</code>? We again take advantage of the fact that a boolean is just an integer, and we multiply the result of the previous step by the value of the <code>freezing</code> series:</p><pre tabindex=0><code>df[&#39;step5&#39;] = df[&#39;freezing&#39;] * df[&#39;step4&#39;]
</code></pre><p>This will zero out all the values from the previous step in which <code>freezing</code> is <code>False</code>, because <code>False * x</code> is the same as <code>0 * x</code>. This gives us our final result:</p><table><thead><tr><th></th><th>DATE</th><th>TMAX</th><th>freezing</th><th>step2</th><th>step3</th><th>step4</th><th>step5</th></tr></thead><tbody><tr><td>0</td><td>2018-01-01</td><td>13</td><td>True</td><td>True</td><td>1</td><td>1</td><td>1</td></tr><tr><td>1</td><td>2018-01-02</td><td>19</td><td>True</td><td>False</td><td>1</td><td>2</td><td>2</td></tr><tr><td>2</td><td>2018-01-03</td><td>29</td><td>True</td><td>False</td><td>1</td><td>3</td><td>3</td></tr><tr><td>3</td><td>2018-01-04</td><td>30</td><td>True</td><td>False</td><td>1</td><td>4</td><td>4</td></tr><tr><td>4</td><td>2018-01-05</td><td>24</td><td>True</td><td>False</td><td>1</td><td>5</td><td>5</td></tr><tr><td>5</td><td>2018-01-06</td><td>12</td><td>True</td><td>False</td><td>1</td><td>6</td><td>6</td></tr><tr><td>6</td><td>2018-01-07</td><td>17</td><td>True</td><td>False</td><td>1</td><td>7</td><td>7</td></tr><tr><td>7</td><td>2018-01-08</td><td>35</td><td>False</td><td>True</td><td>2</td><td>1</td><td>0</td></tr><tr><td>8</td><td>2018-01-09</td><td>43</td><td>False</td><td>False</td><td>2</td><td>2</td><td>0</td></tr><tr><td>9</td><td>2018-01-10</td><td>36</td><td>False</td><td>False</td><td>2</td><td>3</td><td>0</td></tr><tr><td>10</td><td>2018-01-11</td><td>51</td><td>False</td><td>False</td><td>2</td><td>4</td><td>0</td></tr><tr><td>11</td><td>2018-01-12</td><td>60</td><td>False</td><td>False</td><td>2</td><td>5</td><td>0</td></tr><tr><td>12</td><td>2018-01-13</td><td>61</td><td>False</td><td>False</td><td>2</td><td>6</td><td>0</td></tr><tr><td>13</td><td>2018-01-14</td><td>23</td><td>True</td><td>True</td><td>3</td><td>1</td><td>1</td></tr><tr><td>14</td><td>2018-01-15</td><td>21</td><td>True</td><td>False</td><td>3</td><td>2</td><td>2</td></tr><tr><td>15</td><td>2018-01-16</td><td>33</td><td>False</td><td>True</td><td>4</td><td>1</td><td>0</td></tr><tr><td>16</td><td>2018-01-17</td><td>34</td><td>False</td><td>False</td><td>4</td><td>2</td><td>0</td></tr><tr><td>17</td><td>2018-01-18</td><td>32</td><td>True</td><td>True</td><td>5</td><td>1</td><td>1</td></tr><tr><td>18</td><td>2018-01-19</td><td>34</td><td>False</td><td>True</td><td>6</td><td>1</td><td>0</td></tr><tr><td>19</td><td>2018-01-20</td><td>47</td><td>False</td><td>False</td><td>6</td><td>2</td><td>0</td></tr><tr><td>20</td><td>2018-01-21</td><td>49</td><td>False</td><td>False</td><td>6</td><td>3</td><td>0</td></tr><tr><td>21</td><td>2018-01-22</td><td>39</td><td>False</td><td>False</td><td>6</td><td>4</td><td>0</td></tr><tr><td>22</td><td>2018-01-23</td><td>55</td><td>False</td><td>False</td><td>6</td><td>5</td><td>0</td></tr><tr><td>23</td><td>2018-01-24</td><td>42</td><td>False</td><td>False</td><td>6</td><td>6</td><td>0</td></tr><tr><td>24</td><td>2018-01-25</td><td>30</td><td>True</td><td>True</td><td>7</td><td>1</td><td>1</td></tr><tr><td>25</td><td>2018-01-26</td><td>34</td><td>False</td><td>True</td><td>8</td><td>1</td><td>0</td></tr><tr><td>26</td><td>2018-01-27</td><td>53</td><td>False</td><td>False</td><td>8</td><td>2</td><td>0</td></tr><tr><td>27</td><td>2018-01-28</td><td>52</td><td>False</td><td>False</td><td>8</td><td>3</td><td>0</td></tr><tr><td>28</td><td>2018-01-29</td><td>43</td><td>False</td><td>False</td><td>8</td><td>4</td><td>0</td></tr><tr><td>29</td><td>2018-01-30</td><td>31</td><td>True</td><td>True</td><td>9</td><td>1</td><td>1</td></tr><tr><td>30</td><td>2018-01-31</td><td>30</td><td>True</td><td>False</td><td>9</td><td>2</td><td>2</td></tr></tbody></table><h3 id=step-6>Step 6<a href=#step-6 class=hanchor arialabel=Anchor>&#8983;</a></h3><p>Now the answer to our question is as simple as asking for the maximum value from the previous step:</p><pre tabindex=0><code>max_consecutive_dbf = df[&#39;step5&#39;].max()
</code></pre><p>And if everything worked as expected, we should find that the longest consecutive sequence of days on which the temperature stayed below freezing was 7 days, from 2018-01-01 through 2018-01-07:</p><pre tabindex=0><code>assert max_consecutive_dbf == 7
</code></pre><h2 id=results>Results<a href=#results class=hanchor arialabel=Anchor>&#8983;</a></h2><p>If we look at the results for the past 20 years, we see the following:</p><figure class=left><img src=sample-results.png></figure><p>For data used in the above chart, the average stretch in which the temperature stays below freezing is 6.45 days (the average for the entire dataset is 6.33 days).</p></div></div><script src=https://utteranc.es/client.js repo=larsks/blog.oddbit.com issue-term=pathname label=comment theme=github-light crossorigin=anonymous async></script></article></div><footer class=footer><div class=footer__inner><div class="copyright copyright--user"><span>Lars Kellogg-Stedman</span>
<span>:: <a href=https://github.com/panr/hugo-theme-terminal target=_blank>Theme</a> made by <a href=https://github.com/panr target=_blank>panr</a></span></div></div></footer><script type=text/javascript src=/bundle.min.js></script>
<script src=/js/mermaid.min.js></script>
<script>mermaid.initialize({startOnLoad:!0})</script></div></body></html>