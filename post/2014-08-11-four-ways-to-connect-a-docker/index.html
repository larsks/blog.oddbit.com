<!doctype html><html lang=en><head><title>Four ways to connect a docker container to a local network :: blog.oddbit.com</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Update (2018-03-22) Since I wrote this document back in 2014, Docker has developed the macvlan network driver. That gives you a supported mechanism for direct connectivity to a local layer 2 network. I&amp;rsquo;ve written an article about working with the macvlan driver.
This article discusses four ways to make a Docker container appear on a local network. These are not suggested as practical solutions, but are meant to illustrate some of the underlying network technology available in Linux."><meta name=keywords content><meta name=robots content="noodp"><link rel=canonical href=https://blog.oddbit.com/post/2014-08-11-four-ways-to-connect-a-docker/><link rel=stylesheet href=https://blog.oddbit.com/styles.css><link rel=stylesheet href=https://blog.oddbit.com/style.css><link rel="shortcut icon" href=https://blog.oddbit.com/img/theme-colors/orange.png><link rel=apple-touch-icon href=https://blog.oddbit.com/img/theme-colors/orange.png><meta name=twitter:card content="summary"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="og:title" content="Four ways to connect a docker container to a local network"><meta property="og:description" content="Update (2018-03-22) Since I wrote this document back in 2014, Docker has developed the macvlan network driver. That gives you a supported mechanism for direct connectivity to a local layer 2 network. I&amp;rsquo;ve written an article about working with the macvlan driver.
This article discusses four ways to make a Docker container appear on a local network. These are not suggested as practical solutions, but are meant to illustrate some of the underlying network technology available in Linux."><meta property="og:url" content="https://blog.oddbit.com/post/2014-08-11-four-ways-to-connect-a-docker/"><meta property="og:site_name" content="blog.oddbit.com"><meta property="og:image" content="https://blog.oddbit.com/img/favicon/orange.png"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="627"><meta property="article:section" content="tech"><meta property="article:published_time" content="2014-08-11 00:00:00 +0000 UTC"></head><body class=orange><div class="container center headings--one-size"><header class=header><div class=header__inner><div class=header__logo><a href=/><div class=logo>the odd bit blog</div></a></div><ul class="menu menu--mobile"><li class=menu__trigger>Menu&nbsp;▾</li><li><ul class=menu__dropdown><li><a href=/>/</a></li><li><a href=https://oddbit.com>/about</a></li><li><a href=/posts>/posts</a></li><li><a href=/archive>/archive</a></li><li><a href=/rss.xml>/feed</a></li><li><a href=https://github.com/larsks>→Github</a></li><li><a href=https://hachyderm.io/@larsks>→Mastodon</a></li><li><a href=https://twitter.com/larsks>→Twitter</a></li></ul></li></ul></div><nav class=navigation-menu><ul class="navigation-menu__inner menu--desktop"><li><a href=/>/</a></li><li><a href=https://oddbit.com>/about</a></li><li><a href=/posts>/posts</a></li><li><a href=/archive>/archive</a></li><li><a href=/rss.xml>/feed</a></li><li><ul class=menu><li class=menu__trigger>&nbsp;▾</li><li><ul class=menu__dropdown><li><a href=https://github.com/larsks>→Github</a></li><li><a href=https://hachyderm.io/@larsks>→Mastodon</a></li><li><a href=https://twitter.com/larsks>→Twitter</a></li></ul></li></ul></li></ul></nav></header><div class=content><article class=post><h1 class=post-title><a href=https://blog.oddbit.com/post/2014-08-11-four-ways-to-connect-a-docker/>Four ways to connect a docker container to a local network</a></h1><div class=post-meta><time class=post-date>2014-08-11 ::</time></div><span class=post-tags>#<a href=https://blog.oddbit.com/tags/networking/>networking</a>&nbsp;
#<a href=https://blog.oddbit.com/tags/docker/>docker</a>&nbsp;
#<a href=https://blog.oddbit.com/tags/openvswitch/>openvswitch</a>&nbsp;</span><div class=post-content><div><p><strong>Update (2018-03-22)</strong> Since I wrote this document back in 2014,
Docker has developed the <a href=https://docs.docker.com/network/macvlan/>macvlan network
driver</a>. That gives you a
<em>supported</em> mechanism for direct connectivity to a local layer 2
network. I&rsquo;ve <a href=/2018/03/12/using-docker-macvlan-networks/>written an article about working with the macvlan
driver</a>.</p><hr><p>This article discusses four ways to make a Docker container appear on
a local network. These are not suggested as practical solutions, but
are meant to illustrate some of the underlying network technology
available in Linux.</p><p>If you were actually going to use one of these solutions as anything
other than a technology demonstration, you might look to the <a href=https://github.com/jpetazzo/pipework>pipework</a> script, which can automate many of these configurations.</p><h2 id=goals-and-assumptions>Goals and Assumptions<a href=#goals-and-assumptions class=hanchor arialabel=Anchor>&#8983;</a></h2><p>In the following examples, we have a host with address 10.12.0.76 on
the 10.12.0.0/21 network. We are creating a Docker container that we
want to expose as 10.12.0.117.</p><p>I am running Fedora 20 with Docker 1.1.2. This means, in particular,
that my <code>utils-linux</code> package is recent enough to include the
<a href=http://man7.org/linux/man-pages/man1/nsenter.1.html>nsenter</a> command. If you don&rsquo;t have that handy, there is a
convenient Docker recipe to build it for you at <a href=https://github.com/jpetazzo/nsenter>jpetazzo/nsenter</a>
on GitHub.</p><h2 id=a-little-help-along-the-way>A little help along the way<a href=#a-little-help-along-the-way class=hanchor arialabel=Anchor>&#8983;</a></h2><p>In this article we will often refer to the PID of a docker container.
In order to make this convenient, drop the following into a script
called <code>docker-pid</code>, place it somewhere on your <code>PATH</code>, and make it
executable:</p><pre><code>#!/bin/sh

exec docker inspect --format '{{ .State.Pid }}' &quot;$@&quot;
</code></pre><p>This allows us to conveniently get the PID of a docker container by
name or ID:</p><pre><code>$ docker-pid web
22041
</code></pre><p>In a script called <code>docker-ip</code>, place the following:</p><pre><code>#!/bin/sh

exec docker inspect --format '{{ .NetworkSettings.IPAddress }}' &quot;$@&quot;
</code></pre><p>And now we can get the ip address of a container like this:</p><pre><code>$ docker-ip web
172.17.0.4
</code></pre><h2 id=using-nat>Using NAT<a href=#using-nat class=hanchor arialabel=Anchor>&#8983;</a></h2><p>This uses the standard Docker network model combined with NAT rules on
your host to redirect inbound traffic to/outbound traffic from the
appropriate IP address.</p><p>Assign our target address to your host interface:</p><pre><code># ip addr add 10.12.0.117/21 dev em1
</code></pre><p>Start your docker container, using the <code>-p</code> option to bind exposed
ports to an ip address and port on the host:</p><pre><code># docker run -d --name web -p 10.12.0.117:80:80 larsks/simpleweb
</code></pre><p>With this command, Docker will set up the <a href=https://docs.docker.com/articles/networking/>standard network</a> model:</p><ul><li>It will create a <a href=http://lwn.net/Articles/232688/>veth</a> interface pair.</li><li>Connect one end to the <code>docker0</code> bridge.</li><li>Place the other inside the container namespace as <code>eth0</code>.</li><li>Assign an ip address from the network used by the <code>docker0</code> bridge.</li></ul><p>Because we added <code>-p 10.12.0.117:80:80</code> to our command line, Docker
will also create the following rule in the <code>nat</code> table <code>DOCKER</code>
chain (which is run from the <code>PREROUTING</code> chain):</p><pre><code>-A DOCKER -d 10.12.0.117/32 ! -i docker0 -p tcp -m tcp 
  --dport 80 -j DNAT --to-destination 172.17.0.4:80
</code></pre><p>This matches traffic TO our target address (<code>-d 10.12.0.117/32</code>) not
originating on the <code>docker0</code> bridge (<code>! -i docker0</code>) destined for
<code>tcp</code> port <code>80</code> (<code>-p tcp -m tcp --dport 80</code>). Matching traffic has
it&rsquo;s destination set to the address of our docker container (<code>-j DNAT --to-destination 172.17.0.4:80</code>).</p><p>From a host elsewhere on the network, we can now access the web server
at our selected ip address:</p><pre><code>$ curl http://10.12.0.117/hello.html
Hello world
</code></pre><p>If our container were to initiate a network connection with another
system, that connection would appear to originate with ip address of
our <em>host</em>. We can fix that my adding a <code>SNAT</code> rule to the
<code>POSTROUTING</code> chain to modify the source address:</p><pre><code># iptables -t nat -I POSTROUTING -s $(docker-ip web) \
    -j SNAT --to-source 10.12.0.117
</code></pre><p>Note here the use of <code>-I POSTROUTING</code>, which places the rule at the
<em>top</em> of the <code>POSTROUTING</code> chain. This is necessary because, by
default, Docker has already added the following rule to the top of the
<code>POSTROUTING</code> chain:</p><pre><code>-A POSTROUTING -s 172.17.0.0/16 ! -d 172.17.0.0/16 -j MASQUERADE
</code></pre><p>Because this <code>MASQUERADE</code> rule matches traffic from any container, we
need to place our rule earlier in the <code>POSTROUTING</code> chain for it to
have any affect.</p><p>With these rules in place, traffic to 10.12.0.117 (port 80) is
directed to our <code>web</code> container, and traffic <em>originating</em> in the web
container will appear to come from 10.12.0.117.</p><h2 id=with-linux-bridge-devices>With Linux Bridge devices<a href=#with-linux-bridge-devices class=hanchor arialabel=Anchor>&#8983;</a></h2><p>The previous example was relatively easy to configure, but has a few
shortcomings. If you need to configure an interface using DHCP, or if
you have an application that needs to be on the same layer 2 broadcast
domain as other devices on your network, NAT rules aren&rsquo;t going to
work out.</p><p>This solution uses a Linux bridge device, created using <code>brctl</code>, to
connect your containers directly to a physical network.</p><p>Start by creating a new bridge device. In this example, we&rsquo;ll create
one called <code>br-em1</code>:</p><pre><code># brctl addbr br-em1
# ip link set br-em1 up
</code></pre><p>We&rsquo;re going to add <code>em1</code> to this bridge, and move the ip address from
<code>em1</code> onto the bridge.</p><p><strong>WARNING</strong>: This is not something you should do remotely, especially
for the first time, and making this persistent varies from
distribution to distribution, so this will not be a persistent
configuration.</p><p>Look at the configuration of interface <code>em1</code> and note the existing ip
address:</p><pre><code># ip addr show em1
2: em1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq master br-em1 state UP group default qlen 1000
    link/ether 00:1d:09:63:71:30 brd ff:ff:ff:ff:ff:ff
    inet 10.12.0.76/21 scope global br-em1
       valid_lft forever preferred_lft forever
</code></pre><p>Look at your current routes and note the default route:</p><pre><code># ip route
default via 10.12.7.254 dev em1 
10.12.0.0/21 dev em1  proto kernel  scope link  src 10.12.0.76 
</code></pre><p>Now, add this device to your bridge:</p><pre><code># brctl addif br-em1 em1
</code></pre><p>Configure the bridge with the address that used to belong to
<code>em1</code>:</p><pre><code># ip addr del 10.12.0.76/21 dev em1
# ip addr add 10.12.0.76/21 dev br-em1
</code></pre><p>And move the default route to the bridge:</p><pre><code># ip route del default
# ip route add default via 10.12.7.254 dev br-em1
</code></pre><p>If you were doing this remotely; you would do this all in one line
like this:</p><pre><code># ip addr add 10.12.0.76/21 dev br-em1; \
    ip addr del 10.12.0.76/21 dev em1; \
    brctl addif br-em1 em1; \
    ip route del default; \
    ip route add default via 10.12.7.254 dev br-em1
</code></pre><p>At this point, verify that you still have network connectivity:</p><pre><code># curl http://google.com/
&lt;HTML&gt;&lt;HEAD&gt;&lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html;charset=utf-8&quot;&gt;
[...]
</code></pre><p>Start up the web container:</p><pre><code># docker run -d --name web larsks/simpleweb
</code></pre><p>This will give us the normal <code>eth0</code> interface inside the container,
but we&rsquo;re going to ignore that and add a new one.</p><p>Create a <a href=http://lwn.net/Articles/232688/>veth</a> interface pair:</p><pre><code># ip link add web-int type veth peer name web-ext
</code></pre><p>Add the <code>web-ext</code> link to the <code>br-eth0</code> bridge:</p><pre><code># brctl addif br-em1 web-ext
</code></pre><p>And add the <code>web-int</code> interface to the namespace of the container:</p><pre><code># ip link set netns $(docker-pid web) dev web-int
</code></pre><p>Next, we&rsquo;ll use the <a href=http://man7.org/linux/man-pages/man1/nsenter.1.html>nsenter</a> command (part of the <code>util-linux</code> package) to run some commands inside the <code>web</code> container. Start by bringing up the link inside the container:</p><pre><code># nsenter -t $(docker-pid web) -n ip link set web-int up
</code></pre><p>Assign our target ip address to the interface:</p><pre><code># nsenter -t $(docker-pid web) -n ip addr add 10.12.0.117/21 dev web-int
</code></pre><p>And set a new default route inside the container:</p><pre><code># nsenter -t $(docker-pid web) -n ip route del default
# nsenter -t $(docker-pid web) -n ip route add default via 10.12.7.254 dev web-int
</code></pre><p>Again, we can verify from another host that the web server is
available at 10.12.0.117:</p><pre><code>$ curl http://10.12.0.117/hello.html
Hello world
</code></pre><p>Note that in this example we have assigned a static ip address, but we
could just have easily acquired an address using DHCP. After running:</p><pre><code># nsenter -t $(docker-pid web) -n ip link set web-int up
</code></pre><p>We can run:</p><pre><code># nsenter -t $(docker-pid web) -n -- dhclient -d web-int
Internet Systems Consortium DHCP Client 4.2.6
Copyright 2004-2014 Internet Systems Consortium.
All rights reserved.
For info, please visit https://www.isc.org/software/dhcp/

Listening on LPF/web-int/6e:f0:a8:c6:f0:43
Sending on   LPF/web-int/6e:f0:a8:c6:f0:43
Sending on   Socket/fallback
DHCPDISCOVER on web-int to 255.255.255.255 port 67 interval 4 (xid=0x3aaab45b)
DHCPREQUEST on web-int to 255.255.255.255 port 67 (xid=0x3aaab45b)
DHCPOFFER from 10.12.7.253
DHCPACK from 10.12.7.253 (xid=0x3aaab45b)
bound to 10.12.6.151 -- renewal in 714 seconds.
</code></pre><h2 id=with-open-vswitch-bridge-devices>With Open vSwitch Bridge devices<a href=#with-open-vswitch-bridge-devices class=hanchor arialabel=Anchor>&#8983;</a></h2><p>This process is largely the same as in the previous example, but we
use <a href=http://openvswitch.org/>Open vSwitch</a> instead of the legacy Linux bridge devices.
These instructions assume that you have already installed and started
Open vSwitch on your system.</p><p>Create an OVS bridge using the <code>ovs-vsctl</code> command:</p><pre><code># ovs-vsctl add-br br-em1
# ip link set br-em1 up
</code></pre><p>And add your external interface:</p><pre><code># ovs-vsctl add-port br-em1 em1
</code></pre><p>And then proceed as in the previous set of instructions.</p><p>The equivalent all-in-one command is:</p><pre><code># ip addr add 10.12.0.76/21 dev br-em1; \
    ip addr del 10.12.0.76/21 dev em1; \
    ovs-vsctl add-port br-em1 em1; \
    ip route del default; \
    ip route add default via 10.12.7.254 dev br-em1
</code></pre><p>Once that completes, your openvswitch configuration should look like
this:</p><pre><code># ovs-vsctl show
0b1d5895-88e6-42e5-a1da-ad464c75198c
    Bridge &quot;br-em1&quot;
        Port &quot;br-em1&quot;
            Interface &quot;br-em1&quot;
                type: internal
        Port &quot;em1&quot;
            Interface &quot;em1&quot;
    ovs_version: &quot;2.1.2&quot;
</code></pre><p>To add the <code>web-ext</code> interface to the bridge, run:</p><pre><code># ovs-vsctl add-port br-em1 web-ext
</code></pre><p>Instead of:</p><pre><code># brctl addif br-em1 web-ext
</code></pre><p><strong>WARNING</strong>: The Open vSwitch configuration persists between reboots.
This means that when your system comes back up, <code>em1</code> will still be a
member of <code>br-em</code>, which will probably result in no network
connectivity for your host.</p><p>Before rebooting your system, make sure to <code>ovs-vsctl del-port br-em1 em1</code>.</p><h2 id=with-macvlan-devices>With macvlan devices<a href=#with-macvlan-devices class=hanchor arialabel=Anchor>&#8983;</a></h2><p>This process is similar to the previous two, but instead of using a
bridge device we will create a <a href=http://backreference.org/2014/03/20/some-notes-on-macvlanmacvtap/>macvlan</a>, which is a virtual network
interface associated with a physical interface. Unlike the previous
two solutions, this does not require any interruption to your primary
network interface.</p><p>Start by creating a docker container as in the previous examples:</p><pre><code># docker run -d --name web larsks/simpleweb
</code></pre><p>Create a <code>macvlan</code> interface associated with your physical interface:</p><pre><code># ip link add em1p0 link em1 type macvlan mode bridge
</code></pre><p>This creates a new <code>macvlan</code> interface named <code>em1p0</code> (but you can
name it anything you want) associated with interface <code>em1</code>. We are
setting it up in <code>bridge</code> mode, which permits all <code>macvlan</code> interfaces
to communicate with eachother.</p><p>Add this interface to the container&rsquo;s network namespace:</p><pre><code># ip link set netns $(docker-pid web) em1p0
</code></pre><p>Bring up the link:</p><pre><code># nsenter -t $(docker-pid web) -n ip link set em1p0 up
</code></pre><p>And configure the ip address and routing:</p><pre><code># nsenter -t $(docker-pid web) -n ip route del default
# nsenter -t $(docker-pid web) -n ip addr add 10.12.0.117/21 dev em1p0
# nsenter -t $(docker-pid web) -n ip route add default via 10.12.7.254 dev em1p0
</code></pre><p>And demonstrate that <em>from another host</em> the web server is available
at 10.12.0.117:</p><pre><code>$ curl http://10.12.0.117/hello.html
Hello world
</code></pre><p>But note that if you were to try the same thing on the host, you would
get:</p><pre><code>curl: (7) Failed connect to 10.12.0.117:80; No route to host
</code></pre><p>The <em>host</em> is unable to communicate with <code>macvlan</code> devices via the
primary interface. You can create <em>another</em> <code>macvlan</code> interface on
the host, give it an address on the appropriate network, and then set
up routes to your containers via that interface:</p><pre><code># ip link add em1p1 link em1 type macvlan mode bridge
# ip addr add 10.12.6.144/21 dev em1p1
# ip route add 10.12.0.117 dev em1p1
</code></pre></div></div><script src=https://utteranc.es/client.js repo=larsks/blog.oddbit.com issue-term=pathname label=comment theme=github-light crossorigin=anonymous async></script></article></div><footer class=footer><div class=footer__inner><div class="copyright copyright--user"><span>Lars Kellogg-Stedman</span>
<span>:: <a href=https://github.com/panr/hugo-theme-terminal target=_blank>Theme</a> made by <a href=https://github.com/panr target=_blank>panr</a></span></div></div></footer><script type=text/javascript src=/bundle.min.js></script></div></body></html>